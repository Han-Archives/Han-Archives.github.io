{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/[ML] Cross_Validation/[ML] Cross_Validation/",
    "result": {"data":{"cur":{"id":"42a1f5a5-2de2-5172-a997-5546d38c90f9","html":"<h3 id=\"êµì°¨-ê²€ì¦\" style=\"position:relative;\"><a href=\"#%EA%B5%90%EC%B0%A8-%EA%B2%80%EC%A6%9D\" aria-label=\"êµì°¨ ê²€ì¦ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>êµì°¨ ê²€ì¦</h3>\n<p>ê³ ì •ëœ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€ë¥¼ í•˜ë©´ <strong>ê³¼ì í•©ì˜ ë¬¸ì œê°€ ë°œìƒ</strong>í•œë‹¤. ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ <strong>êµì°¨ê²€ì¦</strong>ì´ë¼ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•œë‹¤.</p>\n<h4 id=\"k-fold\" style=\"position:relative;\"><a href=\"#k-fold\" aria-label=\"k fold permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>K-Fold</h4>\n<p>í•™ìŠµ ë°ì´í„°ë¥¼ K ê°œì˜ Foldë¡œ ë‚˜ëˆ„ê³  <strong>ë‚˜ëˆ„ì–´ì§„ í´ë“œ ì¤‘ í•˜ë‚˜ë¥¼ ê²€ì¦ìš©, ë‚˜ë¨¸ì§€ë¥¼ í•™ìŠµìš©ìœ¼ë¡œ ì„ ì •</strong>í•œ ë’¤ ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ ê²€ì¦ìš© í´ë“œë¥¼ ë³€ê²½í•˜ë©´ì„œ í•™ìŠµê³¼ ê²€ì¦ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒ.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 93.33333333333333%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAABYlAAAWJQFJUiTwAAADWUlEQVQ4y3WU61PbRhTF/f9/a/ulkzalmSaUZAhQGJpAmTaUxkB41DwMxjbGlrGFJe1KK1vWW7+OhHF49WrO3Kvd1dE9e+9uKcsy0jQlTbNHuB1LkpSkiL/6x3HOkVvuSyPPxxQSIe0prAmEdLhqt2heXiJtB0cNsR0X21FF7CgXS0hyjilh/oc4SR4ijgmjOF/C4kaT04ZFFI7RbwYIKZG2ja7rGKZJGEaFkikh9y3jiS1ttKnWbUgi9J6OY0tcx8EwDIRlkSXxlCy30kk8YD6ushzXWE5qLAZV3ug7vO6VeSsP+ECdlbTGclZjPdSYr8PMSciLbYOfDl1mzjI0lRRkaZ6h7nucjwUNX9IIJBdjwanUqco+58qgFTs0Q5tzT9D0HGpGwrEeUtEUle6IIz1hGKb3JOfxfeQuTAnHt1IGNx7j0SSDKC2kk6WQJoS+N92rW8UZpYyvT1qMZvhhjHbjEcYx385W2Tq8gSygo2lo3S6apjHyvGlW2eS73JXuBrJJTdLJ5saTyvWMEdINijhKkmI+edR7D/rwrprCHKBfd1BSoTU1HOHS7/SxDYEYiNvYUnRbXYQpiaLoCWFR5TAMi17a7wxZP1UcS4uyOON01KdsNdkXHQ5kp4hPVJ8ts86Z2SUc+w8I71DK+8m0LJYaBt/stljp67w432PVavNKL/PerLBgHfFzr8xHdcEP2t/8YzZIw5jnrKRUfowUW6M6i2qXP3qSmbJkre2yYB7x0aqzZtcK0k23xbvBPoeOhhI2hmkUDV4kZZrFuS4IlXLZUA1eG/tsjC751dhhTWh8X1bMHilW7Cpzco8Nt8Evgy/siBbBaEwQBnieh+/7BQrJlmUhhOCTrDN3vcvm8Iq59jaf3Cvedf9lVa/x/ljw8rPBn1aHOX2TPdEg8cPnJTuOjZQ2H9Q5L40dfh/WmdG3WR1e8MraZV4e8fa6xY/tGkuawXeVDn+1DZI4fZ5wPB4z9n1q3g27TouLwOSLuKQWmOw5bU5GPSpum215xkHPZu3YplLvEVtNxkYL1avjGy1iu0uWJo9um/+xLIgZCYVjDgg8F6mdEVV/wz5coPt5FreyQFRfJ40CSsOhW7SN7TjYjl14SwiEfXvvKVdN5/wgnJympzfd3ft/D42WbmqHnbMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"cross_validation.png\"\n        title=\"cross_validation.png\"\n        src=\"/static/a7948edca84aa194bbaef25dd91c839c/37523/cross_validation.png\"\n        srcset=\"/static/a7948edca84aa194bbaef25dd91c839c/e9ff0/cross_validation.png 180w,\n/static/a7948edca84aa194bbaef25dd91c839c/f21e7/cross_validation.png 360w,\n/static/a7948edca84aa194bbaef25dd91c839c/37523/cross_validation.png 720w,\n/static/a7948edca84aa194bbaef25dd91c839c/6029f/cross_validation.png 906w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h4 id=\"ëŒ€í‘œì ì¸-í´ë˜ìŠ¤ë¡œ-kfold-stratified-k-fold-cross_val_scoreê°€-ìˆë‹¤\" style=\"position:relative;\"><a href=\"#%EB%8C%80%ED%91%9C%EC%A0%81%EC%9D%B8-%ED%81%B4%EB%9E%98%EC%8A%A4%EB%A1%9C-kfold-stratified-k-fold-cross_val_score%EA%B0%80-%EC%9E%88%EB%8B%A4\" aria-label=\"ëŒ€í‘œì ì¸ í´ë˜ìŠ¤ë¡œ kfold stratified k fold cross_val_scoreê°€ ìˆë‹¤ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ëŒ€í‘œì ì¸ í´ë˜ìŠ¤ë¡œ KFold, Stratified k-fold, Cross_val_scoreê°€ ìˆë‹¤.</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">### ì¢‹ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ” ë²•</span>\n!<span class=\"token punctuation\">[</span>png<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>cross_validation<span class=\"token punctuation\">.</span>png<span class=\"token punctuation\">)</span></code></pre></div>\n<hr>\n<h3 id=\"ì˜ˆì‹œ-ì¤‘ì‚°ì¸µ-ë¶„ë¥˜í•˜ê¸°\" style=\"position:relative;\"><a href=\"#%EC%98%88%EC%8B%9C-%EC%A4%91%EC%82%B0%EC%B8%B5-%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0\" aria-label=\"ì˜ˆì‹œ ì¤‘ì‚°ì¸µ ë¶„ë¥˜í•˜ê¸° permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ì˜ˆì‹œ: ì¤‘ì‚°ì¸µ ë¶„ë¥˜í•˜ê¸°</h3>\n<h4 id=\"ë°ì´í„°ì…‹-ì¤€ë¹„\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B-%EC%A4%80%EB%B9%84\" aria-label=\"ë°ì´í„°ì…‹ ì¤€ë¹„ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ë°ì´í„°ì…‹ ì¤€ë¹„</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">import</span> seaborn <span class=\"token keyword\">as</span> sns\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">from</span> matplotlib <span class=\"token keyword\">import</span> rcParams\nrcParams<span class=\"token punctuation\">[</span><span class=\"token string\">'figure.figsize'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">13</span><span class=\"token punctuation\">,</span> <span class=\"token number\">7</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> warnings\n\nwarnings<span class=\"token punctuation\">.</span>filterwarnings<span class=\"token punctuation\">(</span>action<span class=\"token operator\">=</span><span class=\"token string\">'ignore'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"./data/df_uci_adult.csv\"</span><span class=\"token punctuation\">)</span>\n\ndf<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>marital.status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>sex</th>\n      <th>capital_gain</th>\n      <th>capital_loss</th>\n      <th>hours-per-week</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>83311</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>215646</td>\n      <td>4</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>53</td>\n      <td>234721</td>\n      <td>8</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>338409</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37</td>\n      <td>284582</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelEncoder\ncategorical <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'education'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'marital.status'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'occupation'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'relationship'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'sex'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'income'</span><span class=\"token punctuation\">]</span>\nlabel_encoder <span class=\"token operator\">=</span> LabelEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> categorical<span class=\"token punctuation\">:</span>\n    label_encoder<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    df<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> label_encoder<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n<span class=\"token comment\"># features</span>\nX <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'education'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'marital.status'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'occupation'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'relationship'</span><span class=\"token punctuation\">,</span>\n     <span class=\"token string\">'sex'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'age'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'fnlwgt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'capital_gain'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'capital_loss'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'hours-per-week'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># label</span>\ny <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'income'</span><span class=\"token punctuation\">]</span></code></pre></div>\n<h4 id=\"k-fold-1\" style=\"position:relative;\"><a href=\"#k-fold-1\" aria-label=\"k fold 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>K-Fold</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> KFold\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> accuracy_score\n<span class=\"token keyword\">from</span> xgboost <span class=\"token keyword\">import</span> XGBClassifier\n\n<span class=\"token comment\"># 5ê°œì˜ Fold</span>\nkfold <span class=\"token operator\">=</span> KFold<span class=\"token punctuation\">(</span>n_splits<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># cv(split)ë³„ ì •í™•ë„</span>\ncv_accuracy <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\nxgbclf <span class=\"token operator\">=</span> XGBClassifier<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># ë°˜ë³µ íšŸìˆ˜</span>\nn <span class=\"token operator\">=</span><span class=\"token number\">0</span>\n\n<span class=\"token keyword\">for</span> train_index<span class=\"token punctuation\">,</span> test_index <span class=\"token keyword\">in</span> kfold<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    X_train<span class=\"token punctuation\">,</span> X_test<span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>train_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>test_index<span class=\"token punctuation\">]</span>\n    y_train<span class=\"token punctuation\">,</span> y_test <span class=\"token operator\">=</span>y<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>train_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>test_index<span class=\"token punctuation\">]</span>\n    \n    <span class=\"token comment\"># ML í•™ìŠµ ë° ì˜ˆì¸¡</span>\n    xgbclf<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n    xgb_pred <span class=\"token operator\">=</span> xgbclf<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\n    \n    n <span class=\"token operator\">+=</span><span class=\"token number\">1</span>\n    <span class=\"token comment\"># ë°˜ë³µí•  ë•Œë§ˆë‹¤ ì •í™•ë„ ì¸¡ì •</span>\n    acc <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>accuracy_score<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> xgb_pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n    train_size <span class=\"token operator\">=</span> X_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    test_size <span class=\"token operator\">=</span> X_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    \n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'\\n#{0} êµì°¨ ê²€ì¦ ì •í™•ë„ : {1}, í•™ìŠµ ë°ì´í„° í¬ê¸°: {2}, ê²€ì¦ ë°ì´í„° í¬ê¸°\" {3}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span> acc<span class=\"token punctuation\">,</span> train_size<span class=\"token punctuation\">,</span> test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'#{0} ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:{1}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span>test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    \n    cv_accuracy<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>acc<span class=\"token punctuation\">)</span>\n    \n<span class=\"token comment\"># ê°œë³„ iterë³„ ì •í™•ë„ í‰ê·  ê³„ì‚°</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'\\n í‰ê·  ê²€ì¦ ì •í™•ë„:'</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>cv_accuracy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[20:58:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#1 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.865, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#1 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n[20:58:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#2 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.867, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#2 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n[20:58:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#3 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.868, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#3 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n[20:58:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#4 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.87, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#4 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n[20:58:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#5 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.865, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#5 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n\n í‰ê·  ê²€ì¦ ì •í™•ë„: 0.867</code></pre></div>\n<h4 id=\"stratified-k-fold\" style=\"position:relative;\"><a href=\"#stratified-k-fold\" aria-label=\"stratified k fold permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Stratified k-fold</h4>\n<p>ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ targetê°’ì´ <strong>ë¶ˆê· í˜•í•œ ë¶„í¬ë¥¼ ê°€ì§„ ë°ì´í„° ì§‘í•©</strong>ì„ ìœ„í•œ ë°©ì‹ìœ¼ë¡œ target ë¶„í¬ì™€ ë¹„ìŠ·í•œ ë¹„ìœ¨ (ì˜ˆì œì˜ ê²½ìš° 3:1)ë¡œ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ë¶„ë°°í•œë‹¤.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># ì „ì²´ ë°ì´í„° ì¤‘ ëª©í‘œê°’ ë¹„ìœ¨</span>\nsns<span class=\"token punctuation\">.</span>set_style<span class=\"token punctuation\">(</span><span class=\"token string\">\"whitegrid\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Income Distribution of Adults'</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">18</span><span class=\"token punctuation\">,</span> fontweight<span class=\"token operator\">=</span><span class=\"token string\">'bold'</span><span class=\"token punctuation\">)</span>\neda_percentage <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'income'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span>normalize <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rename_axis<span class=\"token punctuation\">(</span><span class=\"token string\">'income'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>reset_index<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> <span class=\"token string\">'Percentage'</span><span class=\"token punctuation\">)</span>\n\nax <span class=\"token operator\">=</span> sns<span class=\"token punctuation\">.</span>barplot<span class=\"token punctuation\">(</span>x <span class=\"token operator\">=</span> <span class=\"token string\">'income'</span><span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> <span class=\"token string\">'Percentage'</span><span class=\"token punctuation\">,</span> data <span class=\"token operator\">=</span> eda_percentage<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> palette<span class=\"token operator\">=</span><span class=\"token string\">'Greens_r'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> p <span class=\"token keyword\">in</span> ax<span class=\"token punctuation\">.</span>patches<span class=\"token punctuation\">:</span>\n    width <span class=\"token operator\">=</span> p<span class=\"token punctuation\">.</span>get_width<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    height <span class=\"token operator\">=</span> p<span class=\"token punctuation\">.</span>get_height<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    x<span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> p<span class=\"token punctuation\">.</span>get_xy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> \n    ax<span class=\"token punctuation\">.</span>annotate<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>height<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.0%</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x <span class=\"token operator\">+</span> width<span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> y <span class=\"token operator\">+</span> height<span class=\"token operator\">*</span><span class=\"token number\">1.02</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> ha<span class=\"token operator\">=</span><span class=\"token string\">'center'</span><span class=\"token punctuation\">,</span> fontweight<span class=\"token operator\">=</span><span class=\"token string\">'bold'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 57.22222222222223%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAAB1ElEQVQoz5WS3WvTYBSH+yd54Y2K4lfV+YHo3GRbJyp4oV7ofyGCc7pOd+G82MU2XArqdJ0g65woelE71i8Et6TVkqbtEpt2FaFJHnnfltChVjzwcA7hzcPvzUkAoOk4WFtVzK3vWI0qumlQsU3Wv6pk1c+oeY2irmOaJoVCQXZRruv6eJ4newAPyrVNQlM3OTd5lf7H1+mbvCb74NQNTj+6wmL2jRR44nC7OiW/CQ27wpHxYfaN9rP/3nmfA/cH2Hn7FE8+vaB1k6b/8p9oCV0wqmVOTFzi0NggwXCIYHhIcnR8mN0jZ4kkotuE3Qh4jkeptsnxhxc5ODbA4fCQj0i9684ZX+i4zl/T+Qkb9QbluklPF6GSWPjPhHala0KlnVCk8Ktj7FyUXMq/ha2EmqWypifIlJKsFuKsfovLea2YYMP80rEUu8LJicttSYhgm2MPLrDnbq8v/JB/h5Kc5llG4WlmTiJmJTXDirokv3FAHDTssvxFRBohkIz0sne0jx23epiNz0vhx/x7IqkZnmcjUiQQcyQ1y1st1kroOg6Nnz94lV1hIR0jml7mZXKJaDrGYnqZ+eRr1ss5vKZLqW6gmRvkLY2cqZKzVDmLZ8WaLoW/AL4K1qMcCQxnAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/334b3ced386e42d4afa8774ec5ca8c62/37523/output_14_0.png\"\n        srcset=\"/static/334b3ced386e42d4afa8774ec5ca8c62/e9ff0/output_14_0.png 180w,\n/static/334b3ced386e42d4afa8774ec5ca8c62/f21e7/output_14_0.png 360w,\n/static/334b3ced386e42d4afa8774ec5ca8c62/37523/output_14_0.png 720w,\n/static/334b3ced386e42d4afa8774ec5ca8c62/612f7/output_14_0.png 773w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> StratifiedKFold\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> accuracy_score\n<span class=\"token keyword\">from</span> xgboost <span class=\"token keyword\">import</span> XGBClassifier\n\n<span class=\"token comment\"># 5ê°œì˜ Fold</span>\nSkfold <span class=\"token operator\">=</span> StratifiedKFold<span class=\"token punctuation\">(</span>n_splits<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># cv(split)ë³„ ì •í™•ë„</span>\ncv_accuracy <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\nxgbclf <span class=\"token operator\">=</span> XGBClassifier<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># ë°˜ë³µ íšŸìˆ˜</span>\nn <span class=\"token operator\">=</span><span class=\"token number\">0</span>\n\n<span class=\"token keyword\">for</span> train_index<span class=\"token punctuation\">,</span> test_index <span class=\"token keyword\">in</span> Skfold<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    X_train<span class=\"token punctuation\">,</span> X_test<span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>train_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>test_index<span class=\"token punctuation\">]</span>\n    y_train<span class=\"token punctuation\">,</span> y_test <span class=\"token operator\">=</span>y<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>train_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">[</span>test_index<span class=\"token punctuation\">]</span>\n    \n    <span class=\"token comment\"># ML í•™ìŠµ ë° ì˜ˆì¸¡</span>\n    xgbclf<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n    xgb_pred <span class=\"token operator\">=</span> xgbclf<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span>\n    \n    n <span class=\"token operator\">+=</span><span class=\"token number\">1</span>\n    <span class=\"token comment\"># ë°˜ë³µí•  ë•Œë§ˆë‹¤ ì •í™•ë„ ì¸¡ì •</span>\n    acc <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>accuracy_score<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> xgb_pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n    train_size <span class=\"token operator\">=</span> X_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    test_size <span class=\"token operator\">=</span> X_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    \n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'\\n#{0} êµì°¨ ê²€ì¦ ì •í™•ë„ : {1}, í•™ìŠµ ë°ì´í„° í¬ê¸°: {2}, ê²€ì¦ ë°ì´í„° í¬ê¸°\" {3}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span> acc<span class=\"token punctuation\">,</span> train_size<span class=\"token punctuation\">,</span> test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'#{0} ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:{1}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span>test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    \n    cv_accuracy<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>acc<span class=\"token punctuation\">)</span>\n    \n<span class=\"token comment\"># ê°œë³„ iterë³„ ì •í™•ë„ í‰ê·  ê³„ì‚°</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'\\n í‰ê·  ê²€ì¦ ì •í™•ë„:'</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>cv_accuracy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[20:57:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#1 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.863, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#1 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n[20:57:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#2 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.867, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#2 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n[20:57:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#3 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.865, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#3 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n[20:57:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#4 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.872, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#4 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n[20:57:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n#5 êµì°¨ ê²€ì¦ ì •í™•ë„ : 0.866, í•™ìŠµ ë°ì´í„° í¬ê¸°: 26048, ê²€ì¦ ë°ì´í„° í¬ê¸°\" [   0    1    2 ... 6509 6510 6511]\n#5 ê²€ì¦ ì…‹ ì¸ë±ìŠ¤:[   0    1    2 ... 6509 6510 6511]\n\n í‰ê·  ê²€ì¦ ì •í™•ë„: 0.867</code></pre></div>\n<h4 id=\"cross_val_score\" style=\"position:relative;\"><a href=\"#cross_val_score\" aria-label=\"cross_val_score permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cross_val_score</h4>\n<p>ìœ„ì˜ KFold, StratifiedKFoldì™€ ê°™ì€ ë°©ì‹ë„ ìˆì§€ë§Œ ë” í¸í•˜ê²Œ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ corss_val_score()ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cross_val_score<span class=\"token punctuation\">(</span>\n    estimator<span class=\"token punctuation\">,</span> <span class=\"token comment\"># ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤ (clf)</span>\n    X<span class=\"token punctuation\">,</span> <span class=\"token comment\"># features</span>\n    y<span class=\"token punctuation\">,</span> <span class=\"token comment\"># label</span>\n    scoring<span class=\"token punctuation\">,</span> <span class=\"token comment\"># evaluation</span>\n    cv <span class=\"token comment\"># k-fold</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> cross_val_score\n\nscore <span class=\"token operator\">=</span>cross_val_score<span class=\"token punctuation\">(</span>xgbclf<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> scoring<span class=\"token operator\">=</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">,</span> cv<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'\\n í‰ê·  ê²€ì¦ ì •í™•ë„:'</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>score<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[20:57:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[20:57:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[20:57:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[20:57:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[20:57:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n\n í‰ê·  ê²€ì¦ ì •í™•ë„: 0.866</code></pre></div>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html\">https://scikit-learn.org/stable/modules/cross_validation.html</a></p>","excerpt":"êµì°¨ ê²€ì¦ ê³ ì •ëœ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€ë¥¼ í•˜ë©´ ê³¼ì í•©ì˜ ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ êµì°¨ê²€ì¦ì´ë¼ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•œë‹¤. K-Fold í•™ìŠµ ë°ì´í„°ë¥¼ K ê°œì˜ Foldë¡œ ë‚˜ëˆ„ê³  ë‚˜ëˆ„ì–´ì§„ í´ë“œ ì¤‘ í•˜ë‚˜ë¥¼ ê²€ì¦ìš©, ë‚˜ë¨¸ì§€ë¥¼ í•™ìŠµìš©ìœ¼ë¡œ ì„ ì •í•œ ë’¤ ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ ê²€ì¦ìš© í´ë“œë¥¼ ë³€ê²½í•˜ë©´ì„œ í•™ìŠµê³¼ ê²€ì¦ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒ.  ëŒ€í‘œì ì¸ í´ë˜ìŠ¤ë¡œ KFold, Stratified k-fold, Cross_val_scoreê°€ ìˆë‹¤. ì˜ˆì‹œ: ì¤‘ì‚°ì¸µ ë¶„ë¥˜í•˜ê¸° ë°ì´í„°ì…‹ ì¤€ë¹„ K-Fold Stratified k-fold ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ targetê°’ì´ ë¶ˆê· í˜•í•œ ë¶„í¬ë¥¼ ê°€ì§„ ë°ì´í„° ì§‘í•©ì„ ìœ„í•œ ë°©ì‹ìœ¼ë¡œ target ë¶„í¬ì™€ ë¹„ìŠ·í•œ ë¹„ìœ¨ (ì˜ˆì œì˜ ê²½ìš° 3:1)ë¡œ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ë¶„ë°°í•œë‹¤.  Cross_val_score ìœ„ì˜ KFold, StratifiedKFoldì™€ ê°™ì€ ë°©ì‹ë„ ìˆì§€ë§Œ ë” í¸í•˜ê²Œ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ corss_val_score()ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²• Reâ€¦","frontmatter":{"date":"September 14, 2022","title":"Cross_Validation","categories":"ML","author":"HwanHee Park","emoji":"ğŸ“"},"fields":{"slug":"/[ML] Cross_Validation/[ML] Cross_Validation/"}},"next":{"id":"e47b0147-862b-5b04-8e95-af2e4574f2d1","html":"<p>ì´ë²ˆ ì¥ì—ì„œëŠ” ì „ ì¥ì—ì„œ ì§„í–‰í•œ ìë£Œë¥¼ ê°€ì§€ê³  Pysparkì˜ ML ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ íì—… ê°€ëŠ¥í™•ë¥ ì„ ì•Œì•„ë³´ì</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pyspark\n<span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>sql <span class=\"token keyword\">import</span> SparkSession\n<span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>functions <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">import</span> warnings\nwarnings<span class=\"token punctuation\">.</span>filterwarnings<span class=\"token punctuation\">(</span><span class=\"token string\">'ignore'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> matplotlib <span class=\"token keyword\">import</span> font_manager<span class=\"token punctuation\">,</span>rc\n<span class=\"token keyword\">import</span> matplotlib\n\nfont_path <span class=\"token operator\">=</span> <span class=\"token string\">'C:\\\\Windows\\\\Fonts\\\\gulim.ttc'</span>\n\n<span class=\"token comment\">#í°íŠ¸ ì´ë¦„ ì–»ì–´ì˜¤ê¸°</span>\nfont_name <span class=\"token operator\">=</span> font_manager<span class=\"token punctuation\">.</span>FontProperties<span class=\"token punctuation\">(</span>fname<span class=\"token operator\">=</span>font_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>get_name<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#font ì„¤ì •</span>\nmatplotlib<span class=\"token punctuation\">.</span>rc<span class=\"token punctuation\">(</span><span class=\"token string\">'font'</span><span class=\"token punctuation\">,</span>family<span class=\"token operator\">=</span>font_name<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># SparkSession</span>\nspark <span class=\"token operator\">=</span>  pyspark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>SparkSession \\\n         <span class=\"token punctuation\">.</span>builder \\\n         <span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">(</span><span class=\"token string\">\"spark.driver.extraClassPath\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">r\"C:\\\\Program Files\\\\PostgreSQL\\\\14\\\\bin\\\\postgresql-42.3.3.jar\"</span><span class=\"token punctuation\">)</span> \\\n         <span class=\"token punctuation\">.</span>getOrCreate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">lodge <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"C:\\\\Users\\\\USER\\\\Desktop\\\\Analysis\\\\Proceed\\\\Spark\\\\lodge_analysis\\\\lodge_analysis.csv\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">lodge</code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ë²ˆí˜¸</th>\n      <th>ê°œë°©ì„œë¹„ìŠ¤ëª…</th>\n      <th>ì‚¬ì—…ì¥ëª…</th>\n      <th>ì§€ì—­</th>\n      <th>ìƒì„¸ì˜ì—…ìƒíƒœëª…</th>\n      <th>ì¸í—ˆê°€ì¼ì</th>\n      <th>íì—…ì¼ì</th>\n      <th>ê°±ì‹ ì¼ì</th>\n      <th>ë©´ì </th>\n      <th>ìš´ì˜ê¸°ê°„</th>\n      <th>start_year</th>\n      <th>end_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39267</td>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ì‚°í˜¸ì¥ì—¬ê´€</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>19780731</td>\n      <td>20030331</td>\n      <td>2021-07</td>\n      <td>77.17</td>\n      <td>25.0</td>\n      <td>1978</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39268</td>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ìƒˆí•œì—¬ê´€</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>19800220</td>\n      <td>20071218</td>\n      <td>2021-07</td>\n      <td>272.00</td>\n      <td>27.0</td>\n      <td>1980</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39269</td>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ì‚¼ì„±</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>19700811</td>\n      <td>19990123</td>\n      <td>2021-07</td>\n      <td>86.94</td>\n      <td>29.0</td>\n      <td>1970</td>\n      <td>1999</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>39270</td>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ìŠ¹ì •ì›</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>20120625</td>\n      <td>20171214</td>\n      <td>2021-07</td>\n      <td>292.50</td>\n      <td>5.0</td>\n      <td>2012</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39271</td>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ì—ìŠ¤ëª¨í…”</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>20030116</td>\n      <td>20160125</td>\n      <td>2021-07</td>\n      <td>351.80</td>\n      <td>13.0</td>\n      <td>2003</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67323</th>\n      <td>618</td>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>ìº í•‘ìŠ¤íƒ€</td>\n      <td>ì œì£¼ì‹œ</td>\n      <td>íì—…</td>\n      <td>20160308</td>\n      <td>20220311</td>\n      <td>2019-10</td>\n      <td>335.00</td>\n      <td>6.0</td>\n      <td>2016</td>\n      <td>2022</td>\n    </tr>\n    <tr>\n      <th>67324</th>\n      <td>619</td>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>ì§€ë¦¬ì‚° í˜¸ìˆ˜ê³µì› ì˜¤í† ìº í•‘ì¥</td>\n      <td>êµ¬ë¡€êµ°</td>\n      <td>íì—…</td>\n      <td>20200909</td>\n      <td>20220311</td>\n      <td>2021-05</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>2020</td>\n      <td>2022</td>\n    </tr>\n    <tr>\n      <th>67325</th>\n      <td>620</td>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>ë§ˆë¦°ì˜¤í† ìº í•‘ì¥</td>\n      <td>íƒœì•ˆêµ°</td>\n      <td>íì—…</td>\n      <td>20160624</td>\n      <td>20161018</td>\n      <td>2018-08</td>\n      <td>335.00</td>\n      <td>0.0</td>\n      <td>2016</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>67326</th>\n      <td>621</td>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>ëª…ì‚¬ì‹­ë¦¬ ì‹ ë¦¬ì•¼ì˜ì¥</td>\n      <td>ì™„ë„êµ°</td>\n      <td>íì—…</td>\n      <td>20190722</td>\n      <td>20190826</td>\n      <td>2019-08</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>2019</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>67327</th>\n      <td>622</td>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>ì¸ì œë‚˜ë¥´ìƒ¤íŒŒí¬ ìº í•‘ì¥</td>\n      <td>ì¸ì œêµ°</td>\n      <td>íì—…</td>\n      <td>20160602</td>\n      <td>20200507</td>\n      <td>2020-05</td>\n      <td>335.00</td>\n      <td>4.0</td>\n      <td>2016</td>\n      <td>2020</td>\n    </tr>\n  </tbody>\n</table>\n<p>67328 rows Ã— 12 columns</p>\n</div>\n<h3 id=\"ë³€ìˆ˜-ì„ íƒ-ë°-ë³€í™˜\" style=\"position:relative;\"><a href=\"#%EB%B3%80%EC%88%98-%EC%84%A0%ED%83%9D-%EB%B0%8F-%EB%B3%80%ED%99%98\" aria-label=\"ë³€ìˆ˜ ì„ íƒ ë° ë³€í™˜ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ë³€ìˆ˜ ì„ íƒ ë° ë³€í™˜</h3>\n<ol>\n<li>ë¶ˆí•„ìš”í•œ ì¹¼ëŸ¼ ì œì™¸ (ë²ˆí˜¸, ì‚¬ì—…ì¥ëª…, start_year, end_year)</li>\n<li>ë‚ ì§œí˜•ìœ¼ë¡œ ë°ì´í„° ë³€í™˜</li>\n<li>Label Encoding</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">## ê³¼ì • 2 ì§„í–‰ ì¤‘ date ë²”ìœ„ ì˜¤ë¥˜ê°’ ìˆ˜ì •</span>\n<span class=\"token comment\"># ì¸í—ˆê°€ì¼ì</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">19970230</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">19970228</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">19750229</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">19750228</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">19940431</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">19940430</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">19840431</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">19840430</span>\n\n<span class=\"token comment\"># íì—…ì¼ì</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">20020230</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">20020228</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">20020231</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">20020228</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">20140000</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">20140101</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">20000300</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">20000301</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">20020400</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">20020401</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">19990900</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">19990901</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">20000900</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">20000901</span>\nlodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>lodge<span class=\"token punctuation\">[</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">19970230</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">19970228</span>\n\ndata <span class=\"token operator\">=</span> lodge\n\n<span class=\"token comment\"># ë¶ˆí•„ìš”í•œ ì¹¼ëŸ¼ ì œì™¸</span>\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'ë²ˆí˜¸'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'ì‚¬ì—…ì¥ëª…'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'start_year'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'end_year'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#-------- ë‚ ì§œí˜•ìœ¼ë¡œ ë°ì´í„° ë³€í™˜ ------------</span>\n<span class=\"token comment\"># ì•½ê°„ ì§€ì €ë¶„í•œ ë°©ì‹ìœ¼ë¡œ ë‚ ì§œí˜• ë°ì´í„°ë¡œ ì „í™˜</span>\n<span class=\"token comment\"># 1. int-> str ë³€í™˜</span>\n<span class=\"token comment\"># 2. str.slice í•¨ìˆ˜ ì‚¬ìš©í•˜ì—¬ ë…„ë„,ì›”,ì¼ë¡œ ë‚˜ëˆ”</span>\n<span class=\"token comment\"># 3. ë‚˜ëˆ ì§„ ì¹¼ëŸ¼ì„ to_datetimeìœ¼ë¡œ ë‚ ì§œí˜•ë°ì´í„°ë¡œ ë³€í™˜</span>\n<span class=\"token comment\"># 1~3 ê³¼ì •ì—ì„œ ë°œìƒí•œ ì„ì‹œ ì¹¼ëŸ¼ ì‚­ì œ</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">make_datetime</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">,</span>col<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    df<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'str'</span><span class=\"token punctuation\">)</span>\n    temp <span class=\"token operator\">=</span> df\n    temp <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>temp<span class=\"token punctuation\">)</span>\n    temp<span class=\"token punctuation\">[</span><span class=\"token string\">'y'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> temp<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">slice</span><span class=\"token punctuation\">(</span>start<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> stop<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n    temp<span class=\"token punctuation\">[</span><span class=\"token string\">'m'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> temp<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">slice</span><span class=\"token punctuation\">(</span>start<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> stop<span class=\"token operator\">=</span><span class=\"token number\">6</span><span class=\"token punctuation\">)</span>\n    temp<span class=\"token punctuation\">[</span><span class=\"token string\">'d'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> temp<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">slice</span><span class=\"token punctuation\">(</span>start<span class=\"token operator\">=</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> stop<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span>\n    \n    temp<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> temp<span class=\"token punctuation\">[</span><span class=\"token string\">'y'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">+</span><span class=\"token string\">\"-\"</span><span class=\"token operator\">+</span>temp<span class=\"token punctuation\">[</span><span class=\"token string\">'m'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">+</span><span class=\"token string\">\"-\"</span><span class=\"token operator\">+</span>temp<span class=\"token punctuation\">[</span><span class=\"token string\">'d'</span><span class=\"token punctuation\">]</span>\n    temp<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>to_datetime<span class=\"token punctuation\">(</span>temp<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    \n    df<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> temp<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">make_datetime<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">make_datetime<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'y'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'m'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'d'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\ndata</code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ê°œë°©ì„œë¹„ìŠ¤ëª…</th>\n      <th>ì§€ì—­</th>\n      <th>ìƒì„¸ì˜ì—…ìƒíƒœëª…</th>\n      <th>ì¸í—ˆê°€ì¼ì</th>\n      <th>íì—…ì¼ì</th>\n      <th>ê°±ì‹ ì¼ì</th>\n      <th>ë©´ì </th>\n      <th>ìš´ì˜ê¸°ê°„</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>1978-07-31</td>\n      <td>2003-03-31</td>\n      <td>2021-07</td>\n      <td>77.17</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>1980-02-20</td>\n      <td>2007-12-18</td>\n      <td>2021-07</td>\n      <td>272.00</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>1970-08-11</td>\n      <td>1999-01-23</td>\n      <td>2021-07</td>\n      <td>86.94</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>2012-06-25</td>\n      <td>2017-12-14</td>\n      <td>2021-07</td>\n      <td>292.50</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ìˆ™ë°•ì—…</td>\n      <td>ì°½ì›ì‹œ</td>\n      <td>íì—…</td>\n      <td>2003-01-16</td>\n      <td>2016-01-25</td>\n      <td>2021-07</td>\n      <td>351.80</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67323</th>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>ì œì£¼ì‹œ</td>\n      <td>íì—…</td>\n      <td>2016-03-08</td>\n      <td>2022-03-11</td>\n      <td>2019-10</td>\n      <td>335.00</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>67324</th>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>êµ¬ë¡€êµ°</td>\n      <td>íì—…</td>\n      <td>2020-09-09</td>\n      <td>2022-03-11</td>\n      <td>2021-05</td>\n      <td>0.00</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>67325</th>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>íƒœì•ˆêµ°</td>\n      <td>íì—…</td>\n      <td>2016-06-24</td>\n      <td>2016-10-18</td>\n      <td>2018-08</td>\n      <td>335.00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>67326</th>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>ì™„ë„êµ°</td>\n      <td>íì—…</td>\n      <td>2019-07-22</td>\n      <td>2019-08-26</td>\n      <td>2019-08</td>\n      <td>0.00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>67327</th>\n      <td>ìë™ì°¨ì•¼ì˜ì¥ì—…</td>\n      <td>ì¸ì œêµ°</td>\n      <td>íì—…</td>\n      <td>2016-06-02</td>\n      <td>2020-05-07</td>\n      <td>2020-05</td>\n      <td>335.00</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>67328 rows Ã— 8 columns</p>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>sort_values<span class=\"token punctuation\">(</span>by<span class=\"token operator\">=</span><span class=\"token string\">\"ê°œë°©ì„œë¹„ìŠ¤ëª…\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># ë³¸ê²©ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ì„ í•˜ê¸° ìœ„í•´ 0ìœ¼ë¡œ ì§€ì •í•œ ê°’(null)ì„ ì¤‘ê°„ê°’ìœ¼ë¡œ ê°’ì„ ëŒ€ì²´</span>\n\n<span class=\"token comment\">#data['ìš´ì˜ê¸°ê°„'][data['ìš´ì˜ê¸°ê°„'] ==0] = 17</span>\n\n<span class=\"token comment\">#data['ë©´ì '][data['ë©´ì '] == 0 ] = 335</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data</code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ê°œë°©ì„œë¹„ìŠ¤ëª…</th>\n      <th>ì§€ì—­</th>\n      <th>ìƒì„¸ì˜ì—…ìƒíƒœëª…</th>\n      <th>ì¸í—ˆê°€ì¼ì</th>\n      <th>íì—…ì¼ì</th>\n      <th>ê°±ì‹ ì¼ì</th>\n      <th>ë©´ì </th>\n      <th>ìš´ì˜ê¸°ê°„</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>54601</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>55414</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>55416</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>55419</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>65386</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65176</th>\n      <td>í•œì˜¥ì²´í—˜ì—…</td>\n      <td>ê°•ì§„êµ°</td>\n      <td>ì˜ì—…</td>\n      <td>2013-11-30</td>\n      <td>2022-03-11</td>\n      <td>2021-07</td>\n      <td>117.41</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>65177</th>\n      <td>í•œì˜¥ì²´í—˜ì—…</td>\n      <td>ê²½ì£¼ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2019-07-02</td>\n      <td>2022-03-11</td>\n      <td>2021-07</td>\n      <td>335.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>65178</th>\n      <td>í•œì˜¥ì²´í—˜ì—…</td>\n      <td>ì„œìš¸íŠ¹ë³„ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2021-07-05</td>\n      <td>2022-03-11</td>\n      <td>2021-07</td>\n      <td>335.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>65180</th>\n      <td>í•œì˜¥ì²´í—˜ì—…</td>\n      <td>ê°•ì§„êµ°</td>\n      <td>ì˜ì—…</td>\n      <td>2013-12-02</td>\n      <td>2022-03-11</td>\n      <td>2021-07</td>\n      <td>95.58</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>65053</th>\n      <td>í•œì˜¥ì²´í—˜ì—…</td>\n      <td>ì „ì£¼ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2013-11-06</td>\n      <td>2022-03-11</td>\n      <td>2021-11</td>\n      <td>335.00</td>\n      <td>9.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>67328 rows Ã— 8 columns</p>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ê°œë°©ì„œë¹„ìŠ¤ëª…</th>\n      <th>ì§€ì—­</th>\n      <th>ìƒì„¸ì˜ì—…ìƒíƒœëª…</th>\n      <th>ì¸í—ˆê°€ì¼ì</th>\n      <th>íì—…ì¼ì</th>\n      <th>ê°±ì‹ ì¼ì</th>\n      <th>ë©´ì </th>\n      <th>ìš´ì˜ê¸°ê°„</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>54601</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>55414</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>55416</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>55419</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>65386</th>\n      <td>0</td>\n      <td>999</td>\n      <td>íì—…</td>\n      <td>1948-08-15</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>61838</th>\n      <td>General Campground</td>\n      <td>0</td>\n      <td>ì˜ì—…</td>\n      <td>1948-08-15</td>\n      <td>1948-08-15</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>59790</th>\n      <td>Resort Condominium</td>\n      <td>0</td>\n      <td>ì˜ì—…</td>\n      <td>1948-08-15</td>\n      <td>1948-08-15</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>60027</th>\n      <td>Resort Condominium</td>\n      <td>999</td>\n      <td>ì˜ì—…</td>\n      <td>1999-12-31</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>57840</th>\n      <td>TOURIST HOTEL</td>\n      <td>999</td>\n      <td>ì˜ì—…</td>\n      <td>1999-12-31</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>60575</th>\n      <td>Tourist Accommodation Business</td>\n      <td>999</td>\n      <td>ì˜ì—…</td>\n      <td>1999-12-31</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>64112</th>\n      <td>Traditional Korean</td>\n      <td>999</td>\n      <td>ì˜ì—…</td>\n      <td>1999-12-31</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>64879</th>\n      <td>Traditional Korean housing experiencing business</td>\n      <td>999</td>\n      <td>ì˜ì—…</td>\n      <td>1999-12-31</td>\n      <td>2022-03-11</td>\n      <td>2022-03</td>\n      <td>335.00</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>58137</th>\n      <td>ê´€ê´‘ìˆ™ë°•ì—…</td>\n      <td>í‰ì°½êµ°</td>\n      <td>íì—…</td>\n      <td>1997-03-14</td>\n      <td>2006-08-31</td>\n      <td>2018-08</td>\n      <td>0.00</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>59038</th>\n      <td>ê´€ê´‘ìˆ™ë°•ì—…</td>\n      <td>ë¶€ì‚°ê´‘ì—­ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2016-09-27</td>\n      <td>2022-03-11</td>\n      <td>2018-12</td>\n      <td>218.85</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>59039</th>\n      <td>ê´€ê´‘ìˆ™ë°•ì—…</td>\n      <td>ë¶€ì‚°ê´‘ì—­ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2016-12-30</td>\n      <td>2022-03-11</td>\n      <td>2021-10</td>\n      <td>624.75</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>59042</th>\n      <td>ê´€ê´‘ìˆ™ë°•ì—…</td>\n      <td>ë¶€ì‚°ê´‘ì—­ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2017-03-15</td>\n      <td>2022-03-11</td>\n      <td>2021-08</td>\n      <td>225.16</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>59041</th>\n      <td>ê´€ê´‘ìˆ™ë°•ì—…</td>\n      <td>ë¶€ì‚°ê´‘ì—­ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2017-02-03</td>\n      <td>2022-03-11</td>\n      <td>2020-02</td>\n      <td>313.04</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>59043</th>\n      <td>ê´€ê´‘ìˆ™ë°•ì—…</td>\n      <td>ë¶€ì‚°ê´‘ì—­ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2017-03-31</td>\n      <td>2022-03-11</td>\n      <td>2022-01</td>\n      <td>1382.35</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>59044</th>\n      <td>ê´€ê´‘ìˆ™ë°•ì—…</td>\n      <td>ë¶€ì‚°ê´‘ì—­ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2017-06-01</td>\n      <td>2022-03-11</td>\n      <td>2019-02</td>\n      <td>169.63</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>59045</th>\n      <td>ê´€ê´‘ìˆ™ë°•ì—…</td>\n      <td>ë¶€ì‚°ê´‘ì—­ì‹œ</td>\n      <td>ì˜ì—…</td>\n      <td>2017-07-03</td>\n      <td>2022-03-11</td>\n      <td>2018-12</td>\n      <td>246.27</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token number\">12</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data<span class=\"token punctuation\">.</span>to_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"C:\\\\Users\\\\USER\\\\Desktop\\\\Analysis\\\\Proceed\\\\Spark\\\\lodge_analysis\\\\dataset.csv\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'cp949'</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>sql <span class=\"token keyword\">import</span> SparkSession\n<span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>functions <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n\n<span class=\"token comment\"># SparkSession ê°ì²´ ìƒì„±</span>\nspark <span class=\"token operator\">=</span> SparkSession\\\n        <span class=\"token punctuation\">.</span>builder\\\n        <span class=\"token punctuation\">.</span>appName<span class=\"token punctuation\">(</span><span class=\"token string\">'PySpark ML for Loging Industry'</span><span class=\"token punctuation\">)</span>\\\n        <span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">(</span><span class=\"token string\">'spark.some.config.option'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'some-value'</span><span class=\"token punctuation\">)</span>\\\n        <span class=\"token punctuation\">.</span>getOrCreate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span>csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"C:\\\\Users\\\\USER\\\\Desktop\\\\Analysis\\\\Proceed\\\\Spark\\\\lodge_analysis\\\\dataset.csv\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'cp949'</span><span class=\"token punctuation\">,</span>inferSchema <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> header <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">+------------+----------+--------------+----------+----------+--------+-------+--------+\n|ê°œë°©ì„œë¹„ìŠ¤ëª…|      ì§€ì—­|ìƒì„¸ì˜ì—…ìƒíƒœëª…|ì¸í—ˆê°€ì¼ì|  íì—…ì¼ì|ê°±ì‹ ì¼ì|   ë©´ì |ìš´ì˜ê¸°ê°„|\n+------------+----------+--------------+----------+----------+--------+-------+--------+\n|  ê´€ê´‘ìˆ™ë°•ì—…|    í‰ì°½êµ°|          íì—…|1997-03-14|2006-08-31| 2018-08|    0.0|     9.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-09-27|2022-03-11| 2018-12| 218.85|     6.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-12-30|2022-03-11| 2021-10| 624.75|     6.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-03-15|2022-03-11| 2021-08| 225.16|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-02-03|2022-03-11| 2020-02| 313.04|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-03-31|2022-03-11| 2022-01|1382.35|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-06-01|2022-03-11| 2019-02| 169.63|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-07-03|2022-03-11| 2018-12| 246.27|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-07-04|2022-03-11| 2018-11| 206.16|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-12-30|2022-03-11| 2018-08|    0.0|     6.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-09-19|2022-03-11| 2018-08| 129.96|     6.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-12-28|2022-03-11| 2020-12| 279.23|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-09-18|2022-03-11| 2021-05| 120.07|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-08-31|2022-03-11| 2019-04| 207.99|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-07-10|2022-03-11| 2020-08|  178.2|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-11-14|2022-03-11| 2020-11| 108.39|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-11-16|2022-03-11| 2020-09|  335.0|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-09-16|2022-03-11| 2021-10| 195.89|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-07-27|2022-03-11| 2021-02| 375.16|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-06-12|2022-03-11| 2021-06|    0.0|     7.0|\n+------------+----------+--------------+----------+----------+--------+-------+--------+\nonly showing top 20 rows</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span>orderBy<span class=\"token punctuation\">(</span><span class=\"token string\">\"ì¸í—ˆê°€ì¼ì\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">+------------+----------+--------------+----------+----------+--------+------+--------+\n|ê°œë°©ì„œë¹„ìŠ¤ëª…|      ì§€ì—­|ìƒì„¸ì˜ì—…ìƒíƒœëª…|ì¸í—ˆê°€ì¼ì|  íì—…ì¼ì|ê°±ì‹ ì¼ì|  ë©´ì |ìš´ì˜ê¸°ê°„|\n+------------+----------+--------------+----------+----------+--------+------+--------+\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1948-08-15|1967-07-10| 2018-08| 335.0|    19.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1948-08-15|2001-07-07| 2018-08| 335.0|    53.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1948-08-15|2015-12-03| 2018-08| 148.5|    67.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1948-08-15|2001-02-01| 2018-08| 335.0|    53.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1948-08-15|1975-09-18| 2018-08| 335.0|    27.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1948-08-15|1972-07-31| 2018-08| 335.0|    24.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          ì˜ì—…|1948-08-15|2022-03-11| 2019-12|144.93|    74.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1948-08-15|2000-06-15| 2018-08| 335.0|    52.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1948-08-15|2001-05-17| 2018-08| 335.0|    53.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          ì˜ì—…|1948-08-15|2022-03-11| 2018-10| 907.0|    74.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1948-08-15|1948-08-15| 2018-08| 335.0|     0.0|\n|      ìˆ™ë°•ì—…|ì„œìš¸íŠ¹ë³„ì‹œ|          íì—…|1949-07-05|2006-03-27| 2018-08| 165.0|    57.0|\n|      ìˆ™ë°•ì—…|ì¸ì²œê´‘ì—­ì‹œ|          íì—…|1952-04-13|2018-08-28| 2018-10| 335.0|    66.0|\n|      ìˆ™ë°•ì—…|    ê²½ì£¼ì‹œ|          íì—…|1954-01-31|1991-07-05| 2018-08|500.96|    37.0|\n|      ìˆ™ë°•ì—…|    ì˜ê´‘êµ°|          íì—…|1954-02-08|2006-10-18| 2018-08|  88.0|    52.0|\n|      ìˆ™ë°•ì—…|    í•´ë‚¨êµ°|          íì—…|1955-01-20|2002-05-02| 2018-08| 335.0|    47.0|\n|      ìˆ™ë°•ì—…|    ì°½ì›ì‹œ|          íì—…|1955-06-14|1999-03-02| 2021-07|166.77|    44.0|\n|      ìˆ™ë°•ì—…|    ê²½ì£¼ì‹œ|          ì˜ì—…|1957-04-19|2022-03-11| 2021-02| 335.0|    65.0|\n|      ìˆ™ë°•ì—…|    ì°½ì›ì‹œ|          íì—…|1958-04-28|2018-01-24| 2021-07| 63.46|    60.0|\n|      ìˆ™ë°•ì—…|    ì°½ì›ì‹œ|          ì˜ì—…|1958-05-19|2022-03-11| 2021-07| 74.04|    64.0|\n+------------+----------+--------------+----------+----------+--------+------+--------+\nonly showing top 20 rows</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span>orderBy<span class=\"token punctuation\">(</span><span class=\"token string\">\"ê°œë°©ì„œë¹„ìŠ¤ëª…\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">+------------+----------+--------------+----------+----------+--------+-------+--------+\n|ê°œë°©ì„œë¹„ìŠ¤ëª…|      ì§€ì—­|ìƒì„¸ì˜ì—…ìƒíƒœëª…|ì¸í—ˆê°€ì¼ì|  íì—…ì¼ì|ê°±ì‹ ì¼ì|   ë©´ì |ìš´ì˜ê¸°ê°„|\n+------------+----------+--------------+----------+----------+--------+-------+--------+\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-06-12|2022-03-11| 2021-06|    0.0|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-12-28|2022-03-11| 2020-12| 279.23|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-07-27|2022-03-11| 2021-02| 375.16|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-06-01|2022-03-11| 2019-02| 169.63|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-09-19|2022-03-11| 2018-08| 129.96|     6.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-07-10|2022-03-11| 2020-08|  178.2|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-09-16|2022-03-11| 2021-10| 195.89|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-12-30|2022-03-11| 2021-10| 624.75|     6.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-03-31|2022-03-11| 2022-01|1382.35|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-07-04|2022-03-11| 2018-11| 206.16|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-12-30|2022-03-11| 2018-08|    0.0|     6.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-09-18|2022-03-11| 2021-05| 120.07|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-08-31|2022-03-11| 2019-04| 207.99|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-11-14|2022-03-11| 2020-11| 108.39|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2015-11-16|2022-03-11| 2020-09|  335.0|     7.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|    í‰ì°½êµ°|          íì—…|1997-03-14|2006-08-31| 2018-08|    0.0|     9.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-09-27|2022-03-11| 2018-12| 218.85|     6.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-03-15|2022-03-11| 2021-08| 225.16|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-02-03|2022-03-11| 2020-02| 313.04|     5.0|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-07-03|2022-03-11| 2018-12| 246.27|     5.0|\n+------------+----------+--------------+----------+----------+--------+-------+--------+\nonly showing top 20 rows</code></pre></div>\n<h3 id=\"ë²”ì£¼í˜•-ë³€ìˆ˜-ì²˜ë¦¬í•˜ê¸°\" style=\"position:relative;\"><a href=\"#%EB%B2%94%EC%A3%BC%ED%98%95-%EB%B3%80%EC%88%98-%EC%B2%98%EB%A6%AC%ED%95%98%EA%B8%B0\" aria-label=\"ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬í•˜ê¸° permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬í•˜ê¸°</h3>\n<p>ì•„ë˜ëŠ” ì´ 3ê°€ì§€ ê³¼ì •ìœ¼ë¡œ ì§„í–‰</p>\n<ol>\n<li>StringIndexer</li>\n</ol>\n<p>ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì¸ë±ì‹±í•˜ì—¬ 0.0 , 1.0, 2.0 ê³¼ ê°™ì€ ë²ˆí˜¸ë¡œ ì¸ë±ì‹±</p>\n<ol start=\"2\">\n<li>OneHotEncoder</li>\n</ol>\n<p>ì¸ë±ì‹±í•œ ê°’ì€ 0,1,2 ì™€ ê°™ì´ ê°’ìœ¼ë¡œì¨ í¬ê¸°ë¥¼ ê°€ì§€ê¸° ë•Œë¬¸ì— OneHotEncoderë¥¼ ì‚¬ìš©í•˜ì—¬ ê°’ì˜ í¬ê¸°ë¥¼ ê°–ì§€ ì•Šë„ë¡ ë³€í™˜</p>\n<ol start=\"3\">\n<li>VectorAssembler</li>\n</ol>\n<p>ì¸ì½”ë”©í•œ ê°’ì„ ë²¡í„°ë¡œ ëª¨ìœ¼ê¸°</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>ml <span class=\"token keyword\">import</span> Pipeline\n<span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>ml<span class=\"token punctuation\">.</span>feature <span class=\"token keyword\">import</span> StringIndexer<span class=\"token punctuation\">,</span> OneHotEncoder<span class=\"token punctuation\">,</span> VectorAssembler\n\n<span class=\"token comment\"># ê°±ì‹ ì¼ì, ì¸í—ˆê°€ì¼ì, íì—…ì¼ìë¥¼ ì œì™¸í•˜ê³  ë‹¤ì‹œ ì§„í–‰</span>\ncategory_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'ê°œë°©ì„œë¹„ìŠ¤ëª…'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'ì§€ì—­'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'ì¸í—ˆê°€ì¼ì'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'íì—…ì¼ì'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'ê°±ì‹ ì¼ì'</span><span class=\"token punctuation\">]</span>\nnumeric_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'ë©´ì '</span><span class=\"token punctuation\">,</span><span class=\"token string\">'ìš´ì˜ê¸°ê°„'</span><span class=\"token punctuation\">]</span>\n<span class=\"token comment\"># label</span>\nlabel_idx <span class=\"token operator\">=</span> StringIndexer<span class=\"token punctuation\">(</span>inputCol <span class=\"token operator\">=</span> <span class=\"token string\">\"ìƒì„¸ì˜ì—…ìƒíƒœëª…\"</span><span class=\"token punctuation\">,</span> outputCol<span class=\"token operator\">=</span> <span class=\"token string\">\"label\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ì„ ì¸ë±ì‹±</span>\nindexers <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    StringIndexer<span class=\"token punctuation\">(</span>inputCol<span class=\"token operator\">=</span>c<span class=\"token punctuation\">,</span> outputCol<span class=\"token operator\">=</span><span class=\"token string\">\"{0}_indexed\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> category_cols\n<span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># ì¸ë±ì‹±í•œ ë³€ìˆ˜ë“¤ì„ ì¸ì½”ë”©</span>\nencoders <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>OneHotEncoder<span class=\"token punctuation\">(</span>dropLast<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>inputCol<span class=\"token operator\">=</span>indexer<span class=\"token punctuation\">.</span>getOutputCol<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            outputCol<span class=\"token operator\">=</span><span class=\"token string\">\"{0}_encoded\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>indexer<span class=\"token punctuation\">.</span>getOutputCol<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> \n    <span class=\"token keyword\">for</span> indexer <span class=\"token keyword\">in</span> indexers\n<span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># ì¸ì½”ë”© ëœ ê°’ê³¼ ìˆ«ì ë³€ìˆ˜ ê°’ì„ ë²¡í„°í™”</span>\n<span class=\"token comment\"># -- encoderì™€ numeric cols ì˜ ê²°í•© ë¦¬ìŠ¤íŠ¸ ê´€ë ¨ ì§€ì‹ ë¶€ì¡±(Arrayë¡œ ì•ˆë¨)</span>\n\nassembler <span class=\"token operator\">=</span> VectorAssembler<span class=\"token punctuation\">(</span>inputCols<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'ê°œë°©ì„œë¹„ìŠ¤ëª…_indexed_encoded'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ì§€ì—­_indexed_encoded'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ì¸í—ˆê°€ì¼ì_indexed_encoded'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'íì—…ì¼ì_indexed_encoded'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ê°±ì‹ ì¼ì_indexed_encoded'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'ë©´ì '</span><span class=\"token punctuation\">,</span><span class=\"token string\">'ìš´ì˜ê¸°ê°„'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>outputCol<span class=\"token operator\">=</span><span class=\"token string\">\"features\"</span><span class=\"token punctuation\">)</span>\n\npipeline <span class=\"token operator\">=</span> Pipeline<span class=\"token punctuation\">(</span>stages<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>label_idx<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> indexers  <span class=\"token operator\">+</span> encoders<span class=\"token operator\">+</span><span class=\"token punctuation\">[</span>assembler<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token operator\">=</span>pipeline<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span>\ntransformed <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span>\ntransformed<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">+------------+----------+--------------+----------+----------+--------+------+--------+-----+--------------------+------------+------------------+----------------+----------------+----------------------------+--------------------+--------------------------+------------------------+------------------------+--------------------+\n|ê°œë°©ì„œë¹„ìŠ¤ëª…|      ì§€ì—­|ìƒì„¸ì˜ì—…ìƒíƒœëª…|ì¸í—ˆê°€ì¼ì|  íì—…ì¼ì|ê°±ì‹ ì¼ì|  ë©´ì |ìš´ì˜ê¸°ê°„|label|ê°œë°©ì„œë¹„ìŠ¤ëª…_indexed|ì§€ì—­_indexed|ì¸í—ˆê°€ì¼ì_indexed|íì—…ì¼ì_indexed|ê°±ì‹ ì¼ì_indexed|ê°œë°©ì„œë¹„ìŠ¤ëª…_indexed_encoded|ì§€ì—­_indexed_encoded|ì¸í—ˆê°€ì¼ì_indexed_encoded|íì—…ì¼ì_indexed_encoded|ê°±ì‹ ì¼ì_indexed_encoded|            features|\n+------------+----------+--------------+----------+----------+--------+------+--------+-----+--------------------+------------+------------------+----------------+----------------+----------------------------+--------------------+--------------------------+------------------------+------------------------+--------------------+\n|  ê´€ê´‘ìˆ™ë°•ì—…|    í‰ì°½êµ°|          íì—…|1997-03-14|2006-08-31| 2018-08|   0.0|     9.0|  1.0|                 2.0|        55.0|            1373.0|           244.0|             0.0|               (7,[2],[1.0])|    (163,[55],[1.0])|      (14963,[1373],[1.0])|      (6606,[244],[1.0])|          (44,[0],[1.0])|(21785,[2,62,1543...|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-09-27|2022-03-11| 2018-12|218.85|     6.0|  0.0|                 2.0|         1.0|             887.0|             0.0|            23.0|               (7,[2],[1.0])|     (163,[1],[1.0])|       (14963,[887],[1.0])|        (6606,[0],[1.0])|         (44,[23],[1.0])|(21785,[2,8,1057,...|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2016-12-30|2022-03-11| 2021-10|624.75|     6.0|  0.0|                 2.0|         1.0|             686.0|             0.0|             7.0|               (7,[2],[1.0])|     (163,[1],[1.0])|       (14963,[686],[1.0])|        (6606,[0],[1.0])|          (44,[7],[1.0])|(21785,[2,8,856,1...|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-03-15|2022-03-11| 2021-08|225.16|     5.0|  0.0|                 2.0|         1.0|            5201.0|             0.0|             4.0|               (7,[2],[1.0])|     (163,[1],[1.0])|      (14963,[5201],[1.0])|        (6606,[0],[1.0])|          (44,[4],[1.0])|(21785,[2,8,5371,...|\n|  ê´€ê´‘ìˆ™ë°•ì—…|ë¶€ì‚°ê´‘ì—­ì‹œ|          ì˜ì—…|2017-02-03|2022-03-11| 2020-02|313.04|     5.0|  0.0|                 2.0|         1.0|             536.0|             0.0|            20.0|               (7,[2],[1.0])|     (163,[1],[1.0])|       (14963,[536],[1.0])|        (6606,[0],[1.0])|         (44,[20],[1.0])|(21785,[2,8,706,1...|\n+------------+----------+--------------+----------+----------+--------+------+--------+-----+--------------------+------------+------------------+----------------+----------------+----------------------------+--------------------+--------------------------+------------------------+------------------------+--------------------+\nonly showing top 5 rows</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">trans_df <span class=\"token operator\">=</span> transformed<span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'features'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>ml<span class=\"token punctuation\">.</span>regression <span class=\"token keyword\">import</span> LinearRegression\n\nlr <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>LinearRegression<span class=\"token punctuation\">(</span>featuresCol<span class=\"token operator\">=</span><span class=\"token string\">'features'</span><span class=\"token punctuation\">,</span> labelCol<span class=\"token operator\">=</span><span class=\"token string\">\"label\"</span><span class=\"token punctuation\">,</span> predictionCol<span class=\"token operator\">=</span><span class=\"token string\">'predlabel'</span><span class=\"token punctuation\">,</span> \n                               maxIter<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> regParam<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> elasticNetParam<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span> standardization<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">trans_df<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  1.0|(21785,[2,62,1543...|\n|  0.0|(21785,[2,8,1057,...|\n|  0.0|(21785,[2,8,856,1...|\n|  0.0|(21785,[2,8,5371,...|\n|  0.0|(21785,[2,8,706,1...|\n|  0.0|(21785,[2,8,563,1...|\n|  0.0|(21785,[2,8,712,1...|\n|  0.0|(21785,[2,8,2325,...|\n|  0.0|(21785,[2,8,415,1...|\n|  0.0|(21785,[2,8,856,1...|\n|  0.0|(21785,[2,8,7123,...|\n|  0.0|(21785,[2,8,2337,...|\n|  0.0|(21785,[2,8,1336,...|\n|  0.0|(21785,[2,8,688,1...|\n|  0.0|(21785,[2,8,1376,...|\n|  0.0|(21785,[2,8,1073,...|\n|  0.0|(21785,[2,8,9370,...|\n|  0.0|(21785,[2,8,1335,...|\n|  0.0|(21785,[2,8,299,1...|\n|  0.0|(21785,[2,8,321,1...|\n+-----+--------------------+\nonly showing top 20 rows</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train_data<span class=\"token punctuation\">,</span> test_data <span class=\"token operator\">=</span> trans_df<span class=\"token punctuation\">.</span>randomSplit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">.7</span><span class=\"token punctuation\">,</span><span class=\"token number\">.3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> seed<span class=\"token operator\">=</span><span class=\"token number\">1234</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train_data<span class=\"token punctuation\">.</span>columns</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">['label', 'features']</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Fit the data to the model</span>\nlinearModel <span class=\"token operator\">=</span> lr<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_data<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">predictions <span class=\"token operator\">=</span> linearModel<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>test_data<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">predandlabels <span class=\"token operator\">=</span> predictions<span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span><span class=\"token string\">\"predlabel\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"label\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">predandlabels<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">+-------------------+-----+\n|          predlabel|label|\n+-------------------+-----+\n| 0.4786779491779273|  0.0|\n|0.47812190795718557|  0.0|\n| 0.4763438691699301|  0.0|\n|0.46373595776939147|  0.0|\n| 0.4621842148277867|  0.0|\n|  0.461957918982136|  0.0|\n|0.46163463920263503|  0.0|\n| 0.4564621627306192|  0.0|\n| 0.4530677250458588|  0.0|\n| 0.4522595255971063|  0.0|\n|0.45080476658935187|  0.0|\n| 0.4472567710093285|  0.0|\n|0.39633212374343496|  0.0|\n| 0.3614890291088182|  0.0|\n| 0.4700399134696608|  0.0|\n| 0.4727877915954192|  0.0|\n|0.46379414812970166|  0.0|\n|0.45904840096662713|  0.0|\n|0.44309292744935574|  0.0|\n| 0.3900524140266282|  0.0|\n+-------------------+-----+\nonly showing top 20 rows</code></pre></div>\n<h3 id=\"í‰ê°€\" style=\"position:relative;\"><a href=\"#%ED%8F%89%EA%B0%80\" aria-label=\"í‰ê°€ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>í‰ê°€</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>ml<span class=\"token punctuation\">.</span>evaluation <span class=\"token keyword\">import</span> RegressionEvaluator\n\n<span class=\"token comment\"># Get the RMSE</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"RMSE: {0}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>linearModel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>rootMeanSquaredError<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"MAE: {0}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>linearModel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>meanAbsoluteError<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Get the R2</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"R2: {0}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>linearModel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>r2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">RMSE: 0.5022262338134558\nMAE: 0.4878241107468986\nR2: 0.012063243903345677</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">evaluator <span class=\"token operator\">=</span> RegressionEvaluator<span class=\"token punctuation\">(</span>predictionCol<span class=\"token operator\">=</span><span class=\"token string\">\"predlabel\"</span><span class=\"token punctuation\">,</span> labelCol<span class=\"token operator\">=</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">,</span> metricName<span class=\"token operator\">=</span><span class=\"token string\">'rmse'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"RMSE: {0}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>evaluator<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>predandlabels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">RMSE: 0.5017870515976061</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">evaluator <span class=\"token operator\">=</span> RegressionEvaluator<span class=\"token punctuation\">(</span>predictionCol<span class=\"token operator\">=</span><span class=\"token string\">\"predlabel\"</span><span class=\"token punctuation\">,</span> labelCol<span class=\"token operator\">=</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">,</span> metricName<span class=\"token operator\">=</span><span class=\"token string\">'mae'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"MAE: {0}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>evaluator<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>predandlabels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">MAE: 0.4873217827313394</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">evaluator <span class=\"token operator\">=</span> RegressionEvaluator<span class=\"token punctuation\">(</span>predictionCol<span class=\"token operator\">=</span><span class=\"token string\">\"predlabel\"</span><span class=\"token punctuation\">,</span> labelCol<span class=\"token operator\">=</span><span class=\"token string\">'label'</span><span class=\"token punctuation\">,</span> metricName<span class=\"token operator\">=</span><span class=\"token string\">'r2'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"R2: {0}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>evaluator<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>predandlabels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">R2: 0.010070756230703637</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">spark<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"https://www.kaggle.com/code/fatmakursun/pyspark-ml-tutorial-for-beginners\">https://www.kaggle.com/code/fatmakursun/pyspark-ml-tutorial-for-beginners</a></p>\n<p><a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.OneHotEncoder.html\">https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.OneHotEncoder.html</a></p>\n<p><a href=\"https://medium.com/@nutanbhogendrasharma/role-of-onehotencoder-and-pipelines-in-pyspark-ml-feature-part-2-3275767e74f0\">https://medium.com/@nutanbhogendrasharma/role-of-onehotencoder-and-pipelines-in-pyspark-ml-feature-part-2-3275767e74f0</a></p>\n<p><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html\">https://spark.apache.org/docs/latest/ml-classification-regression.html</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#%EB%B3%80%EC%88%98-%EC%84%A0%ED%83%9D-%EB%B0%8F-%EB%B3%80%ED%99%98\">ë³€ìˆ˜ ì„ íƒ ë° ë³€í™˜</a></li>\n<li><a href=\"#%EB%B2%94%EC%A3%BC%ED%98%95-%EB%B3%80%EC%88%98-%EC%B2%98%EB%A6%AC%ED%95%98%EA%B8%B0\">ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬í•˜ê¸°</a></li>\n<li><a href=\"#%ED%8F%89%EA%B0%80\">í‰ê°€</a></li>\n<li><a href=\"#reference\">Reference</a></li>\n</ul>\n</div>","frontmatter":{"date":"April 21, 2022","title":"ìˆ™ë°•ì—… ë¶„ì„í•˜ê¸° (3) - MLlib","categories":"Data_Analysis","author":"HwanHee Park","emoji":"ğŸ‘¨â€ğŸ’»"},"fields":{"slug":"/PySpark/[PySpark] ìˆ™ë°•ì—… ë¶„ì„í•˜ê¸° (3) - MLlib/"}},"prev":null,"site":{"siteMetadata":{"siteUrl":"https://han-archives.github.io","comments":{"utterances":{"repo":"Han-Archives/han-archives.github.io"}}}}},"pageContext":{"slug":"/[ML] Cross_Validation/[ML] Cross_Validation/","nextSlug":"/PySpark/[PySpark] ìˆ™ë°•ì—… ë¶„ì„í•˜ê¸° (3) - MLlib/","prevSlug":""}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}