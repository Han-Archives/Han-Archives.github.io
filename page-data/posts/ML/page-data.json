{
    "componentChunkName": "component---src-templates-category-template-js",
    "path": "/posts/ML",
    "result": {"pageContext":{"currentCategory":"ML","categories":["All","DL","Study","Python","ML","Data_Analysis","Toy-Project"],"edges":[{"node":{"id":"1da14877-121f-5d56-a03c-9b3f289f64b0","excerpt":"추가 트리 알고리즘 소개 엑스트라 트리 알고리즘은 랜덤포레스트와 마찬가지로 결정 트리 기반의 알고리즘 랜덤포레스트 차이점 [1] 부트스트랩 방식을 사용하지 않고 전체데이터를 사용한다. [2] 노드를 분할 하는 임계점을 랜덤하게 선택한다. -> 결정트리 방식의 임계점은 불순도를 가장 낮추는 방향으로 분리하지만 추가 트리 알고리즘은 그렇지 않다. 임계점 랜덤 선택?? 임계점을 랜덤으로 선택하면 모델의 성능이 떨어지는 것이 아닌가 할 수 있지만 추가 트리 알고리즘은 앙상블 모델로써 여러 트리 모형 중 가장 좋은 성능의 트리를 선택하여 이를 보완할 수 있다. 랜덤 포레스트와 결정 트리의 경우 최적의 임계값을 계산하는 과정에 시간이 소요되지만 추가 트리 알고리즘은 무작위로 선택하기 때문에 시간이 적게 걸리며 랜덤 포레스트에 비해 더 많은 트리 구조를 활용할 수 있다는 장점이 있다. 예제 : 타이타닉 타이타닉 데이터셋을 통해 랜덤포레스트와 엑스트라트리 알고리즘의 성능을 비교해보자 추가 트리 …","fields":{"slug":"/ML/[ML] ExtraTrees/"},"frontmatter":{"categories":"ML","title":"ExtraTrees","date":"October 28, 2022"}},"next":{"fields":{"slug":"/Clustering/[ML] Clustering_DBSCAN/"}},"previous":{"fields":{"slug":"/Python/[python] CSV,JSON,Pickle,Parquet/"}}},{"node":{"id":"e11cec69-8c3e-51a2-99df-4826cc448bb7","excerpt":"DBSCAN 소개 DBSCAN은 밀도 기반 군집화 알고리즘으로 데이터의 분포가 기하학적으로 복잡한 데이터셋에도 효과적인 군집화가 가능한 알고리즘 개념 DBSCAN에서 중요 파라미터 입실론, min points가 있다. dbscan_1.PNG 입실론과 min points가 정해지고 그에따라 데이터를 군집화하는 과정에서 각 데이터는 3가지 상태 중 하나의 상태가 된다. Core Point Core Point는 선택된 데이터를 기준으로 입실론 영역 내 데이터 수가 min points보다 많은 경우 해당. dbscan_2.PNG Border Point Border Point는 선택된 데이터의 입실론 영역 내 데이터 수가 min points 보다 적고 주변 데이터 중 하나라도 Core Point인 데이터가 있는 경우 해당 dbscan_3.PNG Noise Point Noise Point는 선택된 데이터의 입실론 영역 내 데이터 수가 min points 보다 적고 주변 데이터 중에 Core …","fields":{"slug":"/Clustering/[ML] Clustering_DBSCAN/"},"frontmatter":{"categories":"ML","title":"DBSCAN","date":"October 25, 2022"}},"next":{"fields":{"slug":"/Clustering/[ML] Mean-Shift/"}},"previous":{"fields":{"slug":"/ML/[ML] ExtraTrees/"}}},{"node":{"id":"1e445c86-1e02-58c3-832b-bb2af209794c","excerpt":"Mean-Shift 소개 Mean-Shift는 K-Means와 유사하게 군집의 중심을 지속적으로 이동시키면서 군집화를 수행하며 군집의 중심을 데이터가 많이 모여있는 밀도가 가장 높은 곳으로 이동시키며 K-means와 달리 K의 개수를 설정하지 않아도 됨. KDE (Kernel Density Estimation) KDE는 커널 함수와 데이터를 바탕으로 연속성 있는 확률 밀도 함수를 추정하는 것으로 각 데이터마다 커널 함수를 생성한 후 모든 커널 함수를 더한 뒤 데이터 갯수로 나누어서 KDE 함수를 구함 진행 과정 ms_0.PNG 예제: 붓꽃 데이터  실제 값과 매칭 실제 데이터의 label의 개수는 3개이지만 MeanShift의 경우 2개로 군집을 형성 Reference [1] https://brunch.co.kr/@mnc/10 [2] https://blogs.sas.com/content/iml/2016/07/27/visualize-kernel-density-estimate.html…","fields":{"slug":"/Clustering/[ML] Mean-Shift/"},"frontmatter":{"categories":"ML","title":"Mean-Shift","date":"October 23, 2022"}},"next":{"fields":{"slug":"/Clustering/[ML] KNN/"}},"previous":{"fields":{"slug":"/Clustering/[ML] Clustering_DBSCAN/"}}},{"node":{"id":"5a9546b7-8fa6-54f8-a9ba-271f001eb324","excerpt":"K-means Clustering 소개 K-means는 특정 지점을 선택해 해당 중심에 가장 가까운 데이터를 군집화하는 알고리즘 진행과정 cl_2.PNG 최적의 K 값 적절한 군집의 수를 얻는 방법으로 Elbow method, Silhouette method가 있다. Elbow method Elbow method는 ‘군집간 분산/전체 분산’ 의 비율을 통해 분산 비율의 증가율이 줄어드는 개수로 K를 결정한다. 또한 반대로 ‘군집내 분산’ 의 감소가 더디어지는 부분으로 K를 결정한다. kn_1.jfif Silhouette method 데이터와 그 데이터가 속한 군집의 데이터들간의 비유사성을 계산하는 방법. kn_2.PNG 실루엣 계수값이 양수에 값이 크다면 군집화가 잘된 것이며 반대로 실루엣 계수값이 음수이며 값이 작으면 잘못된 것이다. 사이킷런에서 제공하는 silhouette_score() 값은 0~1 사이값을 가지며 1에 가까울수록 좋다. 예제: 붓꽃 데이터셋 군집화 전에 lab…","fields":{"slug":"/Clustering/[ML] KNN/"},"frontmatter":{"categories":"ML","title":"Clustering_KNN","date":"October 22, 2022"}},"next":{"fields":{"slug":"/Clustering/[ML] Clustering/"}},"previous":{"fields":{"slug":"/Clustering/[ML] Mean-Shift/"}}},{"node":{"id":"035ea913-0a45-5620-a8eb-9da8a16d6582","excerpt":"군집화 군집화는 대표적인 비지도학습 중 하나로 유사한 데이터끼리 하나의 군집(Cluster)로 묶는 것을 말한다. cl_1.PNG 대표적인 군집화 방법 K-means Clustering DBSCAN Clustering GMM Mean Shift 군집화 평가 방법 실루엣 계수 조정 랜드지수 K-means Clustering 소개 K-means는 특정 지점을 선택해 해당 중심에 가장 가까운 데이터를 군집화하는 알고리즘 진행과정 cl_2.PNG DBSCAN 소개 DBSCAN은 밀도 기반 군집화 알고리즘으로 데이터의 분포가 기하학적으로 복잡한 데이터셋에도 효과적인 군집화가 가능한 알고리즘 개념 DBSCAN에서 중요 파라미터 입실론, min points가 있다. dbscan_1.PNG 입실론과 min points가 정해지고 그에따라 데이터를 군집화하는 과정에서 각 데이터는 3가지 상태 중 하나의 상태가 된다. dbscan_0.PNG Core Point Core Point는 선택된 데이터를 …","fields":{"slug":"/Clustering/[ML] Clustering/"},"frontmatter":{"categories":"ML","title":"Clustering","date":"October 21, 2022"}},"next":{"fields":{"slug":"/ML/[ML] CatBoost/"}},"previous":{"fields":{"slug":"/Clustering/[ML] KNN/"}}},{"node":{"id":"7d467ff8-6ac1-56fa-ba39-f6f36ed33bb5","excerpt":"CatBoost CatBoost는 Unbiased boosting with categorical features에 초점을 맞춰서 생성된 알고리즘. 즉 범주형 변수에 초점을 두어 만들어진 Boosting 기반의 알고리즘. 주요 알고리즘 CatBoost는 앞서 2가지 이슈를 먼저 언급합니다. Target Leakage 범주형 변수(categorical Feautres)를 수치형 변수로 변환할 때 target인 label에 대한 정보가 어느 정도 반영됨.즉 target의 정보가 유출 이로인해 training dataset과 test dataset 간 확률 분포가 불일치 Predict Shift Target Leakage로 인해 Train dataset과 test dataset과는 다른 확률 분포를 가질 수 있다. 이 점을 Predict Shift로 정의 위에 대한 해결방안으로 Target Leakage -> Ordered TS , Predict Shift -> Ordered Boosti…","fields":{"slug":"/ML/[ML] CatBoost/"},"frontmatter":{"categories":"ML","title":"CatBoost","date":"October 16, 2022"}},"next":{"fields":{"slug":"/ML/[ML] LightGBM/"}},"previous":{"fields":{"slug":"/Clustering/[ML] Clustering/"}}},{"node":{"id":"5b70f5fe-7146-5ec9-ba1e-199e71befc3e","excerpt":"LightGBM 소개 LightGBM은 GradientBoosting 프레임워크로 결정 트리 기반의 학습 알고리즘으로 XGBoost와 달리 트리가 아래 그림처럼\n수직으로 확장하는 방식(leaf-wise) lgbm_1.PNG\n[출처] https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc 장단점 장점 leaf-wise 방식은 Delta loss가 가장 큰 Leaf을 선택해 분할하는 방식으로 loss를 줄여나간다. 또한 level-wise 알고리즘의 경우 모든 leaf가 균일하게 선택되 분할되기 때문에 leaf-wise 방식이 수행 속도가 빠르고 예측 오류를 최소화할 수 있다. GPU 학습 지원 및 적은 메모리 사용량 등 다양한 이점 등이 존재한다. 단점 Leaf Wise의 큰 단…","fields":{"slug":"/ML/[ML] LightGBM/"},"frontmatter":{"categories":"ML","title":"LightGBM","date":"October 14, 2022"}},"next":{"fields":{"slug":"/ML/[ML] XGBoost/"}},"previous":{"fields":{"slug":"/ML/[ML] CatBoost/"}}},{"node":{"id":"16192a93-09e0-5aae-8051-61a4d4e9991f","excerpt":"XGBoost 소개 GBM을 최적화한 알고리즘.  XGBoost 핵심 라이브러리는 C/C++로 작성되어 더 빠른 수행을 지원하며, 병렬처리 지원, 과적합 방지 등 여러 기능을 추가한 알고리즘 장단점 장점 뛰어난 예측 성능 빠른 수행 시간 (GBM 대비) 과적합 규제 Tree Pruning 자체 내장된 교차 검증 기능 -자체적으로 결손값 처리 단점 데이터가 크기가 작은 경우 과적합이 될 가능성이 크다. XGBoost 알고리즘 xgb_2.PNG xgb_3.PNG xgb_4.PNG xgb_5.PNG XGBoost Hyper Parameter 일반 파라미터 booster : gbtree or gblinear 선택. default는 gbtree silent: 출력 메시지를 나타내고 싶으면 0, 아니면 1. default는 0 nthread: CPU의 실행 Thread 수를 조정. default는 CPU의 전체 스레드 사용 부스터 파라미터 eta : learning rate로 사이킷런 기반이…","fields":{"slug":"/ML/[ML] XGBoost/"},"frontmatter":{"categories":"ML","title":"XGBoost","date":"October 13, 2022"}},"next":{"fields":{"slug":"/ML/[ML] ensemble/"}},"previous":{"fields":{"slug":"/ML/[ML] LightGBM/"}}},{"node":{"id":"3fa11651-8acf-5d81-bcdc-ad895235be35","excerpt":"Ensemble 앙상블 기법이란 한마디로 쉽게 설명하자면 여러 전문가(ML)들이 협력하여 결론(예측)을 하는 방식. ens_1.PNG 앙상블 학습 유형 대표적인 3가지 학습 유형으로 배깅, 보팅, 부스팅 3가지 방법이 있다. 배깅(Bootstrap Aggregating, Bagging) 배깅이란? 랜덤 샘플링한 데이터를 여러 모델에 학습시킨 뒤 결과를 집계하는 방식 특징 배깅의 경우 각 분류기가 서로 독립적으로 병렬적으로 진행 범주형 자료일 때 다수결로 채택, 숫자형 자료일 때 평균 값을 채택 속도가 빠르며 과적합 영향이 적다. 적은 데이터셋이라도 준수한 결과를 도출한다. 배깅의 대표적인 알고리즘 : RandomForest 진행 과정 rf_3.PNG\n[출처] https://medium.com/ml-research-lab/bagging-ensemble-meta-algorithm-for-reducing-variance-c98fffa5489f 보팅 보팅이란? 여러 분류기가 투표를 통해 …","fields":{"slug":"/ML/[ML] ensemble/"},"frontmatter":{"categories":"ML","title":"Ensemble","date":"September 28, 2022"}},"next":{"fields":{"slug":"/ML/[ML] Boosting_Algorithm/"}},"previous":{"fields":{"slug":"/ML/[ML] XGBoost/"}}},{"node":{"id":"faafee8b-fcf8-5f06-b2ac-3cbf460b6e14","excerpt":"Boosting Algorithm 부스팅 부스팅은 앙상블 학습 유형 중 하나로 약한 분류기를 순차적으로 학습-예측하면서 가중치를 조정하여 오류를 개선하면서 학습하는 방식. 대표적인 부스팅 머신러닝 AdaBoost GradientBoost XGBoost, LightGBM, CatBoost 등 AdaBoost 예측 성능이 낮은 학습기를 구축 및 조합하여 가중치 조절을 통해 좋은 성능을 발휘하는 강한 분류기를 합성하는 알고리즘 진행 과정 bs_1.PNG 정리 AdaBoost는 매 단계마다 이전 분류기에서 오차가 크거나 오분류된 데이터들의 가중치를 크게하고 정분류된 데이터들의 가중치는 적게 설정한뒤 다음 단계의 학습데이터셋의 추출과정에 가중치에 비례하게 복원추출하여 새로운 데이터셋을 만들고 모형을 적합하는 과정을 거친다. 이러한 반복 단계를 통해 가중치가 반영된 총 오류를 최소화하는 분류기를 선택하고, 선택된 분류기에서 얻은 가중치 및 오류를 얻고, 이를 가속화된 분류기를 개선하는 데 이…","fields":{"slug":"/ML/[ML] Boosting_Algorithm/"},"frontmatter":{"categories":"ML","title":"Boosting Alogrithms","date":"September 25, 2022"}},"next":{"fields":{"slug":"/ML/[ML] Decision_Trees/"}},"previous":{"fields":{"slug":"/ML/[ML] ensemble/"}}},{"node":{"id":"b2ade22d-c2e0-5e32-b0ce-fb2a910908f8","excerpt":"Decision Trees Decision Tree(결정 트리)는 지도 학습에서 분류 및 회귀에 사용되는 모델 중 하나로 불순도가 낮아지는 방향으로 가지를 계속해서 분할. ML 알고리즘 중에서 가장 직관적인 알고리즘 dt_main.PNG 특징 쉽게 이해할 수 있고 해석이 간편하다. 별도의 전처리 없이 쉽게 사용이 가능하다. RandomForest 모형의 구성 요소 불순도 불순도란 다양한 요소들이 섞여있는 정도를 의미. 대표적인 불순도 척도로 지니 계수와 엔트로피가 사용된다. 지니 계수 지니 계수란 경제적 불평등을 나타내는 용어로 0에 가까울 수록 평등하고 1에 가까울 수록 불평등을 나타낸다. 의사 결정 트리에서의 지니계수는 이와 약간 달리 0.5값을 가질 때를 가장 불순도가 높다고 판단하며 지니계수가 0에 근접하도록 분할을 진행한다. <지니계수를 구하는 공식>\ndt_gini.PNG 엔트로피 엔트로피란 정보이득을 나타내는 지표로 순도가 높을 때 얻는 정보 이득은 증가, 불순도가 높을…","fields":{"slug":"/ML/[ML] Decision_Trees/"},"frontmatter":{"categories":"ML","title":"Decision_Trees","date":"September 25, 2022"}},"next":{"fields":{"slug":"/ML/[ML] RandomForest/"}},"previous":{"fields":{"slug":"/ML/[ML] Boosting_Algorithm/"}}},{"node":{"id":"b22a1546-b405-5a09-af07-080c0d044953","excerpt":"Keywords RandomForest 배깅 하이퍼 파라미터 튜닝 OOB Score 변수 중요도 RandomForest 랜덤포레스트는 분류 및 회귀 ML 중 하나로 앙상블 학습 방법의 일종 으로 트리 기반 알고리즘이다. 각 트리들은 랜덤하게 서로 다른 특성을 가진다. 이를 통해 각 트리들의 예측이 비상관적이며 결과적으로 일반화 성능을 향상시킨다. 랜덤화는 각 트리들의 훈련 과정에서 진행되며, 랜덤 학습 데이터 추출 방법을 이용한 앙상블 학습법인 배깅(bagging)과 랜덤 노드 최적화(randomized node optimization)가 자주 사용된다. 이 두 가지 방법은 서로 동시에 사용되어 랜덤화 특성을 더욱 증진 시킬 수 있다.  [출처] https://velog.io/@ayi4067/DAY27 배깅 랜덤 샘플링한 데이터를 여러 모델에 학습시킨 뒤 결과를 집계하는 방식 배깅의 특징 배깅의 경우 각 분류기가 서로 독립적으로 병렬적으로 진행 범주형 자료일 때 다수결로 채택, 숫…","fields":{"slug":"/ML/[ML] RandomForest/"},"frontmatter":{"categories":"ML","title":"RandomForest","date":"September 18, 2022"}},"next":{"fields":{"slug":"/ML/[ML] SVM/"}},"previous":{"fields":{"slug":"/ML/[ML] Decision_Trees/"}}},{"node":{"id":"849eb3fd-8385-55b6-af45-ca82ffb6acc6","excerpt":"SVM 소개 SVM (Support Vector Machine)은 지도학습 모델 중 하나로 분류 및 회귀 분석에 사용되는 머신 러닝 기법 svm_1.PNG 주요 용어 svm_2.PNG 경계선을 정하는 기준 아래 그림처럼 다양한 경계선이 생성될 수 있다. 어떠한 경계선을 선택하는 것이 옳을까?\nsvm_3.PNG margin이 크다는 의미는 경계선의 폭이 크다는 의미로 새로운 데이터 값이 들어오는 경우에 margin의 클 수록 더 정확한 분류가 가능 커널 트릭 커널 트릭이란 저차원 -> 고차원 공간으로 매핑하는 작업을 말한다. 아래 그림과 같이 경계선을 생성 불가능 할때 주로 사용.\nsvm_4.PNG 주요 파라미터 C C는 오분류된 데이터의 허용 정도를 의미하며 이 값이 작을수록 많이 허용하고 높을 수록 적게 허용한다. 이로 인해 C값이 작으면 경계선 모양이 직선에 가까우며 높을 수록 여러겹의 굽은 선에 가깝다. Gamma 각 데이터가 영향을 주는 정도를 나타내며 Gamma 값이 낮아…","fields":{"slug":"/ML/[ML] SVM/"},"frontmatter":{"categories":"ML","title":"SVM","date":"September 17, 2022"}},"next":{"fields":{"slug":"/ML/[ML] Naive_Bayes/"}},"previous":{"fields":{"slug":"/ML/[ML] RandomForest/"}}},{"node":{"id":"ff193421-b6e2-575c-9d2a-4b47424d3d44","excerpt":"Naive Bayes 소개 나이브 베이즈란 베이즈 정리를 기반으로 한 분류 알고리즘. 단순하고 빠르며 정확도도 갖춘 알고리즘이지만 변수들간의 독립성이라는 조건이 만족되어야 한다. 베이즈 정리 데이터라는 조건이 주어졌을 때 조건부확률을 구하는 공식으로 새로운 정보로 인해 기존의 값이 어떻게 영향을 받는 지 알 수 있다. 사전 확률 P(A) 조건부 확률 (사후 확률) ${P(A|B)  = {P(A \\cap B) \\over P(B)} = {P(B|A)P(A) \\over P(B)}}$ 예시 : x켓몬 빵 구매 근처 편의점에 x켓몬 빵을 사러 갔을 때 구입 유무에 대한 표이다. 위 표를 근거로 점심에 편의점에 갔을 때 x켓몬 빵을 살 확률은? nb_1.PNG 예제: 라면사 분류 Reference [1] https://datascienceschool.net/02%20mathematics/06.06%20%EB%B2%A0%EC%9D%B4%EC%A6%88%20%EC%A0%95%EB%A6%AC.ht…","fields":{"slug":"/ML/[ML] Naive_Bayes/"},"frontmatter":{"categories":"ML","title":"Naive_Bayes","date":"September 17, 2022"}},"next":{"fields":{"slug":"/ML/[ML] Cross_Validation/"}},"previous":{"fields":{"slug":"/ML/[ML] SVM/"}}},{"node":{"id":"3d8213a9-81c8-51fb-b8d4-e1c46eebff19","excerpt":"교차 검증 고정된 학습 데이터와 테스트 데이터로 평가를 하면 과적합의 문제가 발생한다. 이를 방지하기 위해 교차검증이라는 방식을 사용하여 과적합을 방지한다. K-Fold 학습 데이터를 K 개의 Fold로 나누고 나누어진 폴드 중 하나를 검증용, 나머지를 학습용으로 선정한 뒤 위 그림처럼 검증용 폴드를 변경하면서 학습과 검증을 수행하는 것.  대표적인 클래스로 KFold, Stratified k-fold, Cross_val_score가 있다. 좋은 파라미터를 찾는 법  예시: 중산층 분류하기 데이터셋 준비 K-Fold Stratified k-fold 아래 그림과 같이 target값이 불균형한 분포를 가진 데이터 집합을 위한 방식으로 target 분포와 비슷한 비율 (예제의 경우 3:1)로 학습 데이터와 테스트 데이터셋에 분배한다.  Cross_val_score 위의 KFold, StratifiedKFold와 같은 방식도 있지만 더 편하게 할 수 있는 방법이 corss_val_scor…","fields":{"slug":"/ML/[ML] Cross_Validation/"},"frontmatter":{"categories":"ML","title":"Cross_Validation","date":"September 14, 2022"}},"next":{"fields":{"slug":"/Python/[python] 리스트/"}},"previous":{"fields":{"slug":"/ML/[ML] Naive_Bayes/"}}},{"node":{"id":"94555522-b94e-526d-aedc-3b82b7eda0f9","excerpt":"1.데이터 로드하기 <svg xmlns=”http://www.w3.org/2000/svg” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n\n\n\n <svg xmlns=”http://www.w3.org/2000/svg” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n\n\n\n train , test 데이터 크기 확인 <svg xmlns=”http://www.w3.org/2000/svg” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n\n\n\n 데이터는 id, document, label 3가지로 구성되어 있으며 label = 0은 부정적인 평가, label = 1 은 긍정적인 평가를 나타내는 칼럼 2.데이터 정제하기 데이터 중복 유무 확인하기 원래 데이터 크기가 5000이기 때문에 중복 값이 없는 것을 확인 Nan 값 제거 Na 값이 없는 것을 확인 데이터 레이블 값의 분포 확인 …","fields":{"slug":"/Dacon/영화리뷰_감성분석/"},"frontmatter":{"categories":"Data_Analysis ML","title":"영화 리뷰_감성분석","date":"January 21, 2022"}},"next":{"fields":{"slug":"/Study/데이터 마이닝/"}},"previous":{"fields":{"slug":"/Dacon/집값 예측/"}}},{"node":{"id":"2f6cb43c-aef4-58a6-8a4d-c4260edd405a","excerpt":"비슷한 GDP, GDP 성장률을 가진 국가끼리 모아보자 - Merge GDP & GDP Growth - 시각화  - Trouble Shooting 위의 데이터에서 GDP가 80000 이상인 국가 및 도시가 발견되었다. GDP Analysis [1]에서 살펴봤듯 GDP 1위 국가는 미국으로 GDP가 20000이므로 무언가 이상한 데이터가 포함되었다는 것을 확인함 [1] 위와 같이 다른 경제 지표도 포함되어 있는 것을 확인. 위 분석의 목적은 국가 및 도시를 대상으로 분석을 진행하는 것이기 때문에 gdp_2020.csv 파일에서 직접 제거함  미국과 중국의 GDP가 다른 국가에 비해 너무 크므로 제외함  위 plot을 통해 GDP가 큰 나라들도 마이너스 GDP 성장을 한 것을 알 수 있으며 GDP와 GDP Growth간의 상관관계도 딱히 보이지 않는 것을 볼 수 있다. - KMeans Cluster 알고리즘 1. 클러스터 수 (k)를 정하기 2. 반복 수 정하기 3. 클러스터 중심값을…","fields":{"slug":"/GDP_Analysis/GDP Analysis [3] - 군집 분석/"},"frontmatter":{"categories":"Data_Analysis ML","title":"GDP Analysis [3] - 군집 분석","date":"January 20, 2022"}},"next":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [2]  - 데이터 분석/"}},"previous":{"fields":{"slug":"/GDP_Analysis/GDP Analysis [2] - GDP Growth/"}}},{"node":{"id":"df840f27-5c98-58e7-ba08-8385a229e1e8","excerpt":"- 연관 분석 서울시의 생활이동 데이터의 출발지와 도착지 연관분석을 실시해보자 위의 사례를 통해 의미있는 결과를 얻으려면 이동량이 많은 부분만 추려야 한다. 따라서 10000건 이상인 경우의 이동형태만 추출한다. 위 과정이 워낙 많은 시간을 소요하는 과정이므로 pickle로 저장한 후 추후에 불러와서 사용 - Trouble Shooting 4_1.PNG - FP Growth 참고 사이트 :https://zephyrus1111.tistory.com/119 - 연관 분석 - Trouble Shooting - FP Growth","fields":{"slug":"/Seoul_Movement/Seoul_movement [4] - 연관분석/"},"frontmatter":{"categories":"Data_Analysis ML","title":"서울 생활 이동 [4] - 연관성 분석","date":"January 19, 2022"}},"next":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [1] - 데이터 설명 및 전처리/"}},"previous":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [3] - QGIS 활용/"}}}]}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}