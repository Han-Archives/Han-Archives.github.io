{
    "componentChunkName": "component---src-templates-category-template-js",
    "path": "/posts",
    "result": {"pageContext":{"currentCategory":"All","edges":[{"node":{"id":"be92d91d-e2d7-51b6-b994-278f13dfd7dd","excerpt":"CNN Architecture 소개 CNN Architecture란 CNN을 기반으로 한 모델 중 성능이 뛰어난 몇몇 모델의 구조를 말한다. 대표적인 아키텍처로 AlexNet, VGG, GoogleNet, ResNet 등이 있다. 발전 과정 ImageNet 데이터셋을 통한 년도별 성능 발전 상황을 살펴보면 2012년 AlexNet을 기점으로 CNN 구조의 여러 모델들이 높은 성능을 나타내며 발전하였다. 2016년도 이후로는 성능 향상보단 경량화, 효율화 과정을 통해 각 모델의 규모를 줄이는 데 초점을 맞춰 발전 해왔다. \n[출처] https://theaisummer.com/cnn-architectures/ 초반의 CNN 구조는 파라미터의 갯수를 증대시키는 방식으로 진행되었으나 현재 각 모델의 파라미터의 갯수와 성능은 아래의 표와 같이 언제나 비례하지 않는다. cnnar_5.PNG Architecture Scaling 각 모델 구조는 아래 그림과 같이 넓게, 깊게, 넓고 깊게하는 방…","fields":{"slug":"/DL/[DL] CNN_Architectures/"},"frontmatter":{"categories":"DL","title":"CNN Architecture","date":"December 08, 2022"}},"next":{"fields":{"slug":"/DL/[DL] CNN_process/"}},"previous":null},{"node":{"id":"e5234649-87ff-5a43-adec-6525da31d74c","excerpt":"CNN 프로세스 cnn_1.PNG 이미지 호출  필터 적용 이미지의 구조는 이미지의 너비, 높이, 색상 채널 3가지 구조로 구성. 필터를 적용하여 이미지가 갖고 있는 특징적인 부분들을 추출하여 Feature Map을 생성. cnnp_5.png   풀링 풀링은 정보를 축약하는 과정으로 입력 파라미터가 축소 아래의 예시를 통해 풀링 과정 전과 후 파라미터의 수 변화를 살펴보자 풀링 전 cnnp_2.PNG 풀링 후 cnnp_3.PNG 결과 풀링을 진행 전과 후의 차이로 [풀링 전] 파라미터는 20087개, [풀링 후] 파라미터는 1337개로 대략 15배 감소한 것을 확인할 수 있다. Reference [1] https://www.tomasbeuzen.com/deep-learning-with-pytorch/chapters/chapter5_cnns-pt1.html [2] https://www.youtube.com/watch?v=OAksbx2bTVc&list=WL&index=1 [3] htt…","fields":{"slug":"/DL/[DL] CNN_process/"},"frontmatter":{"categories":"DL","title":"CNN Process","date":"December 05, 2022"}},"next":{"fields":{"slug":"/DL/[DL] CNN/"}},"previous":{"fields":{"slug":"/DL/[DL] CNN_Architectures/"}}},{"node":{"id":"4f806e7c-e00a-5a6f-ae05-674d6de60709","excerpt":"CNN (합성곱 신경망) 소개 합성곱 신경망은 이미지의 객체 탐지, 분할 등 이미지나 동영상과 관련된 머신러닝 문제를 해결하는 딥러닝 모델 중 하나로 이미지 인식과 패턴 감지를 위한 최적의 아키텍처를 제공한다. 특징 CNN은 이미지에서 객체, 얼굴, 장면을 인식하기 위해 1.패턴을 찾는 데 특히 유용하며 CNN은 데이터에서 직접 학습하며, 2.패턴을 사용하여 이미지를 분류하고 특징을 수동으로 추출할 필요가 없다. 합성곱 계층은 3.학습 가능한 매개변수를 공유하는 합성곱 계층을 사용하여 테두리, 윤곽선 등 이미지에서 학습한 패턴은 이미지의 픽셀 위치에 독립적인 것으로 가정하여 매개변수를 공유할 수 있다. 진행 과정 CNN의 진행 과정은 크게 Feature Learning과 Classification으로 나뉘어진다. Feature Learning은 이미지로 부터 특징을 찾아 학습하는 과정 Classification은 인공 신경망 과정을 거쳐 이미지를 분류하는 과정 cnn_1.PNG F…","fields":{"slug":"/DL/[DL] CNN/"},"frontmatter":{"categories":"DL","title":"CNN","date":"December 04, 2022"}},"next":{"fields":{"slug":"/DL/[DL] Deep_Learning/"}},"previous":{"fields":{"slug":"/DL/[DL] CNN_process/"}}},{"node":{"id":"60bd67d7-5d95-589c-88db-5a03396860ca","excerpt":"KeyWords DeepLearning 인공 신경망 신경망 아키텍처 활성화 함수 손실 함수 옵티마이저 다중 신경망 역전파 Deep Learning 딥러닝은 신경망 기반의 복잡도가 큰 머신러닝 모델. 많은 수의 은닉층을 사용하여 마치 인간 뇌의 뉴런과 비슷한 방식의 인공신경망 방식으로 정보를 처리  인공신경망 인공신경망이란 생물학의 신경망에서 영감을 얻은 통계학적 학습 알고리즘  [출처] : http://scienceon.hani.co.kr/397536 신경망 아키텍처 인공 신경망은 아래와 같은 신경망 구조로 발전되어 다중 신경망을 구성한다. \n[출처] https://www.asimovinstitute.org/neural-network-zoo/ 그 외에도 dropout 방식과 같은 다양한 구조가 존재한다.\ndl_5.PNG 딥러닝을 이해하기 위한 사전 지식으로 활성화 함수,손실함수, 옵티마이저에 대해 알아보자. 활성화 함수 활성화 함수는 신경망 구조에 비선형성을 추가하기 위해 존재한다…","fields":{"slug":"/DL/[DL] Deep_Learning/"},"frontmatter":{"categories":"DL","title":"Deep Learning","date":"December 03, 2022"}},"next":{"fields":{"slug":"/DL/[DL] Data Augumentation/"}},"previous":{"fields":{"slug":"/DL/[DL] CNN/"}}},{"node":{"id":"f421810d-6886-5f90-9a61-f76f3bcc78bd","excerpt":"Data Augumentation 소개 Data Augmentation이란 데이터 증강이란 의미로 머신 러닝을 위한 데이터의 다양성을 높여 과적합을 방지하는 프로세스. 즉 기존의 데이터셋을 활용하여 다른 버전의 데이터셋을 생성하여 데이터셋의 크기를 늘리는 방법. Data Augumentation의 일반적인 진행과정은 대부분 전처리 후, 모델 학습 이전에 주로 시행된다.  주요 기법 Augumentation의 주요 기법들을 설명 요약하면 크게 1)사이즈 변환 , 2)주요 특징 추출, 3)픽셀 화소 변환, 4)이미지 각도 변환, 5)기타 사항 등 4가지 항목으로 나타낼 수 있다. 사이즈 변환 Resize: 이미지의 사이즈를 지정할 때 사용 RandomResizedCrop : 임의의 위치의 이미지의 사이즈를 지정할 때 사용 주요 특징 추출 CenterCrop : 중앙을 기점으로 지정된 사이즈만큼 추출 FiveCrop : 중앙, 각 이미지의 모서리에 해당되는 부분까지 5 부분에 대한 이미…","fields":{"slug":"/DL/[DL] Data Augumentation/"},"frontmatter":{"categories":"DL","title":"Data Augumentation","date":"December 03, 2022"}},"next":{"fields":{"slug":"/Study/[etc] upload github.io/"}},"previous":{"fields":{"slug":"/DL/[DL] Deep_Learning/"}}},{"node":{"id":"d17c50d3-fbb0-58a5-9114-deb2e00f6059","excerpt":"Github.io 업로드 진행 과정 1. 주피터 노트북에 접속 후 md 파일 생성  다운로드 된 파일 folder.PNG 2. md 파일 수정 깃허브 블로그에 업로드하기 위해선 몇가지 수정작업을 거쳐야 한다. 원본 md 파일 origin_md.PNG 수정된 md 파일 header.PNG tail.PNG pic 자료 수정 pic.PNG 3. cmd로 업로드 하기 1. cd로 깃허브 폴더 경로로 지정한다. 2. npm run deploy로 업로드한다. deploy.PNG Success end.PNG 완료 시 done.PNG Reference [1] https://github.com/zoomkoding/zoomkoding-gatsby-blog Github.io 업로드 진행 과정 1. 주피터 노트북에 접속 후 md 파일 생성 2. md 파일 수정 3. cmd로 업로드 하기 1. cd로 깃허브 폴더 경로로 지정한다. 2. npm run deploy로 업로드한다. 완료 시 Reference","fields":{"slug":"/Study/[etc] upload github.io/"},"frontmatter":{"categories":"Study","title":"Github_io에 저장하기","date":"November 13, 2022"}},"next":{"fields":{"slug":"/Python/[python] CSV,JSON,Pickle,Parquet/"}},"previous":{"fields":{"slug":"/DL/[DL] Data Augumentation/"}}},{"node":{"id":"421e62cb-df32-5ffe-adc6-b878fa069478","excerpt":"데이터 저장 방식 유형 csv csv란 쉼표로 구분한 텍스트 기반의 저장 방식\ncsv.PNG json json은 자바스크립트 객체 표기법으로 key:value 형식으로 구성된 텍스트 기반의 저장 방식 json.PNG pickle pickle은 텍스트 형식으로 저장하는 것이 아닌 바이너리 형태로 저장하는 것으로 대용량 데이터라도 빠르게 호출이 가능하다. parquet parquet은 Hadoop기반 저장방식으로 column 기반의 압축방식으로 pickle보다 압축률이 뛰어나다는 장점이 있으나 pyarrow, fastparquet등의 추가적인 패키지 인스톨이 필요하다. csv csv 불러오기 json json 불러오기 pickle pickle 불러오기 Parquet fastparquet 패키지 필요 parquet 불러오기 특정 칼럼 지정해서 불러오기 데이터 저장 방식 유형 csv csv 불러오기 json json 불러오기 pickle pickle 불러오기 Parquet parquet …","fields":{"slug":"/Python/[python] CSV,JSON,Pickle,Parquet/"},"frontmatter":{"categories":"Python","title":"데이터 저장방식","date":"November 12, 2022"}},"next":{"fields":{"slug":"/ML/[ML] ExtraTrees/"}},"previous":{"fields":{"slug":"/Study/[etc] upload github.io/"}}},{"node":{"id":"1da14877-121f-5d56-a03c-9b3f289f64b0","excerpt":"추가 트리 알고리즘 소개 엑스트라 트리 알고리즘은 랜덤포레스트와 마찬가지로 결정 트리 기반의 알고리즘 랜덤포레스트 차이점 [1] 부트스트랩 방식을 사용하지 않고 전체데이터를 사용한다. [2] 노드를 분할 하는 임계점을 랜덤하게 선택한다. -> 결정트리 방식의 임계점은 불순도를 가장 낮추는 방향으로 분리하지만 추가 트리 알고리즘은 그렇지 않다. 임계점 랜덤 선택?? 임계점을 랜덤으로 선택하면 모델의 성능이 떨어지는 것이 아닌가 할 수 있지만 추가 트리 알고리즘은 앙상블 모델로써 여러 트리 모형 중 가장 좋은 성능의 트리를 선택하여 이를 보완할 수 있다. 랜덤 포레스트와 결정 트리의 경우 최적의 임계값을 계산하는 과정에 시간이 소요되지만 추가 트리 알고리즘은 무작위로 선택하기 때문에 시간이 적게 걸리며 랜덤 포레스트에 비해 더 많은 트리 구조를 활용할 수 있다는 장점이 있다. 예제 : 타이타닉 타이타닉 데이터셋을 통해 랜덤포레스트와 엑스트라트리 알고리즘의 성능을 비교해보자 추가 트리 …","fields":{"slug":"/ML/[ML] ExtraTrees/"},"frontmatter":{"categories":"ML","title":"ExtraTrees","date":"October 28, 2022"}},"next":{"fields":{"slug":"/ML/[ML] CatBoost/"}},"previous":{"fields":{"slug":"/Python/[python] CSV,JSON,Pickle,Parquet/"}}},{"node":{"id":"7d467ff8-6ac1-56fa-ba39-f6f36ed33bb5","excerpt":"CatBoost CatBoost는 Unbiased boosting with categorical features에 초점을 맞춰서 생성된 알고리즘. 즉 범주형 변수에 초점을 두어 만들어진 Boosting 기반의 알고리즘. 주요 알고리즘 CatBoost는 앞서 2가지 이슈를 먼저 언급합니다. Target Leakage 범주형 변수(categorical Feautres)를 수치형 변수로 변환할 때 target인 label에 대한 정보가 어느 정도 반영됨.즉 target의 정보가 유출 이로인해 training dataset과 test dataset 간 확률 분포가 불일치 Predict Shift Target Leakage로 인해 Train dataset과 test dataset과는 다른 확률 분포를 가질 수 있다. 이 점을 Predict Shift로 정의 위에 대한 해결방안으로 Target Leakage -> Ordered TS , Predict Shift -> Ordered Boosti…","fields":{"slug":"/ML/[ML] CatBoost/"},"frontmatter":{"categories":"ML","title":"CatBoost","date":"October 16, 2022"}},"next":{"fields":{"slug":"/ML/[ML] LightGBM/"}},"previous":{"fields":{"slug":"/ML/[ML] ExtraTrees/"}}},{"node":{"id":"5b70f5fe-7146-5ec9-ba1e-199e71befc3e","excerpt":"LightGBM 소개 LightGBM은 GradientBoosting 프레임워크로 결정 트리 기반의 학습 알고리즘으로 XGBoost와 달리 트리가 아래 그림처럼\n수직으로 확장하는 방식(leaf-wise) lgbm_1.PNG\n[출처] https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc 장단점 장점 leaf-wise 방식은 Delta loss가 가장 큰 Leaf을 선택해 분할하는 방식으로 loss를 줄여나간다. 또한 level-wise 알고리즘의 경우 모든 leaf가 균일하게 선택되 분할되기 때문에 leaf-wise 방식이 수행 속도가 빠르고 예측 오류를 최소화할 수 있다. GPU 학습 지원 및 적은 메모리 사용량 등 다양한 이점 등이 존재한다. 단점 Leaf Wise의 큰 단…","fields":{"slug":"/ML/[ML] LightGBM/"},"frontmatter":{"categories":"ML","title":"LightGBM","date":"October 14, 2022"}},"next":{"fields":{"slug":"/ML/[ML] XGBoost/"}},"previous":{"fields":{"slug":"/ML/[ML] CatBoost/"}}},{"node":{"id":"16192a93-09e0-5aae-8051-61a4d4e9991f","excerpt":"XGBoost 소개 GBM을 최적화한 알고리즘.  XGBoost 핵심 라이브러리는 C/C++로 작성되어 더 빠른 수행을 지원하며, 병렬처리 지원, 과적합 방지 등 여러 기능을 추가한 알고리즘 장단점 장점 뛰어난 예측 성능 빠른 수행 시간 (GBM 대비) 과적합 규제 Tree Pruning 자체 내장된 교차 검증 기능 -자체적으로 결손값 처리 단점 데이터가 크기가 작은 경우 과적합이 될 가능성이 크다. XGBoost 알고리즘 xgb_2.PNG xgb_3.PNG xgb_4.PNG xgb_5.PNG XGBoost Hyper Parameter 일반 파라미터 booster : gbtree or gblinear 선택. default는 gbtree silent: 출력 메시지를 나타내고 싶으면 0, 아니면 1. default는 0 nthread: CPU의 실행 Thread 수를 조정. default는 CPU의 전체 스레드 사용 부스터 파라미터 eta : learning rate로 사이킷런 기반이…","fields":{"slug":"/ML/[ML] XGBoost/"},"frontmatter":{"categories":"ML","title":"XGBoost","date":"October 13, 2022"}},"next":{"fields":{"slug":"/ML/[ML] ensemble/"}},"previous":{"fields":{"slug":"/ML/[ML] LightGBM/"}}},{"node":{"id":"3fa11651-8acf-5d81-bcdc-ad895235be35","excerpt":"Ensemble 앙상블 기법이란 한마디로 쉽게 설명하자면 여러 전문가(ML)들이 협력하여 결론(예측)을 하는 방식. ens_1.PNG 앙상블 학습 유형 대표적인 3가지 학습 유형으로 배깅, 보팅, 부스팅 3가지 방법이 있다. 배깅(Bootstrap Aggregating, Bagging) 배깅이란? 랜덤 샘플링한 데이터를 여러 모델에 학습시킨 뒤 결과를 집계하는 방식 특징 배깅의 경우 각 분류기가 서로 독립적으로 병렬적으로 진행 범주형 자료일 때 다수결로 채택, 숫자형 자료일 때 평균 값을 채택 속도가 빠르며 과적합 영향이 적다. 적은 데이터셋이라도 준수한 결과를 도출한다. 배깅의 대표적인 알고리즘 : RandomForest 진행 과정 rf_3.PNG\n[출처] https://medium.com/ml-research-lab/bagging-ensemble-meta-algorithm-for-reducing-variance-c98fffa5489f 보팅 보팅이란? 여러 분류기가 투표를 통해 …","fields":{"slug":"/ML/[ML] ensemble/"},"frontmatter":{"categories":"ML","title":"Ensemble","date":"September 28, 2022"}},"next":{"fields":{"slug":"/ML/[ML] Boosting_Algorithm/"}},"previous":{"fields":{"slug":"/ML/[ML] XGBoost/"}}},{"node":{"id":"faafee8b-fcf8-5f06-b2ac-3cbf460b6e14","excerpt":"Boosting Algorithm 부스팅 부스팅은 앙상블 학습 유형 중 하나로 약한 분류기를 순차적으로 학습-예측하면서 가중치를 조정하여 오류를 개선하면서 학습하는 방식. 대표적인 부스팅 머신러닝 AdaBoost GradientBoost XGBoost, LightGBM, CatBoost 등 AdaBoost 예측 성능이 낮은 학습기를 구축 및 조합하여 가중치 조절을 통해 좋은 성능을 발휘하는 강한 분류기를 합성하는 알고리즘 진행 과정 bs_1.PNG 정리 AdaBoost는 매 단계마다 이전 분류기에서 오차가 크거나 오분류된 데이터들의 가중치를 크게하고 정분류된 데이터들의 가중치는 적게 설정한뒤 다음 단계의 학습데이터셋의 추출과정에 가중치에 비례하게 복원추출하여 새로운 데이터셋을 만들고 모형을 적합하는 과정을 거친다. 이러한 반복 단계를 통해 가중치가 반영된 총 오류를 최소화하는 분류기를 선택하고, 선택된 분류기에서 얻은 가중치 및 오류를 얻고, 이를 가속화된 분류기를 개선하는 데 이…","fields":{"slug":"/ML/[ML] Boosting_Algorithm/"},"frontmatter":{"categories":"ML","title":"Boosting Alogrithms","date":"September 25, 2022"}},"next":{"fields":{"slug":"/ML/[ML] Decision_Trees/"}},"previous":{"fields":{"slug":"/ML/[ML] ensemble/"}}},{"node":{"id":"b2ade22d-c2e0-5e32-b0ce-fb2a910908f8","excerpt":"Decision Trees Decision Tree(결정 트리)는 지도 학습에서 분류 및 회귀에 사용되는 모델 중 하나로 불순도가 낮아지는 방향으로 가지를 계속해서 분할. ML 알고리즘 중에서 가장 직관적인 알고리즘 dt_main.PNG 특징 쉽게 이해할 수 있고 해석이 간편하다. 별도의 전처리 없이 쉽게 사용이 가능하다. RandomForest 모형의 구성 요소 불순도 불순도란 다양한 요소들이 섞여있는 정도를 의미. 대표적인 불순도 척도로 지니 계수와 엔트로피가 사용된다. 지니 계수 지니 계수란 경제적 불평등을 나타내는 용어로 0에 가까울 수록 평등하고 1에 가까울 수록 불평등을 나타낸다. 의사 결정 트리에서의 지니계수는 이와 약간 달리 0.5값을 가질 때를 가장 불순도가 높다고 판단하며 지니계수가 0에 근접하도록 분할을 진행한다. <지니계수를 구하는 공식>\ndt_gini.PNG 엔트로피 엔트로피란 정보이득을 나타내는 지표로 순도가 높을 때 얻는 정보 이득은 증가, 불순도가 높을…","fields":{"slug":"/ML/[ML] Decision_Trees/"},"frontmatter":{"categories":"ML","title":"Decision_Trees","date":"September 25, 2022"}},"next":{"fields":{"slug":"/ML/[ML] RandomForest/"}},"previous":{"fields":{"slug":"/ML/[ML] Boosting_Algorithm/"}}},{"node":{"id":"b22a1546-b405-5a09-af07-080c0d044953","excerpt":"Keywords RandomForest 배깅 하이퍼 파라미터 튜닝 OOB Score 변수 중요도 RandomForest 랜덤포레스트는 분류 및 회귀 ML 중 하나로 앙상블 학습 방법의 일종 으로 트리 기반 알고리즘이다. 각 트리들은 랜덤하게 서로 다른 특성을 가진다. 이를 통해 각 트리들의 예측이 비상관적이며 결과적으로 일반화 성능을 향상시킨다. 랜덤화는 각 트리들의 훈련 과정에서 진행되며, 랜덤 학습 데이터 추출 방법을 이용한 앙상블 학습법인 배깅(bagging)과 랜덤 노드 최적화(randomized node optimization)가 자주 사용된다. 이 두 가지 방법은 서로 동시에 사용되어 랜덤화 특성을 더욱 증진 시킬 수 있다.  [출처] https://velog.io/@ayi4067/DAY27 배깅 랜덤 샘플링한 데이터를 여러 모델에 학습시킨 뒤 결과를 집계하는 방식 배깅의 특징 배깅의 경우 각 분류기가 서로 독립적으로 병렬적으로 진행 범주형 자료일 때 다수결로 채택, 숫…","fields":{"slug":"/ML/[ML] RandomForest/"},"frontmatter":{"categories":"ML","title":"RandomForest","date":"September 18, 2022"}},"next":{"fields":{"slug":"/ML/[ML] SVM/"}},"previous":{"fields":{"slug":"/ML/[ML] Decision_Trees/"}}},{"node":{"id":"849eb3fd-8385-55b6-af45-ca82ffb6acc6","excerpt":"SVM 소개 SVM (Support Vector Machine)은 지도학습 모델 중 하나로 분류 및 회귀 분석에 사용되는 머신 러닝 기법 svm_1.PNG 주요 용어 svm_2.PNG 경계선을 정하는 기준 아래 그림처럼 다양한 경계선이 생성될 수 있다. 어떠한 경계선을 선택하는 것이 옳을까?\nsvm_3.PNG margin이 크다는 의미는 경계선의 폭이 크다는 의미로 새로운 데이터 값이 들어오는 경우에 margin의 클 수록 더 정확한 분류가 가능 커널 트릭 커널 트릭이란 저차원 -> 고차원 공간으로 매핑하는 작업을 말한다. 아래 그림과 같이 경계선을 생성 불가능 할때 주로 사용.\nsvm_4.PNG 주요 파라미터 C C는 오분류된 데이터의 허용 정도를 의미하며 이 값이 작을수록 많이 허용하고 높을 수록 적게 허용한다. 이로 인해 C값이 작으면 경계선 모양이 직선에 가까우며 높을 수록 여러겹의 굽은 선에 가깝다. Gamma 각 데이터가 영향을 주는 정도를 나타내며 Gamma 값이 낮아…","fields":{"slug":"/ML/[ML] SVM/"},"frontmatter":{"categories":"ML","title":"SVM","date":"September 17, 2022"}},"next":{"fields":{"slug":"/ML/[ML] Naive_Bayes/"}},"previous":{"fields":{"slug":"/ML/[ML] RandomForest/"}}},{"node":{"id":"ff193421-b6e2-575c-9d2a-4b47424d3d44","excerpt":"Naive Bayes 소개 나이브 베이즈란 베이즈 정리를 기반으로 한 분류 알고리즘. 단순하고 빠르며 정확도도 갖춘 알고리즘이지만 변수들간의 독립성이라는 조건이 만족되어야 한다. 베이즈 정리 데이터라는 조건이 주어졌을 때 조건부확률을 구하는 공식으로 새로운 정보로 인해 기존의 값이 어떻게 영향을 받는 지 알 수 있다. 사전 확률 P(A) 조건부 확률 (사후 확률) ${P(A|B)  = {P(A \\cap B) \\over P(B)} = {P(B|A)P(A) \\over P(B)}}$ 예시 : x켓몬 빵 구매 근처 편의점에 x켓몬 빵을 사러 갔을 때 구입 유무에 대한 표이다. 위 표를 근거로 점심에 편의점에 갔을 때 x켓몬 빵을 살 확률은? nb_1.PNG 예제: 라면사 분류 Reference [1] https://datascienceschool.net/02%20mathematics/06.06%20%EB%B2%A0%EC%9D%B4%EC%A6%88%20%EC%A0%95%EB%A6%AC.ht…","fields":{"slug":"/ML/[ML] Naive_Bayes/"},"frontmatter":{"categories":"ML","title":"Naive_Bayes","date":"September 17, 2022"}},"next":{"fields":{"slug":"/ML/[ML] Cross_Validation/"}},"previous":{"fields":{"slug":"/ML/[ML] SVM/"}}},{"node":{"id":"3d8213a9-81c8-51fb-b8d4-e1c46eebff19","excerpt":"교차 검증 고정된 학습 데이터와 테스트 데이터로 평가를 하면 과적합의 문제가 발생한다. 이를 방지하기 위해 교차검증이라는 방식을 사용하여 과적합을 방지한다. K-Fold 학습 데이터를 K 개의 Fold로 나누고 나누어진 폴드 중 하나를 검증용, 나머지를 학습용으로 선정한 뒤 위 그림처럼 검증용 폴드를 변경하면서 학습과 검증을 수행하는 것.  대표적인 클래스로 KFold, Stratified k-fold, Cross_val_score가 있다. 좋은 파라미터를 찾는 법  예시: 중산층 분류하기 데이터셋 준비 K-Fold Stratified k-fold 아래 그림과 같이 target값이 불균형한 분포를 가진 데이터 집합을 위한 방식으로 target 분포와 비슷한 비율 (예제의 경우 3:1)로 학습 데이터와 테스트 데이터셋에 분배한다.  Cross_val_score 위의 KFold, StratifiedKFold와 같은 방식도 있지만 더 편하게 할 수 있는 방법이 corss_val_scor…","fields":{"slug":"/ML/[ML] Cross_Validation/"},"frontmatter":{"categories":"ML","title":"Cross_Validation","date":"September 14, 2022"}},"next":{"fields":{"slug":"/Python/[python] 리스트/"}},"previous":{"fields":{"slug":"/ML/[ML] Naive_Bayes/"}}},{"node":{"id":"bc7ba2a2-24a0-5802-bb94-0e7275e5e1c4","excerpt":"list () 목차: 상품 리스트 중첩 리스트 상품리스트 의류와 신발을 판매하는 상점에서 판매 리스트를 작성하자. 상품 리스트 생성 상품 명 변경 새로운 상품 추가 상품 제거 3.새로운 아이템 추가 특정 아이템 제거하기 중첩 리스트 Rerference https://docs.python.org/ko/3/tutorial/datastructures.html","fields":{"slug":"/Python/[python] 리스트/"},"frontmatter":{"categories":"Python","title":"리스트","date":"August 17, 2022"}},"next":{"fields":{"slug":"/Python/[python] 예외처리/"}},"previous":{"fields":{"slug":"/ML/[ML] Cross_Validation/"}}},{"node":{"id":"39f46021-6511-5940-99a9-707c9f28895b","excerpt":"예외 처리 오류 및 예외 처리방법 아래의 예제에서는 숫자를 입력하고 그 숫자가 소수인지 판별하고 소수가 아닌 경우 에러를 발생시키는 코드이다. try, except, else, finally ZeroDivisionError 에러에 저장된 텍스트 출력 예제: 포켓몬인가요? 예제: 소수인가요? 100미만의 숫자를 입력하여 소수인지 판별하는 함수 Reference https://wikidocs.net/30","fields":{"slug":"/Python/[python] 예외처리/"},"frontmatter":{"categories":"Python","title":"예외처리","date":"August 16, 2022"}},"next":{"fields":{"slug":"/Python/[python] 이메일 전송/"}},"previous":{"fields":{"slug":"/Python/[python] 리스트/"}}},{"node":{"id":"9b4e464b-fddd-5562-9178-7ab3b7a46fc7","excerpt":"이메일 전송 사전 준비 라이브러리 설치 smtplib과 email 라이브러리를 설치 발신 이메일 SMTP 설정하기 네이버의 경우 네이버메일 -> 환경설정 -> POP3/IMAP 설정 클릭 -> IMAP/SMTP 설정 클릭 -> 사용함 선택 -> 확인 클릭 후 -> SMTP 서버명과 SMTP 포트를 확인해야함 ※ POP3와 IMAP은 이메일 받을 때의 프로토콜, SMTP는 이메일 보낼 때의 프로토콜 텍스트 이메일 보내기 다양한 종류의 파일 보내기 MIMEText 함수 (텍스트로 구성된 이메일을 보낼 경우) MIMEImage 함수 (이미지를 보낼 경우) MIMEAudio 함수 (오디오를 보낼 때) MIMEBase 함수 (그 외) MIMEMultipart 함수 (다양한 종류의 메시지를 한번에 보내고 싶은 경우)","fields":{"slug":"/Python/[python] 이메일 전송/"},"frontmatter":{"categories":"Python","title":"이메일 전송","date":"August 15, 2022"}},"next":{"fields":{"slug":"/Python/[python] 전역 변수/"}},"previous":{"fields":{"slug":"/Python/[python] 예외처리/"}}},{"node":{"id":"53a4ad21-1300-561b-9a58-81679325a4be","excerpt":"전역 변수 전역 변수를 이용하여 분석 과정에 사용할 변수 생성 및 변수를 지정하자 이제 [국가명, 년도] 로 년도별로 변수를 지정해보자.","fields":{"slug":"/Python/[python] 전역 변수/"},"frontmatter":{"categories":"Python","title":"전역 변수","date":"August 14, 2022"}},"next":{"fields":{"slug":"/Python/[python] 튜플/"}},"previous":{"fields":{"slug":"/Python/[python] 이메일 전송/"}}},{"node":{"id":"f7f3a54b-d6fc-53a4-ba30-a2c74ee0c498","excerpt":"튜플 튜플이란? 튜플은 간단하게 말해 변경이 안되는 리스트로 보면 된다. 또한 ()를 통해 구성한다. 리스트의 방식으로 튜플에서 추가 및 제거는 안된다. 튜플 추가하기 그럼에도 튜플을 추가할 수 있는 방법은 tuple + tuple이라는 방법이 있다. 단!! 요소가 하나인 튜플은 튜플로 정의되지 못한다. ex) (‘태양’)은 튜플이 아니다. 튜플은 추가 및 제거가 안된다는 것 외에는 리스트와 동일한 기능을 지원한다.","fields":{"slug":"/Python/[python] 튜플/"},"frontmatter":{"categories":"Python","title":"튜플","date":"August 12, 2022"}},"next":{"fields":{"slug":"/Python/[python] 특수문자 제거하기/"}},"previous":{"fields":{"slug":"/Python/[python] 전역 변수/"}}},{"node":{"id":"83592f69-9756-5adb-9483-40f2f2cf62b1","excerpt":"특수문자 제거하기 데이터 전처리 과정에서 많이 하는 일 중 하나가 특수문자 제거 혹은 다른 값 대체하는 것 replace re 모듈 대체로 replace 보다는 re 모듈을 사용해서 문자열을 제외한다. 1. 문자열 2. 리스트 주의! 만약 아래와 같은 에러 코드가 발생한다면 리스트를 str(list)로 변환하면 된다. TypeError: expected strings or bytes-like object 제외 혹은 대체해야할 대상이 많은 경우 리스트로 만들어 위 과정을 한번에 진행 가능하다. 3. DataFrame 제품의 제조사 및 불필요 단어 제외하기","fields":{"slug":"/Python/[python] 특수문자 제거하기/"},"frontmatter":{"categories":"Python","title":"특수문자 제거하기","date":"August 11, 2022"}},"next":{"fields":{"slug":"/PySpark/[PySpark] 숙박업 분석하기 (3) - MLlib/"}},"previous":{"fields":{"slug":"/Python/[python] 튜플/"}}},{"node":{"id":"e47b0147-862b-5b04-8e95-af2e4574f2d1","excerpt":"이번 장에서는 전 장에서 진행한 자료를 가지고 Pyspark의 ML 라이브러리를 활용하여 폐업 가능확률을 알아보자 변수 선택 및 변환 불필요한 칼럼 제외 (번호, 사업장명, start_year, end_year) 날짜형으로 데이터 변환 Label Encoding 범주형 변수 처리하기 아래는 총 3가지 과정으로 진행 StringIndexer 범주형 변수를 인덱싱하여 0.0 , 1.0, 2.0 과 같은 번호로 인덱싱 OneHotEncoder 인덱싱한 값은 0,1,2 와 같이 값으로써 크기를 가지기 때문에 OneHotEncoder를 사용하여 값의 크기를 갖지 않도록 변환 VectorAssembler 인코딩한 값을 벡터로 모으기 평가 Reference https://www.kaggle.com/code/fatmakursun/pyspark-ml-tutorial-for-beginners https://spark.apache.org/docs/3.1.1/api/python/reference/api…","fields":{"slug":"/PySpark/[PySpark] 숙박업 분석하기 (3) - MLlib/"},"frontmatter":{"categories":"Data_Analysis","title":"숙박업 분석하기 (3) - MLlib","date":"April 21, 2022"}},"next":{"fields":{"slug":"/PySpark/[PySpark] 숙박업 분석하기 (2) - EDA/"}},"previous":{"fields":{"slug":"/Python/[python] 특수문자 제거하기/"}}},{"node":{"id":"93df98a5-2415-5d89-80b6-5aa5f9e26d18","excerpt":"이번 장에서는 전처리가 완료된 숙박업 데이터 EDA를 통해 숙박업 상태를 간략히 알아보자 toPandas()를 활용하여 EDA를 진행하자 갱신일자 확인하기 분석을 진행하기전 갱신일자 현황을 알아보자 위 자료는 2018년도 8월부터 2022년도 3월까지 특정주기로 갱신된 데이터인 것을 확인 1.영업 상태와 폐업상태 건수를 알아보자 상세영업상태명을 영업, 폐업, 휴업 3가지로 분류 ※ 영업, 휴업을 제외한 자료는 모두 폐업으로 분류  2.운영기간의 분포를 파악하자 운영기간이라는 새로운 변수를 아래와 같은 식을 통해 생성 운영기간(년도) = 폐업기간 - 인허가일자를 통해 운영기간을 구함 우선 인허가일자와 폐업기간 속 오류를 정정하는 작업 시행 운영기간을 아래와 같이 구분하여 비율을 파악해보자 5년이하, 6~10년도, 11년-20년, 21년-30년, 31년-40년, 41년이상  3. 숙박업이 발달한 지역 알아보기 5_1.PNG 세종시,창원시, 경남 고성군의 경우 아래와 같이 구글맵에서 나…","fields":{"slug":"/PySpark/[PySpark] 숙박업 분석하기 (2) - EDA/"},"frontmatter":{"categories":"Data_Analysis","title":"숙박업 분석하기 (2) - EDA","date":"April 21, 2022"}},"next":{"fields":{"slug":"/PySpark/PostgreSQL과 연동하기/"}},"previous":{"fields":{"slug":"/PySpark/[PySpark] 숙박업 분석하기 (3) - MLlib/"}}},{"node":{"id":"e0151f47-d704-5b50-b1e8-ba698656e3a4","excerpt":"아래의 과정에 대한 자세한 내용은 아래의 사이트를 참조 바랍니다. https://han-depository.tistory.com/47 PostgreSQL 접속 정보 SparkSession 연동하기 DB 속 table 호출하기 2.PNG 3.PNG Parquet 불러오기 숙박업 분석 과정에서 저장된 parquet을 호출하여 PostgreSQL에 저장하자. 4.PNG DB에 table 업로드하기 5.PNG Reference https://urame.tistory.com/entry/Spark-PostgreSQL-%EC%97%B0%EB%8F%99-%EB%B0%A9%EB%B2%95-jdbc-spark-sql https://spark-korea.github.io/docs/sql-data-sources-jdbc.html PostgreSQL 접속 정보 SparkSession 연동하기 DB 속 table 호출하기 Parquet 불러오기 DB에 table 업로드하기 Reference","fields":{"slug":"/PySpark/PostgreSQL과 연동하기/"},"frontmatter":{"categories":"Study","title":"PostgreSQL 연동하기","date":"April 21, 2022"}},"next":{"fields":{"slug":"/PySpark/[PySpark] 숙박업 분석하기 (1)- 데이터 수집 및 전처리/"}},"previous":{"fields":{"slug":"/PySpark/[PySpark] 숙박업 분석하기 (2) - EDA/"}}},{"node":{"id":"16b04a9c-e9ed-5a95-9ff7-b55f23dd2013","excerpt":"진행 과정 SparkSession 생성 데이터 불러오기 Union 하여 하나의 DataFrame으로 만들기 Schema로 확인 결측값 처리하기 Parquet으로 저장하기 SparkSession 생성 데이터 불러오기 각 csv파일마다 컬럼 목록이 다르므로 csv파일마다 공통된 컬럼과 분석에 적합한 항목들을 선택한 뒤 진행 번호|개방자치단체코드|사업자명|인허가일자|상세영업상태명|폐업일자|소재지면적|데이터갱신일자|건물지상층수|건물소유구분명| Union 하여 하나의 DataFrame으로 합치기 Schema 확인하기 결측치 처리하기 Null 값이 있는 칼럼은 아래와 같이 처리 개방서비스명 - ‘숙박업’으로 대체 (제일 많은 비율을 차지) 사업자명 - ‘알수없음’으로 대체 개방자치단체코드 - ‘999’로 대체. 추후 알수없음으로 교체 상세영업상태명 - ‘영업중’으로 대체 인허가일자 - 데이터의 평균을 구한 뒤 근접한 날짜로 대체 폐업일자 - 데이터 기준 날짜로 변경 (2022.03.11) 시…","fields":{"slug":"/PySpark/[PySpark] 숙박업 분석하기 (1)- 데이터 수집 및 전처리/"},"frontmatter":{"categories":"Data_Analysis","title":"숙박업 분석하기 (1) - 데이터 수집 및 전처리","date":"April 20, 2022"}},"next":{"fields":{"slug":"/DataStudio/DataStudio 사용하기/"}},"previous":{"fields":{"slug":"/PySpark/PostgreSQL과 연동하기/"}}},{"node":{"id":"a4f830e4-5329-527c-931f-59127371d16c","excerpt":"DataStudio 사용하기 logo.PNG DataStudio란? 구글에서 제공하는 시각화 도구로 양방향 대시보드와 데이터 시각화 보고서를 제작하는데 사용된다. 특징 무료 쉬운 사용법 여러가지 플랫폼과 연결이 쉬움 (다양한 방법으로 데이터소스 사용가능) 복잡한 조건도 사용 가능 데이터 양이 많아지는 경우 프로그램 속도가 느려짐 1. 사이트 접속하기 아래의 사이트를 통해 접속할 수 있으며 구글 계정을 로그인 하는 것으로 사용이 가능하다. https://datastudio.google.com/ 2_1.PNG DataStudio는 위와 같이 다양한 형태의 보고서 형식을 제공하며 아래와 같이 다양한 플랫폼을 통해 데이터를 연결할 수 있다. 2_2.PNG 2. DataStudio 살펴보기 DataStudio에서 제공하는 Sample 데이터의 구조를 파악한 뒤 보유하고 있는 데이터로 DataStudio를 사용하자. Sample 데이터 구조 확인하기 (World Population) 3_3.…","fields":{"slug":"/DataStudio/DataStudio 사용하기/"},"frontmatter":{"categories":"Study","title":"DataStudio 사용하기","date":"March 01, 2022"}},"next":{"fields":{"slug":"/Study/Numpy/"}},"previous":{"fields":{"slug":"/PySpark/[PySpark] 숙박업 분석하기 (1)- 데이터 수집 및 전처리/"}}},{"node":{"id":"ba806a0b-f511-5a0f-ac63-94c5b46c41b1","excerpt":"Numpy의 함수를 사용한 서바이벌 게임 Numpy 1_1.PNG Numpy는 파이썬에서 선형대수 기반의 프로그램을 쉽게 만들 수 있도록 지원하는 패키지이며 루프를 사용하지 않고 대량의 데이터를 배열 연산을 통해 빠른 연산속도를 보장합니다. 예제 [오징어게임] 1_2.PNG\n출처: 넷플릭스 오리지널 드라마 오징어 게임/ 사진 = 넷플릭스 드라마 오징어게임 속 상황처럼 넘파이 배열에는 1~456번의 번호가 할당되어 있으며 라운드별 규칙에 따라 한명의 최후의 생존자가 남을 때까지 라운드를 진행한다. 모집 1~456번까지의 인원이 모여있다. np.arange : numpy의 ndarray를 생성하는 방법으로 np.arnage(n,m)로 호출할 경우 배열에 n~m-1까지의 호출 Round1 :7의 배수와 11의 배수 번호는 제외한다. 게임을 통해 7의 배수와 11의 배수의 번호를 갖고 있는 사람이 탈락했다. Numpy 인덱스 mul_7 그룹과 mul_11 그룹을 합침 r_ 사용. Roun…","fields":{"slug":"/Study/Numpy/"},"frontmatter":{"categories":"Study","title":"Numpy 함수를 사용한 서바이벌 게임","date":"February 25, 2022"}},"next":{"fields":{"slug":"/TFT_Champion_Detection/object_detection/"}},"previous":{"fields":{"slug":"/DataStudio/DataStudio 사용하기/"}}},{"node":{"id":"53d934df-39b8-5bb1-a2a5-8aba8c2dd814","excerpt":"Yolov5를 활용한 TFT 챔피언 객체 탐지 프로젝트 진행 과정    이 페이지에서는 진행과정의 2,4,5의 과정을 기록 더 자세한 진행 과정은 아래의 사이트에 기록 https://han-depository.tistory.com/40?category=1005490 Step2. 영상을 프레임으로 나누기 기억해야 할 점 코덱이 있어야 동영상을 저장할 수 있다. 윈도우 os 상에서는 DIVX 코덱을 사용한다. VideoWriter에서 프레임 수를 지정할 수 있다. cap.get(1)으로 프레임수를 확인 및 mod를 사용하여 프레임 수를 제한할 수 있다. 윈도우 64bit에서 waitKey를 사용할 때 0xFF를 같이 사용한다. Step4. Yolov5를 이용해 객체 인지 학습 아래의 과정은 Colab 환경에서 진행 Yolov5 Yolo란? 실시간으로 물체 인식이 가능한 모델로 객체 인식에 분야에서 제일 잘 알려진 모델 1.PNG 특징 1.이미지 전체를 한번만 본다.\nYolo가 나오기 …","fields":{"slug":"/TFT_Champion_Detection/object_detection/"},"frontmatter":{"categories":"Toy-Project","title":"TFT_Champion_Detection","date":"February 22, 2022"}},"next":{"fields":{"slug":"/TFT_Champion_Detection/jpg_to_mp4/"}},"previous":{"fields":{"slug":"/Study/Numpy/"}}},{"node":{"id":"ab95c526-882e-5ae5-aff3-87a2bf840764","excerpt":"프레임 단위로 나뉘어진 jpg를 mp4로 변환하는 방법 ffmpeg를 사용하여 프레임을 mp4로 만들 수 있다. Reference https://syki66.github.io/blog/2021/04/18/picture-to-video.html","fields":{"slug":"/TFT_Champion_Detection/jpg_to_mp4/"},"frontmatter":{"categories":"Study","title":"jpg to mp4","date":"February 22, 2022"}},"next":{"fields":{"slug":"/GPT-3_Chatbot/Chat_with_GPT3_git/"}},"previous":{"fields":{"slug":"/TFT_Champion_Detection/object_detection/"}}},{"node":{"id":"386800cd-a34b-5b12-93a2-7bcd6e9b4ff1","excerpt":"아래의 코드는 Colab 환경에서 진행하였습니다. 기획 1.PNG 파파고 국가별 언어 한국어 - ko 영어 - en 중국어간체 - zh-CN 중국어번체 - zh-TW 일본어 - ja 인도어 - hi 스페인어 - es 베트남어 - vi 프랑스어 - fr 독일어 - de 포르투칼어 - pt 인도네시아어 - id 페르시아어 - fa 아랍어 - ar 러시아어 - ru 미얀마어 - mm 태국어 - th 이탈리아어 - it 다국어 챗봇 만들기 2.PNG temperature 변화에 따른 응답 확인하기 3.PNG 4.PNG 챗봇 만들기 GPT3의 학습 능력 및 응답기능과 파파고의 번역기능을 활용하여 다국적 언어로 구현 가능한 챗봇을 만들어보자. 시나리오 5.PNG 위 상황에 대한 질문과 응답을 듣기 위해 GPT-3 용 sandbox를 git 하자. 6.PNG 7.PNG 8.PNG 주의사항 GPT-3의 경우 일정 token 이상 사용할 경우 결제를 해야합니다. 하지만 아래와 같이 한국의 신용카드…","fields":{"slug":"/GPT-3_Chatbot/Chat_with_GPT3_git/"},"frontmatter":{"categories":"Toy-Project","title":"Chat_with_GPT3","date":"February 20, 2022"}},"next":{"fields":{"slug":"/Dacon/집값 예측/"}},"previous":{"fields":{"slug":"/TFT_Champion_Detection/jpg_to_mp4/"}}},{"node":{"id":"3aa2f2ab-db61-5f78-a5ea-45e2be30ccba","excerpt":"1.데이터 로드하기 <svg xmlns=”http://www.w3.org/2000/svg” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n\n\n\n <svg xmlns=”http://www.w3.org/2000/svg” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n\n\n\n <svg xmlns=”http://www.w3.org/2000/svg” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n\n\n\n - NA 확인하기 2. EDA - target 변수 확인하기  target의 분포를 확인해보면 이상치의 영향으로 왜도 값이 1.71로 기울어져 있는 것 같다. np.log 변환을 하기 전에 변환 과정으로 정규화 되는 지 먼저 확인해보자.  np.log를 한 결과 대부분의 값들이 정규화된 것을 확인  - 숫자형 변수 확인하기  - 범주형 자료 확인하기  - 변수 간의 상관관계를 파악하…","fields":{"slug":"/Dacon/집값 예측/"},"frontmatter":{"categories":"Data_Analysis","title":"Predict HousePrice","date":"January 21, 2022"}},"next":{"fields":{"slug":"/Dacon/영화리뷰_감성분석/"}},"previous":{"fields":{"slug":"/GPT-3_Chatbot/Chat_with_GPT3_git/"}}},{"node":{"id":"94555522-b94e-526d-aedc-3b82b7eda0f9","excerpt":"1.데이터 로드하기 <svg xmlns=”http://www.w3.org/2000/svg” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n\n\n\n <svg xmlns=”http://www.w3.org/2000/svg” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n\n\n\n train , test 데이터 크기 확인 <svg xmlns=”http://www.w3.org/2000/svg” height=“24px”viewBox=“0 0 24 24”\nwidth=“24px”>\n\n\n\n 데이터는 id, document, label 3가지로 구성되어 있으며 label = 0은 부정적인 평가, label = 1 은 긍정적인 평가를 나타내는 칼럼 2.데이터 정제하기 데이터 중복 유무 확인하기 원래 데이터 크기가 5000이기 때문에 중복 값이 없는 것을 확인 Nan 값 제거 Na 값이 없는 것을 확인 데이터 레이블 값의 분포 확인 …","fields":{"slug":"/Dacon/영화리뷰_감성분석/"},"frontmatter":{"categories":"Data_Analysis ML","title":"영화 리뷰_감성분석","date":"January 21, 2022"}},"next":{"fields":{"slug":"/Study/데이터 마이닝/"}},"previous":{"fields":{"slug":"/Dacon/집값 예측/"}}},{"node":{"id":"5ffe071b-41ad-50c8-a62d-a8eb8a085851","excerpt":"- 정의 대량의 데이터로부터 의미 있는 패턴과 규칙을 발견하기 위해 탐색과 분석을 하는 비즈니스 프로세스 - 유형 1. 가설 검정 가설검정이란 데이터를 수집하고 분석해 가설을 설정하고 이 가설 여부가 합당한지 판정하는 과정 2. 방향성 데이터 마이닝 하향식 접근 방법으로서 원하는 것이 무엇인지 명확할 때 수행하는 데이터 마이닝. 즉 목표 속성을 가지고 그 속성의 값을 찾기 위해 수행하는 데이터 마이닝 ex) 회사를 이탈하는 고객은 누구인가? 3. 무방향성 데이터 마이닝 상향식 접근 방법으로서 목표 속성을 정하지 않고 레코드 간 또는 속성 간의 관계를 찾고자 할 때 수행하는 데이터 마이닝 ex) 장바구니에 동시에 담는 제품은 어떤 것들인가? - 단계 (분석 파이프라인) KDD 방법론 방법론으로 KDD, CRISP-DM 등 다양한 방법이 있지만 이 경우 KDD를 소개한다. 1. 대상 문제 파악 2. 데이터 선정 분석 대상이 되는 데이터 집합을 선정하고, 사용할 부분 집합과 속성을 정한…","fields":{"slug":"/Study/데이터 마이닝/"},"frontmatter":{"categories":"Study","title":"Data Mining","date":"January 21, 2022"}},"next":{"fields":{"slug":"/Study/데이터 사이언티스트 역량/"}},"previous":{"fields":{"slug":"/Dacon/영화리뷰_감성분석/"}}},{"node":{"id":"36497ebe-33d3-593c-9cc1-96655454d904","excerpt":"- 데이터 사이언스란? 과학적 방법, 프로세스, 알고리즘, 시스템을 사용해 다앙한 형식의 데이터로부터 지식과 통찰력을 추출하는 융합 분야. 데이터 사이언티스트가 되기 위한 역량 4가지 1. 데이터 애널리틱스 통계학, 머신러닝 등의 기법을 활용하는 능력 2. 프로그래밍과 데이터베이스 컴퓨터 기초지식, 선형대수, 프로그래밍 언어(파이썬, R등), 데이터베이스(SQL,NoSQL등), 빅데이터(MapReduce, Hadoop 등), 시각화 도구. 3. 해당 영역의 지식과 정서적 지능 기업 운영에 대한 지식, 데이터에 대한 관심, 문제를 해결하려는 성격, 전략적-주도적-창의적-혁신적-협력적 품성, 새로운 기술에 도전하려는 마음가짐. 4. 의사소통 능력 협업하는 능력, 능숙한 발표 능력, 데이터로부터 도출한 지식과 통찰력을 의사결정으로 변환하는 능력, 시각적 표현 능력","fields":{"slug":"/Study/데이터 사이언티스트 역량/"},"frontmatter":{"categories":"Study","title":"데이터 사이언티스트 역량","date":"January 21, 2022"}},"next":{"fields":{"slug":"/GDP_Analysis/GDP Analysis [1] - GDP/"}},"previous":{"fields":{"slug":"/Study/데이터 마이닝/"}}},{"node":{"id":"7ca6d05f-c3f7-544a-8b6f-05aac50bdb64","excerpt":"GDP란 무엇인가? 한 나라의 영역 내에서 가계, 기업, 정부 등 모든 경제주체가 일정기간 동안 생산한 재화 및 서비스의 부가가치를 시장가격으로 평가하여 합산한 것으로 여기에는 비거주자가 제공한 노동, 자본 등 생산요소에 의하여 창출된 것도 포함되어 있다. (출처: 네이버 지식백과) 세계 GDP 수치 데이터 (출처) : https://data.worldbank.org/indicator/NY.GDP.MKTP.CD - 분석 과제 세계 GDP 자료를 분석하여 국가별 GDP 변화를 파악하고 GDP 변화에 패턴이 있는 지 파악해보자. - 데이터의 이해 분석에 사용되는 데이터는 위와 같이 266여개의 도시 및 국가별 GDP를 1960-2020년도까지 1billion($) 단위로 표기한 데이터로 Na 값은 0으로 표기됨 CountryName : 국가 및 도시 이름 CountryCode : 국가 코드 Indicator Name : 지표명 년도 (1960~ 2020) - EDA - OECD (경제…","fields":{"slug":"/GDP_Analysis/GDP Analysis [1] - GDP/"},"frontmatter":{"categories":"Data_Analysis","title":"GDP Analysis [1] - GDP","date":"January 20, 2022"}},"next":{"fields":{"slug":"/GDP_Analysis/GDP Analysis [3] - 군집 분석/"}},"previous":{"fields":{"slug":"/Study/데이터 사이언티스트 역량/"}}},{"node":{"id":"2f6cb43c-aef4-58a6-8a4d-c4260edd405a","excerpt":"비슷한 GDP, GDP 성장률을 가진 국가끼리 모아보자 - Merge GDP & GDP Growth - 시각화  - Trouble Shooting 위의 데이터에서 GDP가 80000 이상인 국가 및 도시가 발견되었다. GDP Analysis [1]에서 살펴봤듯 GDP 1위 국가는 미국으로 GDP가 20000이므로 무언가 이상한 데이터가 포함되었다는 것을 확인함 [1] 위와 같이 다른 경제 지표도 포함되어 있는 것을 확인. 위 분석의 목적은 국가 및 도시를 대상으로 분석을 진행하는 것이기 때문에 gdp_2020.csv 파일에서 직접 제거함  미국과 중국의 GDP가 다른 국가에 비해 너무 크므로 제외함  위 plot을 통해 GDP가 큰 나라들도 마이너스 GDP 성장을 한 것을 알 수 있으며 GDP와 GDP Growth간의 상관관계도 딱히 보이지 않는 것을 볼 수 있다. - KMeans Cluster 알고리즘 1. 클러스터 수 (k)를 정하기 2. 반복 수 정하기 3. 클러스터 중심값을…","fields":{"slug":"/GDP_Analysis/GDP Analysis [3] - 군집 분석/"},"frontmatter":{"categories":"Data_Analysis ML","title":"GDP Analysis [3] - 군집 분석","date":"January 20, 2022"}},"next":{"fields":{"slug":"/GDP_Analysis/GDP Analysis [2] - GDP Growth/"}},"previous":{"fields":{"slug":"/GDP_Analysis/GDP Analysis [1] - GDP/"}}},{"node":{"id":"6d125096-e992-5098-add6-a2ea78448f6c","excerpt":"GDP Growth (경제 성장율) 이란? GDP Growth = (올해 GDP - 작년 GDP) / 작년 GDP * 100 으로  표현하며 작년 대비 GDP의 증가율을 나타낸 것이다. 세계 GDP growth 데이터 (출처) https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG - 분석 과제 GDP 성장률를 파악하여 국가별로 GDP 성장 동향을 파악하고 2019년도와 2020년도 GDP 성장률을 비교하며 어떤 국가가 코로나로 인해 큰 피해를 입었는 지 파악해보자 - 데이터 설명 위 데이터는 266여개의 도시 및 국가의 GDP 성장률에 대해 표기된 데이터로 CountryName : 국가 및 도시 이름 CountryCode : 국가 코드 Indicator Name : 지표명 년도 (1960~ 2020) 2020년도의 GDP 성장률에 대한 통계치 1. 2020년도 GDP 마이너스 성장률 top10 국가 2. 2020년도 GDP 플러스 성장률…","fields":{"slug":"/GDP_Analysis/GDP Analysis [2] - GDP Growth/"},"frontmatter":{"categories":"Data_Analysis","title":"GDP Analysis [2] - GDP Growth","date":"January 20, 2022"}},"next":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [3] - QGIS 활용/"}},"previous":{"fields":{"slug":"/GDP_Analysis/GDP Analysis [3] - 군집 분석/"}}},{"node":{"id":"c10969a0-6e89-53ec-a56a-cce6f661c9b8","excerpt":"서울 생활이동 데이터 분석 (3)  - 시각화 (QGIS) QGIS를 활용하여 서울 생활이동 데이터 분석(2)에서 많은 사람들이 많이 방문하는 지역에 대해 시각적으로 확인해보자. QGIS에서 시군구 코드를 사용해야 함으로 원래 데이터를 활용하여 진행하자 Trouble Shooting!! QGIS의 행정구역 코드와 서울시 시군구 코드와 매칭이 되지 않는 문제가 발생하여 서울시 시군구 코드를 행정구역 코드에 맞춰 변경 Trouble Shooting!! QGIS를 사용하여 확인하는 도중 몇몇 구가 빠져있는 이유를 확인하였고 문제를 파악하던 중 지역구 코드 수정 과정 중에 중복되어 입력되어 있는 것을 확인함. 코드를 살펴봤지만 어떤 부분이 문제인지 찾지 못하여 위의 csv에서 이를 수정함 수정한 목록 : 서울시 종로구, 서울시 중구, 서울시 용산구, 서울시 동대문구, 서울시 성동구 3_4.PNG 3_2.PNG 3_3.PNG 이번엔 도착지에 대한 인구이동에 대해 시각화해보자. 3_5.PNG…","fields":{"slug":"/Seoul_Movement/Seoul_movement [3] - QGIS 활용/"},"frontmatter":{"categories":"Study","title":"서울 생활 이동 [3] - 데이터 시각화 (QGIS)","date":"January 19, 2022"}},"next":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [2]  - 데이터 분석/"}},"previous":{"fields":{"slug":"/GDP_Analysis/GDP Analysis [2] - GDP Growth/"}}},{"node":{"id":"3cf572dc-f36d-5b96-b4cc-54e3b5c787f8","excerpt":"서울 생활이동 데이터 분석 (2) 서울 생활이동 데이터분석(1) 결과물을 가지고 데이터 분석하자 - 분석 과제 1. 가장 많이 출발한 지역은 어디일까? 2. 가장 많이 도착한 지역은 어디일까? ※ 성별, 연령대에 따라 출발지, 도착지가 다를까? 3. 출퇴근 시간 대 이동 인구가 많은 지역은 어디일까? 4. 출퇴근 시간 대를 제외한 이동 인구가 많은 지역은 어디일까? 1. 가장 많이 출발한 지역은 어디일까? 2. 가장 많이 도착한 지역은 어디일까? ※ 성별, 연령별 따라 출발지와 도착지에 변화가 있을까? 성별에 따라 변화가 있는지 확인해보자 도착지도 확인해본 결과 결론 :  1. 성별에 따른 출발지 도착지 변화는 크게 없었다. 연령별에 따라 변화가 있을까? 연령대는 10대, 20-30대, 40-50대, 60대 이상으로 나눴다. 각 연령대별 출발지와 도착지를 모두 확인한 결과 결론 2. 연령대별 출발지와 도착지의 차이가 크지 않았다. 또한 강남구, 서초구, 송파구에 사람들이 많이 방문…","fields":{"slug":"/Seoul_Movement/Seoul_movement [2]  - 데이터 분석/"},"frontmatter":{"categories":"Data_Analysis","title":"서울 생활 이동 [2] - 데이터 분석","date":"January 19, 2022"}},"next":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [4] - 연관분석/"}},"previous":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [3] - QGIS 활용/"}}},{"node":{"id":"df840f27-5c98-58e7-ba08-8385a229e1e8","excerpt":"- 연관 분석 서울시의 생활이동 데이터의 출발지와 도착지 연관분석을 실시해보자 위의 사례를 통해 의미있는 결과를 얻으려면 이동량이 많은 부분만 추려야 한다. 따라서 10000건 이상인 경우의 이동형태만 추출한다. 위 과정이 워낙 많은 시간을 소요하는 과정이므로 pickle로 저장한 후 추후에 불러와서 사용 - Trouble Shooting 4_1.PNG - FP Growth 참고 사이트 :https://zephyrus1111.tistory.com/119 - 연관 분석 - Trouble Shooting - FP Growth","fields":{"slug":"/Seoul_Movement/Seoul_movement [4] - 연관분석/"},"frontmatter":{"categories":"Data_Analysis ML","title":"서울 생활 이동 [4] - 연관성 분석","date":"January 19, 2022"}},"next":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [1] - 데이터 설명 및 전처리/"}},"previous":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [2]  - 데이터 분석/"}}},{"node":{"id":"ada8ff7c-9d43-5d6f-8118-035ab7fb6e80","excerpt":"서울 생활이동 데이터 분석 (1) - 분석 과제 서울시 생활이동 데이터란? 언제 어디서 어디로 얼마나 이동하였는지, 소요시간은 얼마나 걸렸는지에 대한 데이터 ※ 동네산책과 같이 특정지점에서 체류시간이 짧은 이동 및 매우 가까운 근거리 이동은 제외 1_1.PNG - 데이터 설명 데이터에 적혀있는 항목은 아래와 같이 구성되어 있음 대상연월 : 데이터의 기록 날짜 요일 : 요일 도착 시간 : 도착 시군구 코드에 도착한 시간 출발 시군구 코드 : 추후에 서울시에서 제공한 시군구로 변환 (ex) 11010 -> “서울특별시 종로구”) 도착 시군구 코드 : 추후에 서울시에서 제공한 시군구로 변환 (ex) 11010 -> “서울특별시 종로구”) 성별 나이 : 5세 별로 끊어서 기록 이동유형 : H: 야간상주지, W: 주간상주지, E: 기타지역 평균 이동시간 이동인구 : KT의 휴대폰 데이터를 이용하여 한 개 이동의 출발지에서 도착지 간 이동한 인구수 - 데이터 전처리 1. 시간별 데이터를 하나…","fields":{"slug":"/Seoul_Movement/Seoul_movement [1] - 데이터 설명 및 전처리/"},"frontmatter":{"categories":"Data_Analysis","title":"서울 생활 이동 [1] - 데이터 설명 및 전처리","date":"January 18, 2022"}},"next":{"fields":{"slug":"/Month of Birth_Korea/월별 출생 수 분석 [1] - 한국 사례/"}},"previous":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [4] - 연관분석/"}}},{"node":{"id":"acd80440-34cb-5fd3-afcd-4278ddbefc7c","excerpt":"- 분석 과제 이번에는 출생일과 관련된 자료를 통해 어떤 달에 아이가 많이 태어나고 다른 달과 통계적으로 차이가 있는지 없는지를 알아보고 차이가 있다면 어떠한 요인이 그러한 결과를 만들었는 지 확인해보자. - 데이터 출처 데이터는 아래의 UN의 자료를 통해 수집하였음. 출처 : http://data.un.org/Data.aspx?d=POP&f=tableCode%3A55 - 데이터 분석 2015년부터 2019년까지 5년간의 출생데이터를 받았으며 csv파일에서 불필요한 컬럼과 text를 간단히 제거한 후 분석 진행 분석의 목적은 각 년도별 출생을 파악하는 것이 아닌 각 달별로 차이가 있는지를 파악하는 것이기 때문에 Month 별로 값을 더하자  위 데이터를 통해 1월에 생일을 가지는 사람이 제일 많고 12월에 태어난 아이들이 제일 적다는 것을 알 수 있다. 한달의 차이로 5만명의 차이라는 큰 격차가 발생한 이유가 무엇일까? 달 별로 출산율의 차이가 있는 지 확인하기 전에 임신한 달을 …","fields":{"slug":"/Month of Birth_Korea/월별 출생 수 분석 [1] - 한국 사례/"},"frontmatter":{"categories":"Data_Analysis","title":"월별 출생 수 분석 [1] - 한국 사례","date":"January 17, 2022"}},"next":{"fields":{"slug":"/Month of Birth_Korea/월별 출생 수 분석 [2] - 외국 사례/"}},"previous":{"fields":{"slug":"/Seoul_Movement/Seoul_movement [1] - 데이터 설명 및 전처리/"}}},{"node":{"id":"e8f84f81-dc41-57da-a6a3-77ffe41b62bb","excerpt":"- 분석 과제 월별 출생 수 분석1에 이어 외국 사례를 파악하여 월별 출생 건수에 대한 특징을 알아보자. 살펴볼 국가로는 미국, 일본, 독일, 필리핀, 남아프리카, 브라질, 호주를 선택하여 진행함. ( 중국, 인도는 UN에서 데이터를 제공하지 않으므로 제외) - 데이터 출처 데이터는 UN에서 제공한 데이터를 사용하여 분석 진행하였습니다. 데이터 출처 : http://data.un.org/Data.aspx?d=POP&f=tableCode%3A55 - 분석 진행 1. 미국의 출생이 많은 달은? 1.1요약 미국은 7월부터 9월에 태어나는 아이가 제일 많으며 2월, 4월이 제일 적게 태어났다. 또한 8월과 2월의 태어난 아이의 차이는 무려 30만으로 큰 차이가 보인다. 임신하는 달의 측면으로 보았을 때 11월이 제일 많았으며 특징으로 10월부터 1월 즉 연말에 많이 몰려있는 것을 볼 수 있다. 2.일본의 출생이 많은 달은? 2.1요약 일본도 미국과 비슷하게 7월부터 10월에 태어나는 아이…","fields":{"slug":"/Month of Birth_Korea/월별 출생 수 분석 [2] - 외국 사례/"},"frontmatter":{"categories":"Data_Analysis","title":"월별 출생 수 분석 [2] - 외국 사례","date":"January 17, 2022"}},"next":{"fields":{"slug":"/Month of Birth_Korea/월별 출생 수 분석 [3] - 회귀 분석/"}},"previous":{"fields":{"slug":"/Month of Birth_Korea/월별 출생 수 분석 [1] - 한국 사례/"}}},{"node":{"id":"817379e8-1d9b-5dbc-8868-7bd2f1e7b289","excerpt":"- 분석 과제 월별 출생 수 분석 (1), (2)에서 알게된 정보를 바탕으로 출생과 관련된 요인으로 월별 평균온도, 혼인신고 데이터를 받아 임신을 한 시점에 맞춰 연관성이 있는지 연관성 분석을 진행하겠다. - 데이터 1.한국 월별 출생 수 (2015~2019년도) 2.월별 평균 온도 (2015~2019) 3.혼인신고 데이터 - 회귀 분석 이번 분석을 통해 임신한 달과 관련성이 있다고 생각하는 요인 온도, 혼인건수 2개의 요인이 얼마나 설명력을 갖고 있는 지 살펴보자 그 전에 plot을 통해 상관성이 있는지 확인해보자   - 결론 위 그림에서 동그라미를 친 부분을 통해 아래와 같은 결론을 얻을 수 있다. 1.위 2가지 요소는 월별 임신한 수에 대한 34% 정도의 설명력을 가진다. 2.각 요소의 통계적 유의성은 p-value 0.05 이하에서 유의하다고 볼 수 있다. 3.위를 아래와 같은 식으로 나타낼 수 있다. 월별 임신한 수 = 8332.9 + 226.9 * 평균 온도 + 0.85…","fields":{"slug":"/Month of Birth_Korea/월별 출생 수 분석 [3] - 회귀 분석/"},"frontmatter":{"categories":"Data_Analysis","title":"월별 출생 수 분석 [3] - 회귀 분석","date":"January 17, 2022"}},"next":{"fields":{"slug":"/Frequency of Birth/Frequency of Birth Day/"}},"previous":{"fields":{"slug":"/Month of Birth_Korea/월별 출생 수 분석 [2] - 외국 사례/"}}},{"node":{"id":"b45ec051-fbe6-5684-8421-1e4425f51f37","excerpt":"분석 목적 이번 분석 목적은 단순히 어떤 날에 생일이 제일 많은 지 알아보는 분석이다. 데이터 수집 경로 대부분의 데이터는 하루치로 수치가 나오는 것이 아닌 Monthly로 데이터를 제공하기에 구글링을 하여 아래의 사이트를 통해 데이터를 제공받아 분석을 진행하였다. 아래의 데이터는 2000년부터 2014년의 출생 기록으로 미국 사회보장국에서 제공된 데이터이다. https://github.com/fivethirtyeight/data/tree/master/births - SSA 데이터 년도 별로 파악하기 2000년, 2004년, 2009년, 2014년도 생일 빈도수를 알아보자 출생이 많은 날 Top 5 11월 21일 > 9월 6일 > 12월 28일 > 7월 6일 > 9월 19일 순으로 나타남 출생이 적은 날 top 5 12월 25일 > 12월 24일 > 4월 23일 > 4월 2일 > 5월 14일 순으로 나타남     년도를 통합해서 알아보자  일별로 랭크를 매겨 순위를 알아보자","fields":{"slug":"/Frequency of Birth/Frequency of Birth Day/"},"frontmatter":{"categories":"Data_Analysis","title":"생일 빈도수 분석","date":"January 16, 2022"}},"next":null,"previous":{"fields":{"slug":"/Month of Birth_Korea/월별 출생 수 분석 [3] - 회귀 분석/"}}}],"categories":["All","DL","Study","Python","ML","Data_Analysis","Toy-Project"]}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}