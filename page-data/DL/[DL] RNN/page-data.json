{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/DL/[DL] RNN/",
    "result": {"data":{"cur":{"id":"0dc6c46f-3d22-5ef4-a42d-f985c327be59","html":"<h2 id=\"rnn\" style=\"position:relative;\"><a href=\"#rnn\" aria-label=\"rnn permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>RNN</h2>\n<p>이전 시점 정보(시계열 데이터)에 대해 적합한 인공신경망 모델</p>\n<h4 id=\"활용-분야\" style=\"position:relative;\"><a href=\"#%ED%99%9C%EC%9A%A9-%EB%B6%84%EC%95%BC\" aria-label=\"활용 분야 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>활용 분야</h4>\n<ul>\n<li>기계 번역</li>\n<li>음성 인식</li>\n<li>챗봇</li>\n<li>이미지/비디오 파악</li>\n<li>감성 분석</li>\n</ul>\n<h4 id=\"대표-알고리즘\" style=\"position:relative;\"><a href=\"#%EB%8C%80%ED%91%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98\" aria-label=\"대표 알고리즘 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>대표 알고리즘</h4>\n<p>대표적인 RNN 알고리즘으로 RNN(Vanilla), LSTM, GRU 등이 있다.</p>\n<h3 id=\"진행-과정\" style=\"position:relative;\"><a href=\"#%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95\" aria-label=\"진행 과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>진행 과정</h3>\n<p>RNN은 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징을 갖는다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 33.33333333333333%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAACOUlEQVQozyWRXUxSAQCFD1dZy4ycD/XkU7Uca5bZ+nE9NKpVtnpqszZdzSZKmlOBC8X1GmWFQIlL+dUrhC3x8mdi2J82+0EkgaZkW2VIf2Y9mFubb7eh5/E8nHO+HXAch5cVMoR1vuy4ziN4IbmKtNK+T1QCrrUHE3qv4H3bQPZC6wOEtB5BvJVdP3/Dgdea/g0xrTs7ofciqmWRd6AGGNLcy0yyEfyyDpR/MfsVc4F36Tz+Msdhcex7xitbEHOd7ppZk782agvgq9EjTloekpPWAJIdbP2s0SdJdLCYNfkydlR4V8ZkHq025FJ3ho8p1ff3Xfel1oopZpfaHt92URdEjTGaQxuelMgoprDU+WdNc/uzEwravvtsVzKLbnt8Uk47inr7EyBphlcoHlpFa7JP7Vcx0x9I6zRtef73IDO23Gcb/aeZ4jg0GEZOUT2Jj40dk/W12sHiJvtMqrEzRtbdDopUTCIlNUavpDNusT8ycrceAjbmCfgACLVLmk85JTu73/StlKR1+AjQ/vQ4bvoVQkXXhe0t7nJcY+VCyllVQPeWQu2SFqgcVUKZ+Tw0g1IewAPcKR3RHWtGd0xZZnurlDJxJUZ+2wjhGS8c03rCPN4EywQpMYfJamuEgiUsr+yavNxgi1AwhWR1lrBCbI0oYQrJCYKftYo8sriEee4cPJ8k6X9hGJ6DxvMTj75xOF3ph2tmL7yfLyEHd8GEt2B0SYXiPU60BzdjeKERLT0iMONlWLcpH/8Bv+QLm5OUQHgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"rnn_6.png\"\n        title=\"rnn_6.png\"\n        src=\"/static/4506af311185faaf6ea5e37dc1bc0964/37523/rnn_6.png\"\n        srcset=\"/static/4506af311185faaf6ea5e37dc1bc0964/e9ff0/rnn_6.png 180w,\n/static/4506af311185faaf6ea5e37dc1bc0964/f21e7/rnn_6.png 360w,\n/static/4506af311185faaf6ea5e37dc1bc0964/37523/rnn_6.png 720w,\n/static/4506af311185faaf6ea5e37dc1bc0964/302a4/rnn_6.png 1080w,\n/static/4506af311185faaf6ea5e37dc1bc0964/c1b63/rnn_6.png 1200w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span>\n출처 : <a href=\"https://ko.wikipedia.org/wiki/%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D\">https://ko.wikipedia.org/wiki/%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D</a></p>\n<h4 id=\"예시\" style=\"position:relative;\"><a href=\"#%EC%98%88%EC%8B%9C\" aria-label=\"예시 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>예시</h4>\n<p><img src=\"/5c2ccd3021e4e86ea316ac88af1d8d06/rnn_4.png\" alt=\"rnn_4.PNG\"></p>\n<h3 id=\"종류\" style=\"position:relative;\"><a href=\"#%EC%A2%85%EB%A5%98\" aria-label=\"종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>종류</h3>\n<ul>\n<li>Many to One</li>\n</ul>\n<blockquote>\n<p>순차적인 x값들로 하나의 y값을 예측</p>\n</blockquote>\n<ul>\n<li>One to many</li>\n</ul>\n<blockquote>\n<p>하나의 시점(이미지) x로 순차적인 y 값들을 예측</p>\n</blockquote>\n<ul>\n<li>Many to many</li>\n</ul>\n<blockquote>\n<p>순차적인 X 값들로 순차적인 y 값들을 예측</p>\n</blockquote>\n<p><img src=\"/e390954adcf20d505c1655f3a8a44a1c/rnn_2.png\" alt=\"rnn_2.PNG\">\n출처: <a href=\"http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf\">http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf</a></p>\n<h3 id=\"rnn-vanila-rnn-\" style=\"position:relative;\"><a href=\"#rnn-vanila-rnn-\" aria-label=\"rnn vanila rnn  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>RNN( Vanila RNN )</h3>\n<p><img src=\"/38cbbc7cd825845ceac0aed2e5c55782/rnn_3.png\" alt=\"rnn_3.PNG\"></p>\n<h3 id=\"lstm\" style=\"position:relative;\"><a href=\"#lstm\" aria-label=\"lstm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LSTM</h3>\n<p>기존 RNN 모델에 장기기억(long-term-memory)를 추가한 모델</p>\n<p><img src=\"/9f7211db34363b04a9400d44fb6c82eb/rnn_5.png\" alt=\"rnn_5.PNG\"></p>\n<h3 id=\"gru\" style=\"position:relative;\"><a href=\"#gru\" aria-label=\"gru permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GRU</h3>\n<p>LSTM 보다 간단한 구조지만 성능 면에서 밀리지 않는 RNN 모델</p>\n<p><img src=\"/02d85bd586ebbde56cefdecfe10ce42a/rnn_7.png\" alt=\"rnn_7.PNG\"></p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf\">http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf</a></p>\n<p>[2] <a href=\"http://dprogrammer.org/rnn-lstm-gru\">http://dprogrammer.org/rnn-lstm-gru</a></p>\n<p>[3] <a href=\"https://www.youtube.com/watch?v=8HyCNIVRbSU\">https://www.youtube.com/watch?v=8HyCNIVRbSU</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#rnn\">RNN</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%ED%99%9C%EC%9A%A9-%EB%B6%84%EC%95%BC\">활용 분야</a></li>\n<li><a href=\"#%EB%8C%80%ED%91%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98\">대표 알고리즘</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95\">진행 과정</a></p>\n<ul>\n<li><a href=\"#%EC%98%88%EC%8B%9C\">예시</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%A2%85%EB%A5%98\">종류</a></p>\n</li>\n<li>\n<p><a href=\"#rnn-vanila-rnn-\">RNN( Vanila RNN )</a></p>\n</li>\n<li>\n<p><a href=\"#lstm\">LSTM</a></p>\n</li>\n<li>\n<p><a href=\"#gru\">GRU</a></p>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</li>\n</ul>\n</div>","excerpt":"RNN 이전 시점 정보(시계열 데이터)에 대해 적합한 인공신경망 모델 활용 분야 기계 번역 음성 인식 챗봇 이미지/비디오 파악 감성 분석 대표 알고리즘 대표적인 RNN 알고리즘으로 RNN(Vanilla), LSTM, GRU 등이 있다. 진행 과정 RNN은 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징을 갖는다. \n출처 : https://ko.wikipedia.org/wiki/%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D 예시 rnn_4.PNG 종류 Many to One 순차적인 x값들로 하나의 y값을 예측 One to many 하나의 시점(이미지) x로 순차적인 y 값들을 예측 Many to many 순차적인 X 값들로 순차적인 y 값들을 예측 rnn_2.PNG\n출처: http://cs231n.stanford.edu/slides/2017/cs231n_2017…","frontmatter":{"date":"December 19, 2022","title":"RNN","categories":"DL","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/DL/[DL] RNN/"}},"next":{"id":"be92d91d-e2d7-51b6-b994-278f13dfd7dd","html":"<h2 id=\"cnn-architecture\" style=\"position:relative;\"><a href=\"#cnn-architecture\" aria-label=\"cnn architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CNN Architecture</h2>\n<h3 id=\"소개\" style=\"position:relative;\"><a href=\"#%EC%86%8C%EA%B0%9C\" aria-label=\"소개 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>소개</h3>\n<p>CNN Architecture란 CNN을 기반으로 한 모델 중 성능이 뛰어난 몇몇 모델의 구조를 말한다.</p>\n<p>대표적인 아키텍처로 AlexNet, VGG, GoogleNet, ResNet 등이 있다.</p>\n<h3 id=\"발전-과정\" style=\"position:relative;\"><a href=\"#%EB%B0%9C%EC%A0%84-%EA%B3%BC%EC%A0%95\" aria-label=\"발전 과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>발전 과정</h3>\n<p>ImageNet 데이터셋을 통한 년도별 성능 발전 상황을 살펴보면 2012년 AlexNet을 기점으로 CNN 구조의 여러 모델들이 높은 성능을 나타내며 발전하였다. 2016년도 이후로는 성능 향상보단 경량화, 효율화 과정을 통해 각 모델의 규모를 줄이는 데 초점을 맞춰 발전 해왔다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAABOklEQVQoz41S2W4DIQzc//+2vkZ9qFIpR5PsmQALBuOjYkmqpG3UjlY8eGfMjHEjIgAgf4GZc87CXD9ezkZVS/UJ9IaMOBvTD8Ox63Z9f+i63dAXMSL+LhOhnBPRDLAbxtXQb6Zp3bYvH/vVZnM6nxvnXErpXlRdYs4ecT0Mb127M2br3NHamNI0joft9jxN5nJpjDEPtolVNSC+nk5djFm1xCNiIiHKOUOMF2MAABHLzcX2EoyZN+N4dO4dQq5Zb3aIWW4FXCAiTe0hRC6lEZMtIRmJVISfTJGI6lDKwJhob21rbcq5Nlf5F4q4RFF5tKn3Y/9RvDKvT6WqCTEEqC1CACKqKwDwvZhSqszmaw3qGi0/gvceQojMPhQAQIzROVcbVeaDuKKSnHPz7A2idc57Py+w1nrv78mf4Cq+5YEzqFgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"cnnar_1.png\"\n        title=\"cnnar_1.png\"\n        src=\"/static/07d4b5b040679d2be33b1b37abd95d82/37523/cnnar_1.png\"\n        srcset=\"/static/07d4b5b040679d2be33b1b37abd95d82/e9ff0/cnnar_1.png 180w,\n/static/07d4b5b040679d2be33b1b37abd95d82/f21e7/cnnar_1.png 360w,\n/static/07d4b5b040679d2be33b1b37abd95d82/37523/cnnar_1.png 720w,\n/static/07d4b5b040679d2be33b1b37abd95d82/302a4/cnnar_1.png 1080w,\n/static/07d4b5b040679d2be33b1b37abd95d82/c1b63/cnnar_1.png 1200w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span>\n[출처] <a href=\"https://theaisummer.com/cnn-architectures/\">https://theaisummer.com/cnn-architectures/</a></p>\n<p>초반의 CNN 구조는 파라미터의 갯수를 증대시키는 방식으로 진행되었으나 현재 각 모델의 파라미터의 갯수와 성능은 아래의 표와 같이 언제나 비례하지 않는다.</p>\n<p><img src=\"/b43dd68dae65124854d7baf4f5d697a9/cnnar_5.png\" alt=\"cnnar_5.PNG\"></p>\n<h4 id=\"architecture-scaling\" style=\"position:relative;\"><a href=\"#architecture-scaling\" aria-label=\"architecture scaling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture Scaling</h4>\n<p>각 모델 구조는 아래 그림과 같이 넓게, 깊게, 넓고 깊게하는 방식으로 스케일링을 진행.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.55555555555556%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAABlUlEQVQoz3VRS4/TMBDOX+fHcEFw5cIJVgjtBWlZBFuo0jZpHNsZv+3YieMYOSkrIbQjnzzfa2aqdav8Qi3zBMff5OmH4yxtPwX8F1/9g90bz2+DcvxraB/myf3vUHnv3ehSSi+ZcziT/mme/JrzMgV5OavLeXamkPv2eq1Po7U55zhPwVjAhBEaRz9qnXPuGT6iY9qCpBQtHM1wSHEqZMd6TepdKcWoaatwzbujxicnWc55ELKhg9Fam4IB1tChXteStDIGAC7LppRz9qOQsuOsNRrP2+f9T/7mI0rzaExJR2SPFdpXVikrqUBLWm7k4IlAIBEoSKlAvtXi/X1XhlqK26dH/vYObyOsVUPcu7sujNY6t/M/fKWvXh+UvWVxzktRAsdYDB5r8fk7FPK6VtqGwwmsNdbaZdNusf7ygOZ4y2K0Y6DKzbeut16BIIR4H6oYFwEcACilQojSdoFjsV895xz8pKR9dnYuMKa67joMUDHGm6YJIew+0zRhjK9dx6Cs2nvfI4RQv+s653qEKKGMsRDCHxj7dUzQUmjeAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"cnnar_3.png\"\n        title=\"cnnar_3.png\"\n        src=\"/static/cfd4539de426a2a7ea8d6c6b1ef4db08/37523/cnnar_3.png\"\n        srcset=\"/static/cfd4539de426a2a7ea8d6c6b1ef4db08/e9ff0/cnnar_3.png 180w,\n/static/cfd4539de426a2a7ea8d6c6b1ef4db08/f21e7/cnnar_3.png 360w,\n/static/cfd4539de426a2a7ea8d6c6b1ef4db08/37523/cnnar_3.png 720w,\n/static/cfd4539de426a2a7ea8d6c6b1ef4db08/5205c/cnnar_3.png 833w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>[출처] <a href=\"https://theaisummer.com/cnn-architectures/\">https://theaisummer.com/cnn-architectures/</a></p>\n<h3 id=\"alexnet\" style=\"position:relative;\"><a href=\"#alexnet\" aria-label=\"alexnet permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>AlexNet</h3>\n<p>AlexNet은 2012년 ImageNet의 분류 대회에서 63% 정확도로 우승한 모델로 5개의 Conv 층과 3개의 Full Connect 층으로 구성</p>\n<p><img src=\"/5e7bc6d8926d90d027782c46f68c1027/cnnar_7.png\" alt=\"cnnar_7.PNG\">\n[출처]<a href=\"http://cs231n.stanford.edu/slides/2017/\">http://cs231n.stanford.edu/slides/2017/</a></p>\n<h4 id=\"주요-특징\" style=\"position:relative;\"><a href=\"#%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95\" aria-label=\"주요 특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>주요 특징</h4>\n<ul>\n<li>input 값을 256x256으로 resize</li>\n<li>tanh 대신 처음으로 RELU 활성화 함수 사용</li>\n<li>Norm layer 사용</li>\n<li>Data Augmentation을 통해 데이터셋 크기를 2048배 확장</li>\n<li>0.5의 확률로 뉴런이 네트워크에서 삭제. (드롭아웃)</li>\n</ul>\n<h4 id=\"구조\" style=\"position:relative;\"><a href=\"#%EA%B5%AC%EC%A1%B0\" aria-label=\"구조 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>구조</h4>\n<p><img src=\"/b6a85f9b1172f3d73e4037a28bca468e/cnnar_6.png\" alt=\"cnnar_6.PNG\"></p>\n<h3 id=\"vgg\" style=\"position:relative;\"><a href=\"#vgg\" aria-label=\"vgg permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VGG</h3>\n<p>VGG(Visual Geometry Group)는 다중 레이어가 있는 심층 CNN 구조로 대표적인 모델로 VGG-16, VGG-19가 있다. (VGG 뒤 번호는 각 모델의 layer의 수)</p>\n<p><img src=\"/1ac570a9f34197ae95fd893346b090d8/cnnar_11.png\" alt=\"cnnar_11.PNG\">\nVGG-16의 경우 13개의 Conv layer와 3개의 Full Connect Layer로 구성</p>\n<h4 id=\"주요-특징-1\" style=\"position:relative;\"><a href=\"#%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95-1\" aria-label=\"주요 특징 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>주요 특징</h4>\n<ul>\n<li>모델 입력값은 224x224</li>\n<li>3x3 커널만을 사용. 학습 진행시 kernels의 수가 2배씩 증가.</li>\n<li>엄청난 파라미터 수로 인해 학습 많은 학습 시간이 소요됨.</li>\n<li>다른 모델에 비해 다량의 메모리가 필요.</li>\n</ul>\n<h4 id=\"구조-1\" style=\"position:relative;\"><a href=\"#%EA%B5%AC%EC%A1%B0-1\" aria-label=\"구조 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>구조</h4>\n<p><img src=\"/bcb952b85e90d747b48f107db61fa48c/cnnar_12.png\" alt=\"cnnar_12.PNG\">\n[출처] <a href=\"http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf\">http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf</a></p>\n<h3 id=\"googlenet--inceptionnet\" style=\"position:relative;\"><a href=\"#googlenet--inceptionnet\" aria-label=\"googlenet  inceptionnet permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GoogleNet / InceptionNet</h3>\n<p>계산 효율성을 높인 더 깊은 네트워크.</p>\n<p>1x1, 3x3, 5x5 다양한 필터 사이즈를 사용한 네트워크.</p>\n<h4 id=\"inception-구조\" style=\"position:relative;\"><a href=\"#inception-%EA%B5%AC%EC%A1%B0\" aria-label=\"inception 구조 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inception 구조</h4>\n<p>GoogleNet은 Inception이라는 구조를 사용. Inception이란 1x1, 3x3, 5x5 Convolutions 를 결합한 module로 1x1 Convolutions을 통해 파라미터의 수를 축소 시킨 다음 3x3, 5x5 필터를 통해 진행</p>\n<p><img src=\"/c06b3ff6f941dd4ebbc23ae5cf7579be/cnnar_13.png\" alt=\"cnnar_13.PNG\"></p>\n<h4 id=\"다양한-필터-사이즈의-이점\" style=\"position:relative;\"><a href=\"#%EB%8B%A4%EC%96%91%ED%95%9C-%ED%95%84%ED%84%B0-%EC%82%AC%EC%9D%B4%EC%A6%88%EC%9D%98-%EC%9D%B4%EC%A0%90\" aria-label=\"다양한 필터 사이즈의 이점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>다양한 필터 사이즈의 이점</h4>\n<p><img src=\"/46637ea50599b4fa2ee839c8b98bac1a/cnnar_14.png\" alt=\"cnnar_14.PNG\"></p>\n<p>이미지에서 특징적인 포인트는 이미지 속 객체의 크기에 따라 큰 편차가 발생. 사이즈가 큰 필터를 사용하면 그림 2의 특징적인 부분이 그림 1에 비해 잘 파악하지 못하게 되며 이를 방지하기 위해 1x1, 3x3, 5x5와 같이 다양한 크기의 필터를 활용</p>\n<h4 id=\"주요-특징-2\" style=\"position:relative;\"><a href=\"#%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95-2\" aria-label=\"주요 특징 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>주요 특징</h4>\n<ul>\n<li>22 layers으로 구성</li>\n<li>Inception Module을 사용</li>\n<li>Full Connect layer를 사용하지 않음</li>\n<li>AlexNet 보다 12배 적은 파라미터</li>\n<li>다양한 크기의 필터 활용</li>\n</ul>\n<h4 id=\"구조-2\" style=\"position:relative;\"><a href=\"#%EA%B5%AC%EC%A1%B0-2\" aria-label=\"구조 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>구조</h4>\n<p><img src=\"/5460979b90a0079c7d95cfd64c75dbfd/cnnar_15.png\" alt=\"cnnar_15.PNG\"></p>\n<p>※ 보조 분류기란 심층 네트워크의 수렴을 개선하기 위해 사용.</p>\n<h3 id=\"resnet\" style=\"position:relative;\"><a href=\"#resnet\" aria-label=\"resnet permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ResNet</h3>\n<p>잔차 신경망(ResNet)은 Skip Connection을 통해 잔차를 학습하는 신경망. 152개의 layers으로 구성</p>\n<h4 id=\"기울기-소실\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EC%9A%B8%EA%B8%B0-%EC%86%8C%EC%8B%A4\" aria-label=\"기울기 소실 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기울기 소실</h4>\n<p>앞서 살펴본 AlexNet, VGG, GoogleNet을 보면 년도가 지날 수록 layer 층이 더 깊어지며 발전되어왔다. 심층 네트워크 모델의 깊이가 증가할 수록 복잡한 기능을 구현되어 모델의 성능이 향상된다. 하지만 더 많은 layers를 쌓는 과정에서 기울기 소실 문제가 발생되어 더 많은 layers 쌓아도 성능이 저하되는 문제가 발생한다.</p>\n<h4 id=\"잔차-블록\" style=\"position:relative;\"><a href=\"#%EC%9E%94%EC%B0%A8-%EB%B8%94%EB%A1%9D\" aria-label=\"잔차 블록 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>잔차 블록</h4>\n<p>심층 네트워크의 기울기 소실 문제를 잔차블록을 통해 보완했다. 잔차블록은 기존의 망에 입력 값을 출력값에 더해주는 길을 추가한 것.</p>\n<p>잔차블록의 핵심 아이디어는 기존의 방식의 결과값 H(x)와 입력값 x의 차이 F(x)를 0에 근사하도록 학습을 진행하는 방향으로 진행.</p>\n<p><img src=\"/da569266b22053106ba60dc874bb5247/cnnar_16.png\" alt=\"cnnar_16.PNG\"></p>\n<h4 id=\"주요-특징-3\" style=\"position:relative;\"><a href=\"#%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95-3\" aria-label=\"주요 특징 3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>주요 특징</h4>\n<ul>\n<li>잔차 블록 결합 층으로 구성</li>\n<li>주기적으로 필터 수를 2배로 증가, stride 2를 적용하여 다운샘플링 진행</li>\n<li>ResNet 50미만의 모델들은 3x3 Conv layers를 사용하지만 ResNet50 이상의 모델의 경우 계산 효율을 높이기 위해 bottleneck. 즉 1x1 Conv를 활용</li>\n</ul>\n<p><img src=\"/f5d307d47dce7289a2bcd2ec2dd06b5e/cnnar_17.png\" alt=\"cnnar_17.PNG\">\n[출처] <a href=\"http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf\">http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf</a></p>\n<h4 id=\"구성\" style=\"position:relative;\"><a href=\"#%EA%B5%AC%EC%84%B1\" aria-label=\"구성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>구성</h4>\n<p><img src=\"/c73f223d549a55b4ef09183505cee7c9/cnnar_18.jfif\" alt=\"cnnar_18.jfif\"></p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://www.youtube.com/watch?v=4AuCBqPvmcc&#x26;list=WL&#x26;index=3&#x26;t=131s\">https://www.youtube.com/watch?v=4AuCBqPvmcc&#x26;list=WL&#x26;index=3&#x26;t=131s</a></p>\n<p>[2] <a href=\"https://wikidocs.net/164335\">https://wikidocs.net/164335</a></p>\n<p>[3] <a href=\"https://theaisummer.com/cnn-architectures/\">https://theaisummer.com/cnn-architectures/</a></p>\n<p>[4] <a href=\"http://cs231n.stanford.edu/slides/2017/\">http://cs231n.stanford.edu/slides/2017/</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#cnn-architecture\">CNN Architecture</a></p>\n<ul>\n<li>\n<p><a href=\"#%EC%86%8C%EA%B0%9C\">소개</a></p>\n</li>\n<li>\n<p><a href=\"#%EB%B0%9C%EC%A0%84-%EA%B3%BC%EC%A0%95\">발전 과정</a></p>\n<ul>\n<li><a href=\"#architecture-scaling\">Architecture Scaling</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#alexnet\">AlexNet</a></p>\n<ul>\n<li><a href=\"#%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95\">주요 특징</a></li>\n<li><a href=\"#%EA%B5%AC%EC%A1%B0\">구조</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#vgg\">VGG</a></p>\n<ul>\n<li><a href=\"#%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95-1\">주요 특징</a></li>\n<li><a href=\"#%EA%B5%AC%EC%A1%B0-1\">구조</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#googlenet--inceptionnet\">GoogleNet / InceptionNet</a></p>\n<ul>\n<li><a href=\"#inception-%EA%B5%AC%EC%A1%B0\">Inception 구조</a></li>\n<li><a href=\"#%EB%8B%A4%EC%96%91%ED%95%9C-%ED%95%84%ED%84%B0-%EC%82%AC%EC%9D%B4%EC%A6%88%EC%9D%98-%EC%9D%B4%EC%A0%90\">다양한 필터 사이즈의 이점</a></li>\n<li><a href=\"#%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95-2\">주요 특징</a></li>\n<li><a href=\"#%EA%B5%AC%EC%A1%B0-2\">구조</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#resnet\">ResNet</a></p>\n<ul>\n<li><a href=\"#%EA%B8%B0%EC%9A%B8%EA%B8%B0-%EC%86%8C%EC%8B%A4\">기울기 소실</a></li>\n<li><a href=\"#%EC%9E%94%EC%B0%A8-%EB%B8%94%EB%A1%9D\">잔차 블록</a></li>\n<li><a href=\"#%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95-3\">주요 특징</a></li>\n<li><a href=\"#%EA%B5%AC%EC%84%B1\">구성</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"December 08, 2022","title":"CNN Architecture","categories":"DL","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/DL/[DL] CNN_Architectures/"}},"prev":{"id":"e1aee229-4607-5ace-8454-12e54615a43d","html":"<h2 id=\"hadoop\" style=\"position:relative;\"><a href=\"#hadoop\" aria-label=\"hadoop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop</h2>\n<p><img src=\"/de7ae2a6adfa3a99dc513c792103c495/hadoop_1.png\" alt=\"hadoop_1.PNG\"></p>\n<p><img src=\"/6a047e71e009cfe1b59b145dfda39ea4/hadoop_2.png\" alt=\"hadoop_2.PNG\"></p>\n<h3 id=\"특징\" style=\"position:relative;\"><a href=\"#%ED%8A%B9%EC%A7%95\" aria-label=\"특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>특징</h3>\n<ul>\n<li>\n<p>분산 파일 시스테과의 강한 연계를 통해 높은 스루풋 처리를 실현하는 분산 처리 소프트웨어</p>\n</li>\n<li>\n<p>Hadoop 프레임 워크 대부분은 JAVA으로 작성.  -> 일반적인 서버와 네트워크로 구성 및 사용 가능</p>\n</li>\n<li>\n<p>다양한 OS에서 동작 가능. 보통은 Linux 환경에서 사용</p>\n</li>\n<li>\n<p>서버를 추가하는 것만으로 용량 및 성능이 향상</p>\n</li>\n<li>\n<p>관계형 DB(RDBMS)나 검색 엔진과 구조 자체가 다르다.</p>\n</li>\n<li>\n<p>Hadoop은 오픈소스 프로젝트로 여러 사람들의 공동 작업으로 업데이트가 빠름</p>\n</li>\n</ul>\n<h3 id=\"하둡-에코시스템\" style=\"position:relative;\"><a href=\"#%ED%95%98%EB%91%A1-%EC%97%90%EC%BD%94%EC%8B%9C%EC%8A%A4%ED%85%9C\" aria-label=\"하둡 에코시스템 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>하둡 에코시스템</h3>\n<p><img src=\"/e48d9276394f4405ad662751ba3fd681/hadoop_3.png\" alt=\"hadoop_3.PNG\">\n출처: 시작하세요! 하둡 프로그래밍(위키북스)</p>\n<h3 id=\"하둡의-구조\" style=\"position:relative;\"><a href=\"#%ED%95%98%EB%91%A1%EC%9D%98-%EA%B5%AC%EC%A1%B0\" aria-label=\"하둡의 구조 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>하둡의 구조</h3>\n<p>하둡의 구조는 Version 별로 차이가 존재한다.</p>\n<h4 id=\"version-1\" style=\"position:relative;\"><a href=\"#version-1\" aria-label=\"version 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Version 1</h4>\n<p>분산저장과 병렬처리를 하기 위한 목적으로 탄생.</p>\n<p>작업 단위는 job.</p>\n<p><img src=\"/bf5bf467a8f54ac9eeceb5f4196c77df/hadoop_4.png\" alt=\"hadoop_4.PNG\">\n출처 : <a href=\"https://mapreducer.wordpress.com/2015/04/14/hadoop-architecture/\">https://mapreducer.wordpress.com/2015/04/14/hadoop-architecture/</a></p>\n<ul>\n<li>분산저장</li>\n</ul>\n<p>네임노드(name node)와 데이터노드(data node)로 나누어 처리된다.</p>\n<blockquote>\n<p>네임노드는 블록정보를 가지고 있는 메타데이터와 데이터 노드를 관리한다.</p>\n</blockquote>\n<blockquote>\n<p>데이터노드는 데이터를 블록단위로 저장하면서 블록단위 데이터를 복제하여 데이터 유실에 대비한다.</p>\n</blockquote>\n<ul>\n<li>병렬처리</li>\n</ul>\n<p>잡트래커(JobTracker)와 태스크트래커(TaskTracker)가 담당한다.</p>\n<blockquote>\n<p>잡트래커는 전체 진행상황을 관리하고 자원관리도 처리한다.</p>\n</blockquote>\n<blockquote>\n<p>테스크트래커는 실제 작업을 처리한다.</p>\n</blockquote>\n<blockquote>\n<p>병렬처리의 작업단위는 slot으로 Map slot과 Reduce slot이 있으며 병렬처리를 통해 클러스트당 최대 4000개의 노드를 등록 가능</p>\n</blockquote>\n<h4 id=\"version-2\" style=\"position:relative;\"><a href=\"#version-2\" aria-label=\"version 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Version 2</h4>\n<p>하둡 버전 2는 하둡 버전 1을 보완한 것으로 잡트래커의 병목현상을 제거하기 위해 YARN 아키텍처가 등장하였다. 이를 통해 배치, 인터렉티브, 스트림과 같은 다양한 데이터 처리가 가능하게 되었다.</p>\n<p>작업 단위는 애플리케이션</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 624px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/webp;base64,UklGRoIAAABXRUJQVlA4IHYAAADQAwCdASoUAAoAPtFWpEuoJKOhsAgBABoJYwC7ACG5dz2JoLGZogAA/vYQt+hgkCVvk3dgyRzPeli22potruK/rE+DGdNZSeKi/lT62hAZuvzv2Qt6ye3bEUildAEZBGl1046fJrxKI9H0LgK8eiVDulTuwoAA'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"hadoop_5.webp\"\n        title=\"hadoop_5.webp\"\n        src=\"/static/06316725bb9675ee3c1ff6553b4cfe6f/b5732/hadoop_5.webp\"\n        srcset=\"/static/06316725bb9675ee3c1ff6553b4cfe6f/59d6e/hadoop_5.webp 180w,\n/static/06316725bb9675ee3c1ff6553b4cfe6f/a3012/hadoop_5.webp 360w,\n/static/06316725bb9675ee3c1ff6553b4cfe6f/b5732/hadoop_5.webp 624w\"\n        sizes=\"(max-width: 624px) 100vw, 624px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span>\n출처: <a href=\"https://intellipaat.com/blog/tutorial/hadoop-tutorial/what-is-yarn/\">https://intellipaat.com/blog/tutorial/hadoop-tutorial/what-is-yarn/</a></p>\n<p><strong>YARN은 Job Tracker의 기능을 분리시켜</strong></p>\n<ul>\n<li>자원 관리</li>\n</ul>\n<blockquote>\n<p>리소스 매니저, 노드 매니저</p>\n</blockquote>\n<ul>\n<li>작업 관리</li>\n</ul>\n<blockquote>\n<p>애플리케이션 마스터</p>\n</blockquote>\n<ul>\n<li>작업 처리</li>\n</ul>\n<blockquote>\n<p>컨테이너</p>\n</blockquote>\n<h4 id=\"yarn의-실행-과정\" style=\"position:relative;\"><a href=\"#yarn%EC%9D%98-%EC%8B%A4%ED%96%89-%EA%B3%BC%EC%A0%95\" aria-label=\"yarn의 실행 과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>YARN의 실행 과정</h4>\n<ol>\n<li>\n<p>YARN 클라이언트가 리소스 매니저에게 Job 실행 요청.</p>\n</li>\n<li>\n<p>리소스 매니저는 노드 매니저 중 하나를 랜덤하게 선택하여 그 노드에서 애플리케이션 매니저를 실행.</p>\n</li>\n</ol>\n<p>( 선택된 노드 매니저가 존재하는 서버상의 컨테이너가 실행되어 애플리케이션 마스터가 실행)</p>\n<ol start=\"3\">\n<li>\n<p>애플리케이션 매니저는 리소스 매니저에게 Job 실행에 필요한 컨테이너들의 할당을 요청. 즉 모든 리소스 요청은 리소스 매니저를 통해 진행되고 후에 애플리케이션 매니저들은 사용한 컨테이너들을 리소스 매니저에게 반환한다.</p>\n</li>\n<li>\n<p>리소스 매니저는 애플리케이션 매니저를 대신해 노드 매니저들에게 태스트 실행을 명령한다.</p>\n</li>\n</ol>\n<p>(각 태스크는 각기 하나의 컨테이너 안에서 실행)</p>\n<h4 id=\"version-3\" style=\"position:relative;\"><a href=\"#version-3\" aria-label=\"version 3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Version 3</h4>\n<p>하둡 버전 2의 업그레이드 모델으로</p>\n<ul>\n<li>\n<p>Java 최소 버전 변경 7 -> 8</p>\n</li>\n<li>\n<p>HDFS에서의 Erasure Coding 지원</p>\n</li>\n</ul>\n<blockquote>\n<p>기존 원래 데이터의 3배 복제 과정 - > 1.4배의 오버헤드로 저장 가능  (데이터 저장 용량 문제 보완)</p>\n</blockquote>\n<ul>\n<li>YARN TimeLine Service Version 2</li>\n</ul>\n<blockquote>\n<p>기존 YARN Version 기능 개선</p>\n</blockquote>\n<ul>\n<li>Support for more than 2 NameNodes.</li>\n</ul>\n<blockquote>\n<p>2개 이상의 네임 노드를 지원하여 NameNode Fail Over 시 발생하는 다운 타임을 최소화</p>\n</blockquote>\n<h3 id=\"hdfs--mapreduce\" style=\"position:relative;\"><a href=\"#hdfs--mapreduce\" aria-label=\"hdfs  mapreduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS + MapReduce</h3>\n<p>Hadoop의 핵심요소는 HDFS(분산 파일 시스템)와 MapReduce(데이터 처리 시스템)이다.</p>\n<p>위 두가지를 짧게 요약하자면</p>\n<ul>\n<li>\n<p>HDFS : 대용량 (TB 이상)의 데이터를 지리적으로 분산되어 있는 수많은 서버에 저장하는 시스템</p>\n</li>\n<li>\n<p>MapReduce : 분산되어 저장된 대용량 데이터를 병렬로 처리하는 시스템</p>\n</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAAB3klEQVQoz5VTW47bMAzM/W/SO/QQ+5eiH5u0WMdxYj2s94PSFKId7O5nBQxs2uRoOKJOrTW80HvH/8StHzhiIsJpJHEiEWrOQG8HOqhW9C9ktVQ0auhtrxkEVAmtdQYT4lgpeGilEDMhxALrIpanQqEOah0pVWhtkHIde6EUgtkcrAtcP77VSjgZYyCl5N1zLli1h7YJ1mfMq8JDCPjg+L8PFquU0EajVEKpBUprqE0j5QSihlMIkXeOseB2m3G9/uFWR/tCPPAx3/B3mjDyYnSY5w9ItcKud1ixQCqB+T4h5bgT5pLZ2D48pMYYKziH+7Lg9vsNv37+gHlMsM7AGIltk7BKMIxRMCO2hoWclBK73HEAw8s8vNrgfYQPCSlFJGfgfYALASkX+BDhY0ZIhePR/rCLPayNkFLiU86lQmqD5b6glArnAx5PwYVEHSlnjp2PoNqYQCrNGO0SE1KDUhtCyLi8X3A+n1Fy4VOb5ztjEDfqEEKyx9tmUGtDjBmXyxXP54qY8vexGS2zolVCK80KlTZ4v1whpGbCz3nb1Y1nG/PIQ30o3Geo86HwPKbMLQ/PjHWYphu2zTLha6BZwCCjfeBHO+PfJ+FX0t5eonHUcsJ+7Y6rdxB9v4r7+z90DqXZwlb1hwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"hadoop_6.png\"\n        title=\"hadoop_6.png\"\n        src=\"/static/e4f869a28eeca9a946187c58841af726/37523/hadoop_6.png\"\n        srcset=\"/static/e4f869a28eeca9a946187c58841af726/e9ff0/hadoop_6.png 180w,\n/static/e4f869a28eeca9a946187c58841af726/f21e7/hadoop_6.png 360w,\n/static/e4f869a28eeca9a946187c58841af726/37523/hadoop_6.png 720w,\n/static/e4f869a28eeca9a946187c58841af726/302a4/hadoop_6.png 1080w,\n/static/e4f869a28eeca9a946187c58841af726/b79a5/hadoop_6.png 1372w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>출처: <a href=\"https://velog.io/@ha0kim/2021-03-02\">https://velog.io/@ha0kim/2021-03-02</a></p>\n<h3 id=\"활용-분야\" style=\"position:relative;\"><a href=\"#%ED%99%9C%EC%9A%A9-%EB%B6%84%EC%95%BC\" aria-label=\"활용 분야 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>활용 분야</h3>\n<ul>\n<li>\n<p>웹 로그 통계</p>\n</li>\n<li>\n<p>검색 인덱스 엔진</p>\n</li>\n<li>\n<p>통계적 기계 번역</p>\n</li>\n<li>\n<p>포맷/이미지 변환</p>\n</li>\n<li>\n<p>이상값 검출</p>\n</li>\n<li>\n<p>기계 학습</p>\n</li>\n</ul>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://www.youtube.com/watch?v=aReuLtY0YMI\">https://www.youtube.com/watch?v=aReuLtY0YMI</a>   - 하둡 소개</p>\n<p>[2] <a href=\"https://dalsacoo-log.tistory.com/entry/Apache-Hadoop-v1-%ED%8A%B9%EC%A7%95-v2-%ED%8A%B9%EC%A7%95-yarn-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-HDFS-%EB%A7%B5%EB%A6%AC%EB%93%80%EC%8A%A4-1\">https://dalsacoo-log.tistory.com/entry/Apache-Hadoop-v1-%ED%8A%B9%EC%A7%95-v2-%ED%8A%B9%EC%A7%95-yarn-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-HDFS-%EB%A7%B5%EB%A6%AC%EB%93%80%EC%8A%A4-1</a></p>\n<p>[3] <a href=\"https://han-py.tistory.com/361\">https://han-py.tistory.com/361</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#hadoop\">Hadoop</a></p>\n<ul>\n<li>\n<p><a href=\"#%ED%8A%B9%EC%A7%95\">특징</a></p>\n</li>\n<li>\n<p><a href=\"#%ED%95%98%EB%91%A1-%EC%97%90%EC%BD%94%EC%8B%9C%EC%8A%A4%ED%85%9C\">하둡 에코시스템</a></p>\n</li>\n<li>\n<p><a href=\"#%ED%95%98%EB%91%A1%EC%9D%98-%EA%B5%AC%EC%A1%B0\">하둡의 구조</a></p>\n<ul>\n<li><a href=\"#version-1\">Version 1</a></li>\n<li><a href=\"#version-2\">Version 2</a></li>\n<li><a href=\"#yarn%EC%9D%98-%EC%8B%A4%ED%96%89-%EA%B3%BC%EC%A0%95\">YARN의 실행 과정</a></li>\n<li><a href=\"#version-3\">Version 3</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#hdfs--mapreduce\">HDFS + MapReduce</a></p>\n</li>\n<li>\n<p><a href=\"#%ED%99%9C%EC%9A%A9-%EB%B6%84%EC%95%BC\">활용 분야</a></p>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"December 22, 2022","title":"Hadoop","categories":"STUDY","author":"HwanHee Park","emoji":"📥"},"fields":{"slug":"/Hadoop/Hadoop/"}},"site":{"siteMetadata":{"siteUrl":"https://han-archives.github.io","comments":{"utterances":{"repo":"Han-Archives/han-archives.github.io"}}}}},"pageContext":{"slug":"/DL/[DL] RNN/","nextSlug":"/DL/[DL] CNN_Architectures/","prevSlug":"/Hadoop/Hadoop/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}