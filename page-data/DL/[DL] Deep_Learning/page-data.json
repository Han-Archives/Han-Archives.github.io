{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/DL/[DL] Deep_Learning/",
    "result": {"data":{"cur":{"id":"60bd67d7-5d95-589c-88db-5a03396860ca","html":"<h3 id=\"keywords\" style=\"position:relative;\"><a href=\"#keywords\" aria-label=\"keywords permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KeyWords</h3>\n<ul>\n<li>DeepLearning</li>\n<li>인공 신경망</li>\n<li>신경망 아키텍처</li>\n<li>활성화 함수</li>\n<li>손실 함수</li>\n<li>옵티마이저</li>\n<li>다중 신경망</li>\n<li>역전파</li>\n</ul>\n<h3 id=\"deep-learning\" style=\"position:relative;\"><a href=\"#deep-learning\" aria-label=\"deep learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deep Learning</h3>\n<p><strong>딥러닝은 신경망 기반의 복잡도가 큰 머신러닝 모델.</strong></p>\n<p>많은 수의 은닉층을 사용하여 마치 인간 뇌의 뉴런과 비슷한 방식의 인공신경망 방식으로 정보를 처리</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 39.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAIDBP/EABUBAQEAAAAAAAAAAAAAAAAAAAAC/9oADAMBAAIQAxAAAAHXeVEQf//EABcQAQEBAQAAAAAAAAAAAAAAAAECADH/2gAIAQEAAQUCOkmqQ3//xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAwEBPwEn/8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQIBAT8BZ//EABQQAQAAAAAAAAAAAAAAAAAAABD/2gAIAQEABj8Cf//EABcQAAMBAAAAAAAAAAAAAAAAAAABIRH/2gAIAQEAAT8hrA2qMph//9oADAMBAAIAAwAAABADz//EABYRAQEBAAAAAAAAAAAAAAAAAAABMf/aAAgBAwEBPxDCv//EABURAQEAAAAAAAAAAAAAAAAAAAAB/9oACAECAQE/ECP/xAAYEAEBAQEBAAAAAAAAAAAAAAABEQAxIf/aAAgBAQABPxCSi+OvAW8WYqGEvd//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"dl_0.jpg\"\n        title=\"dl_0.jpg\"\n        src=\"/static/7537a5b9c9dd12ce62f34ae9dc58ad89/80e3c/dl_0.jpg\"\n        srcset=\"/static/7537a5b9c9dd12ce62f34ae9dc58ad89/4ec73/dl_0.jpg 180w,\n/static/7537a5b9c9dd12ce62f34ae9dc58ad89/158ba/dl_0.jpg 360w,\n/static/7537a5b9c9dd12ce62f34ae9dc58ad89/80e3c/dl_0.jpg 720w,\n/static/7537a5b9c9dd12ce62f34ae9dc58ad89/47311/dl_0.jpg 1080w,\n/static/7537a5b9c9dd12ce62f34ae9dc58ad89/e5166/dl_0.jpg 1200w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"인공신경망\" style=\"position:relative;\"><a href=\"#%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D\" aria-label=\"인공신경망 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>인공신경망</h3>\n<p>인공신경망이란 생물학의 신경망에서 영감을 얻은 통계학적 학습 알고리즘</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 567px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 88.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAASABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHvTWFMAJIr/8QAFhABAQEAAAAAAAAAAAAAAAAAARAg/9oACAEBAAEFAnTf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAFBABAAAAAAAAAAAAAAAAAAAAMP/aAAgBAQAGPwIf/8QAHBAAAgICAwAAAAAAAAAAAAAAAAERQSExUWFx/9oACAEBAAE/Ie3Ik5loWiiXgTcFPS0Wz//aAAwDAQACAAMAAAAQcM/8/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAGxABAQEAAwEBAAAAAAAAAAAAAREAITFxUZH/2gAIAQEAAT8QqEAR05qAccc4pCq+5tWHjiAC8d5gpX6TdPDB+Duofd//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"dl_1.jpg\"\n        title=\"dl_1.jpg\"\n        src=\"/static/a53128f49ac7e54e2c795495f3f933cf/a7172/dl_1.jpg\"\n        srcset=\"/static/a53128f49ac7e54e2c795495f3f933cf/4ec73/dl_1.jpg 180w,\n/static/a53128f49ac7e54e2c795495f3f933cf/158ba/dl_1.jpg 360w,\n/static/a53128f49ac7e54e2c795495f3f933cf/a7172/dl_1.jpg 567w\"\n        sizes=\"(max-width: 567px) 100vw, 567px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>[출처] : <a href=\"http://scienceon.hani.co.kr/397536\">http://scienceon.hani.co.kr/397536</a></p>\n<h3 id=\"신경망-아키텍처\" style=\"position:relative;\"><a href=\"#%EC%8B%A0%EA%B2%BD%EB%A7%9D-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98\" aria-label=\"신경망 아키텍처 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>신경망 아키텍처</h3>\n<p>인공 신경망은 아래와 같은 신경망 구조로 발전되어 다중 신경망을 구성한다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 170%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"dl_4.png\"\n        title=\"dl_4.png\"\n        src=\"/static/6835e5fcbd448811301540dd3bf3cc4a/37523/dl_4.png\"\n        srcset=\"/static/6835e5fcbd448811301540dd3bf3cc4a/e9ff0/dl_4.png 180w,\n/static/6835e5fcbd448811301540dd3bf3cc4a/f21e7/dl_4.png 360w,\n/static/6835e5fcbd448811301540dd3bf3cc4a/37523/dl_4.png 720w,\n/static/6835e5fcbd448811301540dd3bf3cc4a/302a4/dl_4.png 1080w,\n/static/6835e5fcbd448811301540dd3bf3cc4a/07a9c/dl_4.png 1440w,\n/static/6835e5fcbd448811301540dd3bf3cc4a/a4ed7/dl_4.png 4706w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span>\n[출처] <a href=\"https://www.asimovinstitute.org/neural-network-zoo/\">https://www.asimovinstitute.org/neural-network-zoo/</a></p>\n<p>그 외에도 dropout 방식과 같은 다양한 구조가 존재한다.\n<img src=\"/6476f749e531e1680ef789794bbb5e44/dl_5.png\" alt=\"dl_5.PNG\"></p>\n<p>딥러닝을 이해하기 위한 사전 지식으로 <strong>활성화 함수</strong>,<strong>손실함수</strong>, <strong>옵티마이저</strong>에 대해 알아보자.</p>\n<h3 id=\"활성화-함수\" style=\"position:relative;\"><a href=\"#%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98\" aria-label=\"활성화 함수 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>활성화 함수</h3>\n<p>활성화 함수는 신경망 구조에 <strong>비선형성을 추가하기 위해 존재</strong>한다.</p>\n<p><strong>선형구조의 경우 많은 계층을 거치는 과정에서 전체 신경망 모델이 단순해진다.</strong></p>\n<p>이를 방지하기 위해 비선형 구조로 변환하는 것이다. 다만 비선형 구조의 경우에도 기울기 소실과 같은 문제점이 존재한다.</p>\n<h4 id=\"활성화-함수의-종류\" style=\"position:relative;\"><a href=\"#%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EC%9D%98-%EC%A2%85%EB%A5%98\" aria-label=\"활성화 함수의 종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>활성화 함수의 종류</h4>\n<blockquote>\n<p>시그모이드 함수</p>\n</blockquote>\n<blockquote>\n<p>TanH 함수(하이퍼볼릭탄젠트 함수)</p>\n</blockquote>\n<blockquote>\n<p>ReLU</p>\n</blockquote>\n<blockquote>\n<p>Softmax</p>\n</blockquote>\n<h3 id=\"손실-함수\" style=\"position:relative;\"><a href=\"#%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98\" aria-label=\"손실 함수 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>손실 함수</h3>\n<p>손실 함수란 예측한 값이 실제값과의 차이를 수치화하는 함수를 말한다. 이 손실함수를 최소화하는 가중치와 편향을 찾는 것이 중요 목표이다.</p>\n<h4 id=\"손실-함수-종류\" style=\"position:relative;\"><a href=\"#%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98-%EC%A2%85%EB%A5%98\" aria-label=\"손실 함수 종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>손실 함수 종류</h4>\n<ul>\n<li>Binary Cross-Entropy</li>\n</ul>\n<blockquote>\n<p>Sigmoid 함수를 사용하는 이진 분류의 경우 주로 사용</p>\n</blockquote>\n<ul>\n<li>categorical_crossentropy (범주형 교차 엔트로피)</li>\n</ul>\n<blockquote>\n<p>Softmax 함수를 사용하는 다중 클래스 분류(Multi-Class Classification)의 경우에 주로 사용</p>\n</blockquote>\n<ul>\n<li>sparse_categorical_crossentropy</li>\n</ul>\n<blockquote>\n<p>위의 범주형 교차 엔트로피와 동일하게 다중 클래스 분류에 사용되지만 원-핫 인코딩된 상태가 아닌 정수형값을 (0,1,2,3,4) 갖는 레이블에 대해 수행</p>\n</blockquote>\n<ul>\n<li>MSE</li>\n</ul>\n<blockquote>\n<p>평균제곱오차라 하며 오차(실제값과 예측값의 차이)를 제곱한 값을 나타내는 손실함수</p>\n</blockquote>\n<h3 id=\"옵티마이저\" style=\"position:relative;\"><a href=\"#%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80\" aria-label=\"옵티마이저 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>옵티마이저</h3>\n<p>옵티마이저란 아래에서 언급될 역전파 과정에서 가중치를 수정할 때 사용하는 알고리즘으로</p>\n<h4 id=\"옵티마이저-종류\" style=\"position:relative;\"><a href=\"#%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80-%EC%A2%85%EB%A5%98\" aria-label=\"옵티마이저 종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>옵티마이저 종류</h4>\n<ul>\n<li>GD(경사 하강법)</li>\n</ul>\n<blockquote>\n<p>전체 데이터를 계산하여 발생한 오류를 통해 가중치를 수정. -> 오래걸리고 메모리 소모가 큼</p>\n</blockquote>\n<ul>\n<li>SGD</li>\n</ul>\n<blockquote>\n<p>배치 단위로 가중치를 수정</p>\n</blockquote>\n<ul>\n<li>Momentum</li>\n</ul>\n<blockquote>\n<p>관성이라는 물리학 법칙을 응용한 것으로 경사하강법의 기울기 + 그 전 시점의 기울기의 일정비율을 더하는 것</p>\n</blockquote>\n<blockquote>\n<p>모멘텀을 통해 아래와 같이 기울기가 0인 구간(로컬 미니멈)을 돌파하여 우리가 원하는 가장 낮은 손실함수 값에 도달할 수 있음</p>\n</blockquote>\n<blockquote>\n<p><img src=\"/4250838bca5af91162fe06124aa452bc/dl_7.png\" alt=\"dl_7.PNG\"></p>\n</blockquote>\n<ul>\n<li>Adagrad</li>\n</ul>\n<blockquote>\n<p>각 매개변수에 서로 다른 학습률 적용하는 것으로 변화가 많은 매개변수는 학습률을 작게, 변화가 적은 매개변수는 학습률을 크게 설정</p>\n</blockquote>\n<ul>\n<li>RMSprop</li>\n</ul>\n<blockquote>\n<p>Adagrad의 단점인 학습이 계속 진행되면 나중에는 학습률이 크게 떨어진다는 단점을 다른 수식으로 개선한 것</p>\n</blockquote>\n<ul>\n<li>Adam</li>\n</ul>\n<blockquote>\n<p>RMSprop + Momentum</p>\n</blockquote>\n<blockquote>\n<p>가장 많이 사용되는 옵티마이저로, Momentum(방향)과 RMSprop(학습률)을 조정</p>\n</blockquote>\n<h3 id=\"다중-신경망\" style=\"position:relative;\"><a href=\"#%EB%8B%A4%EC%A4%91-%EC%8B%A0%EA%B2%BD%EB%A7%9D\" aria-label=\"다중 신경망 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>다중 신경망</h3>\n<p>인공 신경망의 조합을 통해 다중 신경망을 생성하며 이 신경망들은 아래의 과정을 통해 다음 노드로 전달 되거나 결과값을 나타낸다.\n<img src=\"/4ca3db627c730ce51eed995aed9e8a47/dl_2.png\" alt=\"dl_2.PNG\"></p>\n<p>입력 값들은 설정된 가중치와 곱해지고 bias를 더한 뒤 활성화 함수를 통해 값이 변화된 후 다음 layer로 전달된다.</p>\n<h3 id=\"역전파\" style=\"position:relative;\"><a href=\"#%EC%97%AD%EC%A0%84%ED%8C%8C\" aria-label=\"역전파 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>역전파</h3>\n<p>역전파란 딥러닝의 핵심 요소 중 하나로 기존에 진행한 방식에서 발생한 오차를 토대로 손실함수를 최소화하기 위해 가중치를 수정하며 진행하는 방식</p>\n<h4 id=\"예시\" style=\"position:relative;\"><a href=\"#%EC%98%88%EC%8B%9C\" aria-label=\"예시 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>예시</h4>\n<p>아래의 예시는 예능에서 자주 하는 맞추기 게임으로 각 사람은 정답에 대한 설명을 통해 전달하여 최종 사람이 답을 맞추는 과정이다. 이 때의 설명을 가중치로 이해하면 역전파의 과정을 이해하기 더 쉬울 것이다. 역전파 과정이 끝이 나면 다시 수정된 내용을 기반으로 다시 진행하는 과정을 통해 손실함수를 줄여가며 개선하며 진행한다.</p>\n<p><img src=\"/d5f79e813ff2e4d8b36299058d2c5c87/dl_3.png\" alt=\"dl_3.PNG\"></p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://wikidocs.net/36033\">https://wikidocs.net/36033</a></p>\n<p>[2] <a href=\"https://wikidocs.net/152765\">https://wikidocs.net/152765</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#keywords\">KeyWords</a></p>\n</li>\n<li>\n<p><a href=\"#deep-learning\">Deep Learning</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D\">인공신경망</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%8B%A0%EA%B2%BD%EB%A7%9D-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98\">신경망 아키텍처</a></p>\n</li>\n<li>\n<p><a href=\"#%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98\">활성화 함수</a></p>\n<ul>\n<li><a href=\"#%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EC%9D%98-%EC%A2%85%EB%A5%98\">활성화 함수의 종류</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98\">손실 함수</a></p>\n<ul>\n<li><a href=\"#%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98-%EC%A2%85%EB%A5%98\">손실 함수 종류</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80\">옵티마이저</a></p>\n<ul>\n<li><a href=\"#%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80-%EC%A2%85%EB%A5%98\">옵티마이저 종류</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EB%8B%A4%EC%A4%91-%EC%8B%A0%EA%B2%BD%EB%A7%9D\">다중 신경망</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%97%AD%EC%A0%84%ED%8C%8C\">역전파</a></p>\n<ul>\n<li><a href=\"#%EC%98%88%EC%8B%9C\">예시</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</div>","excerpt":"KeyWords DeepLearning 인공 신경망 신경망 아키텍처 활성화 함수 손실 함수 옵티마이저 다중 신경망 역전파 Deep Learning 딥러닝은 신경망 기반의 복잡도가 큰 머신러닝 모델. 많은 수의 은닉층을 사용하여 마치 인간 뇌의 뉴런과 비슷한 방식의 인공신경망 방식으로 정보를 처리  인공신경망 인공신경망이란 생물학의 신경망에서 영감을 얻은 통계학적 학습 알고리즘  [출처] : http://scienceon.hani.co.kr/397536 신경망 아키텍처 인공 신경망은 아래와 같은 신경망 구조로 발전되어 다중 신경망을 구성한다. \n[출처] https://www.asimovinstitute.org/neural-network-zoo/ 그 외에도 dropout 방식과 같은 다양한 구조가 존재한다.\ndl_5.PNG 딥러닝을 이해하기 위한 사전 지식으로 활성화 함수,손실함수, 옵티마이저에 대해 알아보자. 활성화 함수 활성화 함수는 신경망 구조에 비선형성을 추가하기 위해 존재한다…","frontmatter":{"date":"December 03, 2022","title":"Deep Learning","categories":"DL","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/DL/[DL] Deep_Learning/"}},"next":{"id":"f421810d-6886-5f90-9a61-f76f3bcc78bd","html":"<h2 id=\"data-augumentation\" style=\"position:relative;\"><a href=\"#data-augumentation\" aria-label=\"data augumentation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Augumentation</h2>\n<h3 id=\"소개\" style=\"position:relative;\"><a href=\"#%EC%86%8C%EA%B0%9C\" aria-label=\"소개 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>소개</h3>\n<p>Data Augmentation이란 데이터 증강이란 의미로 머신 러닝을 위한 데이터의 다양성을 높여 과적합을 방지하는 프로세스. 즉 기존의 데이터셋을 활용하여 다른 버전의 데이터셋을 생성하여 데이터셋의 크기를 늘리는 방법.</p>\n<p>Data Augumentation의 일반적인 진행과정은 대부분 전처리 후, 모델 학습 이전에 주로 시행된다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 68.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAACCklEQVQoz42SS2/TQBDHc+FbwBE+ApdeuHBDgiOiB66AaI8IqUjAkSMHLhCQeCiiVIAqwSGiqooSVcDBoSSukzZ2kjbrOrEd2+vHer2PQU7aKhGIMlqtNKP5zezOfwpwgkkB0EWD+tr73cqn5s/vEiAhSUqplLLwL258YQoe4eX711Zvzu21NWfk93o9ZJpCiBlYSvknHHFAA6ejKsjQ2k11Oq0Agksp8gBnx8zkiLEXZuDgZH3pyvri3E7tmx/GuqFbg0EO51WklCLPzLLsqOo4Ou4dZmDjpKsqvfoP8+BgpvOLh7cDa49n9MPje6ulIgAkTBIBREDMgUkZMRh64evld8U3pYa6HQSB0TFsx8nh0tVzH+fPLt+68PbiKbWxZTNoIV/vW7v7lo7srsetBLwwqWtNRdWQac50frlwaWP+dHXh/PPLZ2w/jBggL0UO7jvYHMV2xDGDLrKKDxafLt34ulZOUjocDl3X5ZwXtF81pG+Ho6GyuUEZE+PPT00bMAWcileP7j67c73X1WNCfN/HGB9KJYTgnAMA5+Jw1EeWwxl4UUoymgnhh5gxllJKCKGUFvI5T6QS/G9LAgGFKJNhmnpRFKfUcRzTsvoIua77HxvGYOB6rc1yW6noSkXmitLJo06GCUDHMJSVJ40vKzvVz7aHdb0dx/EJ8HEFjANDqe5rNdTampbqN2qcBq0vW5EgAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"cnna_1.png\"\n        title=\"cnna_1.png\"\n        src=\"/static/69ed6d5b99e07f5ce13d1ca1eda68cd5/37523/cnna_1.png\"\n        srcset=\"/static/69ed6d5b99e07f5ce13d1ca1eda68cd5/e9ff0/cnna_1.png 180w,\n/static/69ed6d5b99e07f5ce13d1ca1eda68cd5/f21e7/cnna_1.png 360w,\n/static/69ed6d5b99e07f5ce13d1ca1eda68cd5/37523/cnna_1.png 720w,\n/static/69ed6d5b99e07f5ce13d1ca1eda68cd5/ae694/cnna_1.png 850w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"주요-기법\" style=\"position:relative;\"><a href=\"#%EC%A3%BC%EC%9A%94-%EA%B8%B0%EB%B2%95\" aria-label=\"주요 기법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>주요 기법</h3>\n<p>Augumentation의 주요 기법들을 설명 요약하면 크게 1)사이즈 변환 , 2)주요 특징 추출, 3)픽셀 화소 변환, 4)이미지 각도 변환, 5)기타 사항 등 4가지 항목으로 나타낼 수 있다.</p>\n<ol>\n<li>사이즈 변환</li>\n</ol>\n<blockquote>\n<p>Resize: 이미지의 사이즈를 지정할 때 사용</p>\n</blockquote>\n<blockquote>\n<p>RandomResizedCrop : 임의의 위치의 이미지의 사이즈를 지정할 때 사용</p>\n</blockquote>\n<ol start=\"2\">\n<li>주요 특징 추출</li>\n</ol>\n<blockquote>\n<p>CenterCrop : 중앙을 기점으로 지정된 사이즈만큼 추출</p>\n</blockquote>\n<blockquote>\n<p>FiveCrop : 중앙, 각 이미지의 모서리에 해당되는 부분까지 5 부분에 대한 이미지 추출</p>\n</blockquote>\n<blockquote>\n<p>RandomCrop: 임의의 부분을 지정된 만큼 추출</p>\n</blockquote>\n<ol start=\"3\">\n<li>픽셀 화소 변환</li>\n</ol>\n<blockquote>\n<p>GrayScale : 이미지를 회색 이미지로 변환</p>\n</blockquote>\n<blockquote>\n<p>ColorJitter : 이미지의 밝기, 채도 및 기타 속성을 임의로 변경</p>\n</blockquote>\n<ol start=\"4\">\n<li>이미지 각도 변환</li>\n</ol>\n<blockquote>\n<p>RandomPerspective : 이미지의 임의의 원근 변환</p>\n</blockquote>\n<blockquote>\n<p>RandomRotation : 이미지의 임의 각도나 정해진 각도 범위에서 회전</p>\n</blockquote>\n<blockquote>\n<p>RandomAffine : 이미지에 임의의 Affine 변환 수행</p>\n</blockquote>\n<blockquote>\n<p>RandomHorizontalFlip : 주어진 확률에 따라 수평선 뒤집기 수행</p>\n</blockquote>\n<blockquote>\n<p>RandomVerticalFlip : 주어진 확률에 따라 수직선 뒤집기 수행</p>\n</blockquote>\n<ol start=\"5\">\n<li>기타</li>\n</ol>\n<blockquote>\n<p>Pad : 이미지 윤곽선에 간격을 줌</p>\n</blockquote>\n<blockquote>\n<p>RandomApply : 확률 기반으로 주어진 변환 목록을 무작위로 시행</p>\n</blockquote>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://dataaspirant.com/data-augmentation-techniques-deep-learning/#t-1598844713768\">https://dataaspirant.com/data-augmentation-techniques-deep-learning/#t-1598844713768</a></p>\n<p>[2] <a href=\"https://link.springer.com/article/10.1007/s00521-022-07645-z\">https://link.springer.com/article/10.1007/s00521-022-07645-z</a></p>\n<p>[3] <a href=\"https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html#augmentation\">https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html#augmentation</a></p>","frontmatter":{"date":"December 03, 2022","title":"Data Augumentation","categories":"DL","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/DL/[DL] Data Augumentation/"}},"prev":{"id":"4f806e7c-e00a-5a6f-ae05-674d6de60709","html":"<h2 id=\"cnn-합성곱-신경망\" style=\"position:relative;\"><a href=\"#cnn-%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9D\" aria-label=\"cnn 합성곱 신경망 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CNN (합성곱 신경망)</h2>\n<h3 id=\"소개\" style=\"position:relative;\"><a href=\"#%EC%86%8C%EA%B0%9C\" aria-label=\"소개 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>소개</h3>\n<p>합성곱 신경망은 이미지의 객체 탐지, 분할 등 이미지나 동영상과 관련된 머신러닝 문제를 해결하는 딥러닝 모델 중 하나로 이미지 인식과 패턴 감지를 위한 최적의 아키텍처를 제공한다.</p>\n<h3 id=\"특징\" style=\"position:relative;\"><a href=\"#%ED%8A%B9%EC%A7%95\" aria-label=\"특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>특징</h3>\n<p>CNN은 이미지에서 객체, 얼굴, 장면을 인식하기 위해 <strong>1.패턴을 찾는 데 특히 유용</strong>하며 CNN은 데이터에서 직접 학습하며, <strong>2.패턴을 사용하여 이미지를 분류하고 특징을 수동으로 추출할 필요가 없다.</strong></p>\n<p>합성곱 계층은 <strong>3.학습 가능한 매개변수를 공유</strong>하는 합성곱 계층을 사용하여 테두리, 윤곽선 등 이미지에서 학습한 패턴은 이미지의 픽셀 위치에 독립적인 것으로 가정하여 매개변수를 공유할 수 있다.</p>\n<h3 id=\"진행-과정\" style=\"position:relative;\"><a href=\"#%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95\" aria-label=\"진행 과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>진행 과정</h3>\n<p>CNN의 진행 과정은 크게 Feature Learning과 Classification으로 나뉘어진다.</p>\n<ul>\n<li>\n<p>Feature Learning은 이미지로 부터 특징을 찾아 학습하는 과정</p>\n</li>\n<li>\n<p>Classification은 인공 신경망 과정을 거쳐 이미지를 분류하는 과정</p>\n</li>\n</ul>\n<p><img src=\"/aa20751417fca87cc1ced06192e33b17/cnn_1.png\" alt=\"cnn_1.PNG\"></p>\n<h3 id=\"feature-learning\" style=\"position:relative;\"><a href=\"#feature-learning\" aria-label=\"feature learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Feature Learning</h3>\n<p>Feature Learning의 과정은 Convolution(합성곱), RELU(활성화 함수), Pooling 과정 등으로 나눌 수 있다.</p>\n<h4 id=\"convolution\" style=\"position:relative;\"><a href=\"#convolution\" aria-label=\"convolution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Convolution</h4>\n<p>Convolution 과정은 이미지 혹은 input 값을 주어진 필터를 통해 Feature Map을 만드는 과정</p>\n<p><img src=\"/950bc4a66cf2b5055ddce15c16dc1c0d/cnn_2.gif\" alt=\"cnn_2.gif\"></p>\n<p>[출처] <a href=\"https://towardsdatascience.com/a-simple-guide-to-convolutional-neural-networks-751789e7bd88\">https://towardsdatascience.com/a-simple-guide-to-convolutional-neural-networks-751789e7bd88</a></p>\n<p>이때 Feature Map 크기는 필터의 크기, Stride 값, zero-padding 여부에 따라 정해진다.</p>\n<h4 id=\"relu\" style=\"position:relative;\"><a href=\"#relu\" aria-label=\"relu permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>RELU</h4>\n<p>Convolution 결과인 Feature Map을 활성화 함수 RELU를 적용시켜 비선형성을 추가하는 과정</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 95.55555555555554%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAABYlAAAWJQFJUiTwAAACd0lEQVQ4y5VUi46bQAzk/7/tpEpt00oJCRASnuERCLDLLkw1BpI7XXVqkRzvGns8Y6M4+OKZ51m8Ho3YKza/84AyM6Y11/kXQGMnGGu3KNYw7AT8zmbUA6DtfwB2gxaGvNtpYWamGT+SGa1ammz5/wSotMFo7FYmoARr1BKh3C3Xod8kbP7vDO0T7LswW5gK4XUMNGde0bfAR1sAB21grZXiF7OX/BeGSJ7xtQGzHaFGi58p0Or3jOZPY3L8GvAroOiBvFvstpqceyBtJ3y7GtT9RHRoY2GMlbly+7RxvTthqeGXFkFp4RcWbq5xuhm4mYZXWHiFwT4bkdYKvVK4d/q59X71BNRmWZyjhw6DHvHoB3SKyWq19bzG2kGjGQzqh4KdpmW70+dtOsYY+L6PPM/heR6SJMXlcpFYmqa4Xq/P5DA8I00TBEEgOXEUwXVdyWOMWI7WGucwFDC+IHAURajrGlmWic3CZkIcx2jbFo/HA03TiN1uN/R9j6IoMI4jHKUUjscjyrIUVkwg4Pl8FtD3DNmUgHzPRqxhLRuQMcl9AGQxfRiGYjwzkd8g8yiPQGRKRmzIJlVVCQFhyB/qJwC7s4BJLCATAnIMb29v2O12cicAZXZdJ3lJkggZYTgMAw6HA+j3+z3u97sAkTVj7Lw9ZEh5HA1BqIBNCMzYU/LpdJLOTDqdPATnsyxqt/sF1z0uf1XWwg8CabBtdds2FdA/JadJDDNqVGWB7tGirkrc8hxt0yBLkyfDJI4wDL1IplEN50kMggpgWVY4+Fd41wx77yL+GMbY+1f4UQ7vkqJsFaqHhhtEiLMCRXETuVwK2dJzlvy0/gDJM7atOwphwwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"cnn_3.png\"\n        title=\"cnn_3.png\"\n        src=\"/static/a4fed057a7bd2e93c08ac83244f78c68/37523/cnn_3.png\"\n        srcset=\"/static/a4fed057a7bd2e93c08ac83244f78c68/e9ff0/cnn_3.png 180w,\n/static/a4fed057a7bd2e93c08ac83244f78c68/f21e7/cnn_3.png 360w,\n/static/a4fed057a7bd2e93c08ac83244f78c68/37523/cnn_3.png 720w,\n/static/a4fed057a7bd2e93c08ac83244f78c68/58bb7/cnn_3.png 985w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h4 id=\"pooling\" style=\"position:relative;\"><a href=\"#pooling\" aria-label=\"pooling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pooling</h4>\n<p>Pooling이란 정보를 축약하는 과정으로 Convolution+RELU를 통해 얻은 정보값을 축약시키는 과정으로 입력데이터 크기가 축소되는 과정(파라미터 수 감소)을 통해 과적합을 방지하는 과정</p>\n<p>대표적인 방법으로 각 영역에 Max 값을 추출하는 Max Pooling과 각 영역의 평균 값을 추출하는 Average Pooling 이있다.</p>\n<p><img src=\"/378e517602c051a642267e9b72314031/cnn_4.png\" alt=\"cnn_4.PNG\">\n[출처] <a href=\"https://pyimagesearch.com/2021/05/14/convolutional-neural-networks-cnns-and-layer-types/\">https://pyimagesearch.com/2021/05/14/convolutional-neural-networks-cnns-and-layer-types/</a></p>\n<p>합성곱, RELU, Pooling 과정을 한 Layer Filter라고 할때, 여러 필터를 거치는 과정을 통해 훨씬 더 복잡한 구조의 패턴을 감지하는 방식으로 진행된다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.111111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABcRAAAXEQHKJvM/AAACmklEQVQoz02TWU9aQRiGT2KvrEpFUBYFBeOWKOXGjUXjggtxLcagLCr2uIAIqKwuNYrRRFMxXFlvjD/0aWYSm158mcyb98z3zvPNUcbGxjAajQwODtLb20t7ezsWiwWr1Yrzu1OuYi/0vr4+3C43jgEHZrNZlt1uZ3h4GJvNRk9PD0oqlSKXyxGPx0mn02xvb+P1etnZ2ZEl9NnZWdxuN6urq4yMjBAIBPD7/bhcLoLBIIuLiywsLLCxsYFSqVT4+Pjg9fWV9/d3rq6u2Nzc5O7ujnK5zP39Pbu7u4yPj8vDI5GI3KuqSjgc5vz8nFgsRjqT4fT0FOXh4YHHx0eq1aqsZDIpu15fX5PNZimVSvKQiYkJeUgoFJKrSCOSXVxecnBwIJsdHx+jDA0NYTSZ8FutdLa2odPr0el0dHZ04DMasVksNOn1aBsb0ZtMTBsMdJnNaBobadBoMOj0UjM2N9Pe0YEiEokEv/J5SoUCgbU1pqamiEYiJFWV3ViMmZkZpqeniW5toUYirCwtyXSTk5Pyusd7e4RDIclfubm5kewq1SqPT09kMhnW19c5OzsjXyrx+/lZXlE0KRYKZPN5bstl+bHw3d7ecpRKkc3lKBQKKIJTsVjkqljkvFSSprm5OY4SCQ5VlZOTE5aXl+nv7+enqrIVDsv0YqozPh/RaJRQMMj+3p4cjOJwODAYDPzo7magq4t6jYa6+nqsbW0s2+2SYX1DA19qamhqaWHJZqO7tY3aujq+1tbyTatlzmzGIjiaTCharRan00ni8BDxyBVFkeVxu0ns7+PxeP5po6OjpOJxxv/ziR8ifXSE99MnWAhulZcX+Qbn5+fx+XySh+B3cXEhEQgtl81K36cmBiV8f97eELNYWVnhL3q2qC5vB6XtAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"cnn_5.png\"\n        title=\"cnn_5.png\"\n        src=\"/static/024180d2b6dc2edf9a78e18a6d07fbc1/37523/cnn_5.png\"\n        srcset=\"/static/024180d2b6dc2edf9a78e18a6d07fbc1/e9ff0/cnn_5.png 180w,\n/static/024180d2b6dc2edf9a78e18a6d07fbc1/f21e7/cnn_5.png 360w,\n/static/024180d2b6dc2edf9a78e18a6d07fbc1/37523/cnn_5.png 720w,\n/static/024180d2b6dc2edf9a78e18a6d07fbc1/302a4/cnn_5.png 1080w,\n/static/024180d2b6dc2edf9a78e18a6d07fbc1/07a9c/cnn_5.png 1440w,\n/static/024180d2b6dc2edf9a78e18a6d07fbc1/5df5d/cnn_5.png 1572w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span>\n[출처] <a href=\"https://glassboxmedicine.com/2020/08/03/convolutional-neural-networks-cnns-in-5-minutes/\">https://glassboxmedicine.com/2020/08/03/convolutional-neural-networks-cnns-in-5-minutes/</a></p>\n<h4 id=\"flatten\" style=\"position:relative;\"><a href=\"#flatten\" aria-label=\"flatten permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Flatten</h4>\n<p>Feature Learning 과정의 최종 결과(2,3차원)를 1차원 벡터로 변경하는 과정.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.77777777777777%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABaElEQVQoz51S207CQBDl/z+BGIj+ASHAm0i7LQ9ieNKSEJFWRRKgF5R2d9vlmBloBeXJSc7uydxndmt5rqG1YiglGcRLPd2/UfobU2A2e2YQJ12tDAL2KKU0ngZfAomwLQhhMeeEZdBk4mE8fsBodI/l8gP7vTnrsChyxmmXJMOhw/iTsN1u4ea6iWbjCp73yA40PiWJog18/wVB4GOXfrFOa8lTua6A44rKnxMSabVaaDSaqNfr8LynqmIYb7FcRViuwgpx8nlcEyCEgOOInw7poIqO46LT6aHb7WE+n9MmoVTGxaRMq0fLsrR6PGNy7tB1He5Wygw1Mmw2KywWb7y79Zr4O+I4RpHnkFIiTY8Jme+glWJ9rnPu7rDDPbIs45HNdpuYMNyYJIn5jqLQpOnOkE3rS1BGKWVojH7/1gwGd8xJV41MX+UUh8Wf/sNzXr6ybQ1g29bZDqf/hTHF9DXwp0HgMyfdN3Bc9Yo1ic2NAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"cnn_6.png\"\n        title=\"cnn_6.png\"\n        src=\"/static/7162ff94a02cb41e6c0a35c252f4064b/37523/cnn_6.png\"\n        srcset=\"/static/7162ff94a02cb41e6c0a35c252f4064b/e9ff0/cnn_6.png 180w,\n/static/7162ff94a02cb41e6c0a35c252f4064b/f21e7/cnn_6.png 360w,\n/static/7162ff94a02cb41e6c0a35c252f4064b/37523/cnn_6.png 720w,\n/static/7162ff94a02cb41e6c0a35c252f4064b/c1328/cnn_6.png 866w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span>\n[출처] <a href=\"https://prod.velog.io/@rsj9987/%EB%94%A5%EB%9F%AC%EB%8B%9D-CNN-%EA%B8%B0%EB%B3%B8-%EA%B5%AC%EC%A1%B0\">https://prod.velog.io/@rsj9987/%EB%94%A5%EB%9F%AC%EB%8B%9D-CNN-%EA%B8%B0%EB%B3%B8-%EA%B5%AC%EC%A1%B0</a></p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://huangdi.tistory.com/12\">https://huangdi.tistory.com/12</a></p>\n<p>[2] <a href=\"https://bigdaheta.tistory.com/48\">https://bigdaheta.tistory.com/48</a></p>\n<p>[3] <a href=\"https://www.youtube.com/watch?v=4AuCBqPvmcc&#x26;list=TLPQMDMxMjIwMjKQRLqCpat_6A&#x26;index=2\">https://www.youtube.com/watch?v=4AuCBqPvmcc&#x26;list=TLPQMDMxMjIwMjKQRLqCpat_6A&#x26;index=2</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#cnn-%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9D\">CNN (합성곱 신경망)</a></p>\n<ul>\n<li>\n<p><a href=\"#%EC%86%8C%EA%B0%9C\">소개</a></p>\n</li>\n<li>\n<p><a href=\"#%ED%8A%B9%EC%A7%95\">특징</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95\">진행 과정</a></p>\n</li>\n<li>\n<p><a href=\"#feature-learning\">Feature Learning</a></p>\n<ul>\n<li><a href=\"#convolution\">Convolution</a></li>\n<li><a href=\"#relu\">RELU</a></li>\n<li><a href=\"#pooling\">Pooling</a></li>\n<li><a href=\"#flatten\">Flatten</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"December 04, 2022","title":"CNN","categories":"DL","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/DL/[DL] CNN/"}},"site":{"siteMetadata":{"siteUrl":"https://han-archives.github.io","comments":{"utterances":{"repo":"Han-Archives/han-archives.github.io"}}}}},"pageContext":{"slug":"/DL/[DL] Deep_Learning/","nextSlug":"/DL/[DL] Data Augumentation/","prevSlug":"/DL/[DL] CNN/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}