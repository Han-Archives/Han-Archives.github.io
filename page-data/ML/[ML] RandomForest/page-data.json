{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/ML/[ML] RandomForest/",
    "result": {"data":{"cur":{"id":"b22a1546-b405-5a09-af07-080c0d044953","html":"<h3 id=\"keywords\" style=\"position:relative;\"><a href=\"#keywords\" aria-label=\"keywords permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Keywords</h3>\n<ul>\n<li>RandomForest</li>\n<li>배깅</li>\n<li>하이퍼 파라미터 튜닝</li>\n<li>OOB Score</li>\n<li>변수 중요도</li>\n</ul>\n<h2 id=\"randomforest\" style=\"position:relative;\"><a href=\"#randomforest\" aria-label=\"randomforest permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>RandomForest</h2>\n<blockquote>\n<p>랜덤포레스트는 <strong>분류 및 회귀 ML 중 하나로 앙상블 학습 방법의 일종</strong> 으로 트리 기반 알고리즘이다. <strong>각 트리들은 랜덤하게 서로 다른 특성</strong>을 가진다. 이를 통해 각 트리들의 예측이 <strong>비상관적</strong>이며 <strong>결과적으로 일반화 성능을 향상</strong>시킨다.</p>\n</blockquote>\n<blockquote>\n<p>랜덤화는 각 트리들의 훈련 과정에서 진행되며, <strong>랜덤 학습 데이터 추출 방법을 이용한 앙상블 학습법인 배깅(bagging)과 랜덤 노드 최적화(randomized node optimization)가 자주 사용된다</strong>. 이 두 가지 방법은 서로 동시에 사용되어 랜덤화 특성을 더욱 증진 시킬 수 있다.</p>\n</blockquote>\n<blockquote>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.22222222222223%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACTklEQVQ4y32TTU8TURSGu3TjxkT/AjtNICaEjSw0Gv0D7HDhwn8gcWFMjB/QosQoSMAEKEOkK0sLloS2JogYbRqjoIBYUCraDobSmc50OvfOY6YffFk9ybl5c/Ke95x7zr0eAMdxDriUjhtm8YfOjecpboXW8Ea+oRcF9fi1mGue3eA+F1XB+a852voXaH/6iav+JXKGvZdc9cPCnsPV9ne4Y9h8TGt82NBY/lXAFpJ6/AOC7uHmC7cgUBJgCbBlJb7f7CqvaDu7OS6vZq6oJ5lM4h9VmAyHicViPBsfZyIUIh6PEQgECE5MMDMzw9CIn2AwSDQaZWh4mKmpKaanI7tYiMp8PS759t0unvQPoCgKXl8PvX39KGNjdPnu87i3j/FAAF93DwODg2Xc6e1meMTPqKLQ6X1QxrZtV6/str01hzR+UsNOYbOCs3EcU4VSDqlGQVbmIzMRKBVACKQaA9vau7IuYVtfJ1fUyAnI6ets13Bhk23L4rdVIpNPkynBVgky+e+olkB1cW6FrCWp7MTB07FocCRkcPplgfNzeU5EDE7FdS681jj+osDJ6A4X5zSOTeo0xvNcmtc4OmnQ+kqnddbFJmdmNUxR3XIgbdH2VqNjwaD7S5H2hM41F6+YtCcNrq86PErDlQWbm59NHq5WOPeWTXwrJpcTGneWTMTes3Go70DRQK6lsFIp2NwAR9QeSF1+eYausDzkoroxNRzmTUMD75qaSDQ3U1TVcqqQ8q+c//+UmmAwSKKxkfdnz5FsacHKZiudSPnP//wHJwKqnS7X0FsAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"rf_1.png\"\n        title=\"rf_1.png\"\n        src=\"/static/e671b4b0021826413ff8f13be067e3fb/37523/rf_1.png\"\n        srcset=\"/static/e671b4b0021826413ff8f13be067e3fb/e9ff0/rf_1.png 180w,\n/static/e671b4b0021826413ff8f13be067e3fb/f21e7/rf_1.png 360w,\n/static/e671b4b0021826413ff8f13be067e3fb/37523/rf_1.png 720w,\n/static/e671b4b0021826413ff8f13be067e3fb/c483d/rf_1.png 751w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n</blockquote>\n<p>[출처] <a href=\"https://velog.io/@ayi4067/DAY27\">https://velog.io/@ayi4067/DAY27</a></p>\n<hr>\n<h3 id=\"배깅\" style=\"position:relative;\"><a href=\"#%EB%B0%B0%EA%B9%85\" aria-label=\"배깅 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>배깅</h3>\n<blockquote>\n<p>랜덤 샘플링한 데이터를 여러 모델에 학습시킨 뒤 결과를 집계하는 방식</p>\n</blockquote>\n<h4 id=\"배깅의-특징\" style=\"position:relative;\"><a href=\"#%EB%B0%B0%EA%B9%85%EC%9D%98-%ED%8A%B9%EC%A7%95\" aria-label=\"배깅의 특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>배깅의 특징</h4>\n<ul>\n<li>\n<p>배깅의 경우 각 분류기가 서로 독립적으로 병렬적으로 진행</p>\n</li>\n<li>\n<p>범주형 자료일 때 다수결로 채택, 숫자형 자료일 때 평균 값을 채택</p>\n</li>\n<li>\n<p>속도가 빠르며 과적합 영향이 적다.</p>\n</li>\n<li>\n<p>적은 데이터셋이라도 준수한 결과를 도출한다.</p>\n</li>\n<li>\n<p>배깅의 대표적인 알고리즘 : RandomForest</p>\n</li>\n</ul>\n<h4 id=\"부트스트랩-샘플링-방식\" style=\"position:relative;\"><a href=\"#%EB%B6%80%ED%8A%B8%EC%8A%A4%ED%8A%B8%EB%9E%A9-%EC%83%98%ED%94%8C%EB%A7%81-%EB%B0%A9%EC%8B%9D\" aria-label=\"부트스트랩 샘플링 방식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>부트스트랩 샘플링 방식</h4>\n<blockquote>\n<p>부트스트랩은 통계학 분야에서 <strong>여러 작은 데이터 셋을 임의로 생성하여 개별 평균의 분포도를 측정하는 목적을 위한 샘플링 방식</strong></p>\n</blockquote>\n<blockquote>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 628px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 31.666666666666664%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABaUlEQVQY0yXOzW/TMABA8f7/Zw4ctjMXhASiE6UbIEE7NI3RqFXWVrB0az6WLHHiJI4T2+VNdLd3+umNAKrOsIj1/8QdwFhLKDr2uWKft/TVLVauGKRPUgZEYkeX/mXQCq17+r5Ha41zjpE2jvmmZPvb55C8w0oPbeHrKuF8+ciXVURzf4oOXtMEp1xuP/J9fcbTz/c0eUZRlpRliRAFxhhGvYVP6zXV9Qkkb8FJ9HDA2wluAsHiLkf6M/p4jHqc4IdXLPdXqGxC1xZUsqauJVVVvYA4w2Y95j49pwiniA6MGVjsyiN4HUgqf8YQjzHpB27DH6z2c1Q6QbcFsm5omgYp5QtoRETvTfkVfWP2J2MbNxycY7pMufBC2ss39LtX1HcnnC1yJl7JZy8nnY9RIkNU8ogJIRiGgdE/IBMVcRIh8hRnBox1xGVHXCi67AEr15h6Q1LUREIRFQ366YG+a2mVQil1vLTW8gxBALvyxOAFggAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"rf_2.png\"\n        title=\"rf_2.png\"\n        src=\"/static/3fdadd610fcb37feac9c216653aefded/3d84d/rf_2.png\"\n        srcset=\"/static/3fdadd610fcb37feac9c216653aefded/e9ff0/rf_2.png 180w,\n/static/3fdadd610fcb37feac9c216653aefded/f21e7/rf_2.png 360w,\n/static/3fdadd610fcb37feac9c216653aefded/3d84d/rf_2.png 628w\"\n        sizes=\"(max-width: 628px) 100vw, 628px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n</blockquote>\n<p>[출처] <a href=\"https://velog.io/@ayi4067/DAY27\">https://velog.io/@ayi4067/DAY27</a></p>\n<h4 id=\"진행과정\" style=\"position:relative;\"><a href=\"#%EC%A7%84%ED%96%89%EA%B3%BC%EC%A0%95\" aria-label=\"진행과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>진행과정</h4>\n<blockquote>\n<p><img src=\"/5176a9f1d8def6595977e42df1978823/rf_3.png\" alt=\"rf_3.PNG\"></p>\n</blockquote>\n<p>[출처] <a href=\"https://medium.com/ml-research-lab/bagging-ensemble-meta-algorithm-for-reducing-variance-c98fffa5489f\">https://medium.com/ml-research-lab/bagging-ensemble-meta-algorithm-for-reducing-variance-c98fffa5489f</a></p>\n<hr>\n<h4 id=\"하이퍼-파라미터-튜닝\" style=\"position:relative;\"><a href=\"#%ED%95%98%EC%9D%B4%ED%8D%BC-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D\" aria-label=\"하이퍼 파라미터 튜닝 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>하이퍼 파라미터 튜닝</h4>\n<blockquote>\n<p>n_estimators : 랜덤 포레스트의 <strong>결정 트리의 갯수</strong>를 지정. <em>default값은 10</em></p>\n</blockquote>\n<blockquote>\n<p>max_features : 최적의 분할을 위해 고려해야 할 <strong>특징들의 갯수</strong></p>\n</blockquote>\n<blockquote>\n<p>min_sample_split : 노드 분할을 위한 <strong>최소 샘플 데이터의 갯수</strong></p>\n</blockquote>\n<blockquote>\n<p>min_samples_leaf : 말단 노드가 되기 위한 최소한의 샘플 수</p>\n</blockquote>\n<blockquote>\n<p>max_depth : 트리의 최대 깊이</p>\n</blockquote>\n<blockquote>\n<p>max_leaf_nodes : 말단 노드의 최대 갯수</p>\n</blockquote>\n<h3 id=\"oob-스코어\" style=\"position:relative;\"><a href=\"#oob-%EC%8A%A4%EC%BD%94%EC%96%B4\" aria-label=\"oob 스코어 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>OOB 스코어</h3>\n<h4 id=\"oob-오차\" style=\"position:relative;\"><a href=\"#oob-%EC%98%A4%EC%B0%A8\" aria-label=\"oob 오차 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>OOB 오차</h4>\n<blockquote>\n<p>일반적으로 배깅 방식은 데이터셋의 2/3을 훈련 데이터로 사용한다. 나머지 1/3을 OOB(Out-of-Bag)관측치라 한다. <strong>OOB와 훈련 데이터셋의 예측과의 차이를 OOB 오차</strong>라고 하며 이 오차가 <strong>배깅 방식에서 평가 방식</strong>으로 사용된다. 이 OOB 오차를 통해 <em>OOB 스코어를 계산</em>한다.</p>\n</blockquote>\n<h3 id=\"변수-중요도\" style=\"position:relative;\"><a href=\"#%EB%B3%80%EC%88%98-%EC%A4%91%EC%9A%94%EB%8F%84\" aria-label=\"변수 중요도 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>변수 중요도</h3>\n<blockquote>\n<p>랜덤 포레스트의 장점 중 하나로 <strong>변수의 중요도를 구할 수 있다.</strong> 변수의 중요도를 파악하는 방법은 <em>어떤 변수가 분할 변수로 사용되고 사용된 후의 불순도(오차제곱합 or 지니계수)가 많이 감소되는 크기를 구한 후 평균</em>을 통해 구한다.</p>\n</blockquote>\n<blockquote>\n<p><img src=\"/0e431b3e2c2f960e5e965894d094298d/rf_4.png\" alt=\"rf_4.PNG\"></p>\n</blockquote>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a></p>\n<p>[2] <a href=\"https://ko.wikipedia.org/wiki/%EB%9E%9C%EB%8D%A4_%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8\">https://ko.wikipedia.org/wiki/%EB%9E%9C%EB%8D%A4_%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8</a></p>\n<p>[3] <a href=\"https://medium.com/nerd-for-tech/random-forest-sturdy-algorithm-d60b9f9140d4\">https://medium.com/nerd-for-tech/random-forest-sturdy-algorithm-d60b9f9140d4</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<ul>\n<li><a href=\"#keywords\">Keywords</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#randomforest\">RandomForest</a></p>\n<ul>\n<li>\n<p><a href=\"#%EB%B0%B0%EA%B9%85\">배깅</a></p>\n<ul>\n<li><a href=\"#%EB%B0%B0%EA%B9%85%EC%9D%98-%ED%8A%B9%EC%A7%95\">배깅의 특징</a></li>\n<li><a href=\"#%EB%B6%80%ED%8A%B8%EC%8A%A4%ED%8A%B8%EB%9E%A9-%EC%83%98%ED%94%8C%EB%A7%81-%EB%B0%A9%EC%8B%9D\">부트스트랩 샘플링 방식</a></li>\n<li><a href=\"#%EC%A7%84%ED%96%89%EA%B3%BC%EC%A0%95\">진행과정</a></li>\n<li><a href=\"#%ED%95%98%EC%9D%B4%ED%8D%BC-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D\">하이퍼 파라미터 튜닝</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#oob-%EC%8A%A4%EC%BD%94%EC%96%B4\">OOB 스코어</a></p>\n<ul>\n<li><a href=\"#oob-%EC%98%A4%EC%B0%A8\">OOB 오차</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EB%B3%80%EC%88%98-%EC%A4%91%EC%9A%94%EB%8F%84\">변수 중요도</a></p>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</li>\n</ul>\n</div>","excerpt":"Keywords RandomForest 배깅 하이퍼 파라미터 튜닝 OOB Score 변수 중요도 RandomForest 랜덤포레스트는 분류 및 회귀 ML 중 하나로 앙상블 학습 방법의 일종 으로 트리 기반 알고리즘이다. 각 트리들은 랜덤하게 서로 다른 특성을 가진다. 이를 통해 각 트리들의 예측이 비상관적이며 결과적으로 일반화 성능을 향상시킨다. 랜덤화는 각 트리들의 훈련 과정에서 진행되며, 랜덤 학습 데이터 추출 방법을 이용한 앙상블 학습법인 배깅(bagging)과 랜덤 노드 최적화(randomized node optimization)가 자주 사용된다. 이 두 가지 방법은 서로 동시에 사용되어 랜덤화 특성을 더욱 증진 시킬 수 있다.  [출처] https://velog.io/@ayi4067/DAY27 배깅 랜덤 샘플링한 데이터를 여러 모델에 학습시킨 뒤 결과를 집계하는 방식 배깅의 특징 배깅의 경우 각 분류기가 서로 독립적으로 병렬적으로 진행 범주형 자료일 때 다수결로 채택, 숫…","frontmatter":{"date":"September 18, 2022","title":"RandomForest","categories":"ML","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/ML/[ML] RandomForest/"}},"next":{"id":"ff193421-b6e2-575c-9d2a-4b47424d3d44","html":"<h2 id=\"naive-bayes\" style=\"position:relative;\"><a href=\"#naive-bayes\" aria-label=\"naive bayes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Naive Bayes</h2>\n<h3 id=\"소개\" style=\"position:relative;\"><a href=\"#%EC%86%8C%EA%B0%9C\" aria-label=\"소개 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>소개</h3>\n<p>나이브 베이즈란 베이즈 정리를 기반으로 한 분류 알고리즘. 단순하고 빠르며 정확도도 갖춘 알고리즘이지만 변수들간의 독립성이라는 조건이 만족되어야 한다.</p>\n<h3 id=\"베이즈-정리\" style=\"position:relative;\"><a href=\"#%EB%B2%A0%EC%9D%B4%EC%A6%88-%EC%A0%95%EB%A6%AC\" aria-label=\"베이즈 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>베이즈 정리</h3>\n<p>데이터라는 조건이 주어졌을 때 조건부확률을 구하는 공식으로 새로운 정보로 인해 기존의 값이 어떻게 영향을 받는 지 알 수 있다.</p>\n<ul>\n<li>사전 확률</li>\n</ul>\n<blockquote>\n<p>P(A)</p>\n</blockquote>\n<ul>\n<li>조건부 확률 (사후 확률)</li>\n</ul>\n<blockquote>\n<p>${P(A|B)  = {P(A \\cap B) \\over P(B)} = {P(B|A)P(A) \\over P(B)}}$</p>\n</blockquote>\n<h4 id=\"예시--x켓몬-빵-구매\" style=\"position:relative;\"><a href=\"#%EC%98%88%EC%8B%9C--x%EC%BC%93%EB%AA%AC-%EB%B9%B5-%EA%B5%AC%EB%A7%A4\" aria-label=\"예시  x켓몬 빵 구매 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>예시 : x켓몬 빵 구매</h4>\n<p>근처 편의점에 x켓몬 빵을 사러 갔을 때 구입 유무에 대한 표이다. 위 표를 근거로 점심에 편의점에 갔을 때 x켓몬 빵을 살 확률은?</p>\n<p><img src=\"/60deb62704eda7b302e0d82d9738fb2f/nb_1.png\" alt=\"nb_1.PNG\"></p>\n<h3 id=\"예제-라면사-분류\" style=\"position:relative;\"><a href=\"#%EC%98%88%EC%A0%9C-%EB%9D%BC%EB%A9%B4%EC%82%AC-%EB%B6%84%EB%A5%98\" aria-label=\"예제 라면사 분류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>예제: 라면사 분류</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">import</span> seaborn <span class=\"token keyword\">as</span> sns\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> warnings\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> accuracy_score<span class=\"token punctuation\">,</span> roc_auc_score\n\nwarnings<span class=\"token punctuation\">.</span>filterwarnings<span class=\"token punctuation\">(</span>action<span class=\"token operator\">=</span><span class=\"token string\">'ignore'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 데이터 불러오기</span>\nramen <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'C:/Users/USER/Project/everyday_python/data/df_ramen.csv'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'cp949'</span><span class=\"token punctuation\">)</span>\nramen<span class=\"token punctuation\">.</span>columns <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'type'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'item'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'place'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'region'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> LabelEncoder\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">MultiColumnLabelEncoder</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>columns <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>columns <span class=\"token operator\">=</span> columns <span class=\"token comment\"># array of column names to encode</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">fit</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>X<span class=\"token punctuation\">,</span>y<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self <span class=\"token comment\"># not relevant here</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">transform</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">'''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''</span>\n        output <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>columns <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">:</span>\n                output<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> LabelEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> colname<span class=\"token punctuation\">,</span>col <span class=\"token keyword\">in</span> output<span class=\"token punctuation\">.</span>iteritems<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                output<span class=\"token punctuation\">[</span>colname<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> LabelEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> output\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">fit_transform</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>X<span class=\"token punctuation\">,</span>y<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df <span class=\"token operator\">=</span> MultiColumnLabelEncoder<span class=\"token punctuation\">(</span>columns <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'item'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'place'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'region'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>ramen<span class=\"token punctuation\">)</span>\ndf <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span>\n\nX <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'place'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'price'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'region'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\ny <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'item'</span><span class=\"token punctuation\">]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n\nX_train<span class=\"token punctuation\">,</span> X_test<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">1234</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>naive_bayes <span class=\"token keyword\">import</span> CategoricalNB\n\ncnb <span class=\"token operator\">=</span> CategoricalNB<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\npred <span class=\"token operator\">=</span> cnb<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">acc <span class=\"token operator\">=</span> accuracy_score<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"예측 정확도 : {0:.3f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>acc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">예측 정확도 : 0.768</code></pre></div>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://datascienceschool.net/02%20mathematics/06.06%20%EB%B2%A0%EC%9D%B4%EC%A6%88%20%EC%A0%95%EB%A6%AC.html\">https://datascienceschool.net/02%20mathematics/06.06%20%EB%B2%A0%EC%9D%B4%EC%A6%88%20%EC%A0%95%EB%A6%AC.html</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#naive-bayes\">Naive Bayes</a></p>\n<ul>\n<li>\n<p><a href=\"#%EC%86%8C%EA%B0%9C\">소개</a></p>\n</li>\n<li>\n<p><a href=\"#%EB%B2%A0%EC%9D%B4%EC%A6%88-%EC%A0%95%EB%A6%AC\">베이즈 정리</a></p>\n<ul>\n<li><a href=\"#%EC%98%88%EC%8B%9C--x%EC%BC%93%EB%AA%AC-%EB%B9%B5-%EA%B5%AC%EB%A7%A4\">예시 : x켓몬 빵 구매</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%98%88%EC%A0%9C-%EB%9D%BC%EB%A9%B4%EC%82%AC-%EB%B6%84%EB%A5%98\">예제: 라면사 분류</a></p>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"September 17, 2022","title":"Naive_Bayes","categories":"ML","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/ML/[ML] Naive_Bayes/"}},"prev":{"id":"3fa11651-8acf-5d81-bcdc-ad895235be35","html":"<h2 id=\"ensemble\" style=\"position:relative;\"><a href=\"#ensemble\" aria-label=\"ensemble permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ensemble</h2>\n<p>앙상블 기법이란 한마디로 쉽게 설명하자면 <strong>여러 전문가(ML)들이 협력하여 결론(예측)을 하는 방식</strong>.</p>\n<p><img src=\"/93ced71a7b96e5ecde96fd534997c98c/ens_1.png\" alt=\"ens_1.PNG\"></p>\n<h3 id=\"앙상블-학습-유형\" style=\"position:relative;\"><a href=\"#%EC%95%99%EC%83%81%EB%B8%94-%ED%95%99%EC%8A%B5-%EC%9C%A0%ED%98%95\" aria-label=\"앙상블 학습 유형 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>앙상블 학습 유형</h3>\n<p>대표적인 3가지 학습 유형으로 <strong>배깅, 보팅, 부스팅 3가지 방법</strong>이 있다.</p>\n<h3 id=\"배깅bootstrap-aggregating-bagging\" style=\"position:relative;\"><a href=\"#%EB%B0%B0%EA%B9%85bootstrap-aggregating-bagging\" aria-label=\"배깅bootstrap aggregating bagging permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>배깅(Bootstrap Aggregating, Bagging)</h3>\n<h4 id=\"배깅이란\" style=\"position:relative;\"><a href=\"#%EB%B0%B0%EA%B9%85%EC%9D%B4%EB%9E%80\" aria-label=\"배깅이란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>배깅이란?</h4>\n<blockquote>\n<p>랜덤 샘플링한 데이터를 여러 모델에 학습시킨 뒤 결과를 집계하는 방식</p>\n</blockquote>\n<h4 id=\"특징\" style=\"position:relative;\"><a href=\"#%ED%8A%B9%EC%A7%95\" aria-label=\"특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>특징</h4>\n<ul>\n<li>\n<p>배깅의 경우 각 분류기가 서로 독립적으로 병렬적으로 진행</p>\n</li>\n<li>\n<p>범주형 자료일 때 다수결로 채택, 숫자형 자료일 때 평균 값을 채택</p>\n</li>\n<li>\n<p>속도가 빠르며 과적합 영향이 적다.</p>\n</li>\n<li>\n<p>적은 데이터셋이라도 준수한 결과를 도출한다.</p>\n</li>\n<li>\n<p>배깅의 대표적인 알고리즘 : RandomForest</p>\n</li>\n</ul>\n<h4 id=\"진행-과정\" style=\"position:relative;\"><a href=\"#%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95\" aria-label=\"진행 과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>진행 과정</h4>\n<p><img src=\"/5176a9f1d8def6595977e42df1978823/rf_3.png\" alt=\"rf_3.PNG\">\n[출처] <a href=\"https://medium.com/ml-research-lab/bagging-ensemble-meta-algorithm-for-reducing-variance-c98fffa5489f\">https://medium.com/ml-research-lab/bagging-ensemble-meta-algorithm-for-reducing-variance-c98fffa5489f</a></p>\n<h3 id=\"보팅\" style=\"position:relative;\"><a href=\"#%EB%B3%B4%ED%8C%85\" aria-label=\"보팅 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>보팅</h3>\n<h4 id=\"보팅이란\" style=\"position:relative;\"><a href=\"#%EB%B3%B4%ED%8C%85%EC%9D%B4%EB%9E%80\" aria-label=\"보팅이란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>보팅이란?</h4>\n<blockquote>\n<p>여러 분류기가 투표를 통해 예측 결과를 결정하는 방식</p>\n</blockquote>\n<h4 id=\"방식\" style=\"position:relative;\"><a href=\"#%EB%B0%A9%EC%8B%9D\" aria-label=\"방식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>방식</h4>\n<ul>\n<li>\n<p>소프트 보팅 :모든 분류기가 예측한 값의 결정 확률 평균을 구한 뒤 확률이 높은 값으로 결정</p>\n</li>\n<li>\n<p>하드 보팅 : 다수의 분류기가 예측한 값으로 결정</p>\n</li>\n</ul>\n<p><img src=\"/2c88b57bf183decb396a15286bbcc3b8/ens_2.png\" alt=\"ens_2.PNG\">\n[출처] <a href=\"https://velog.io/@gangjoo/ML-%EB%B6%84%EB%A5%98-%EC%95%99%EC%83%81%EB%B8%94-%ED%95%99%EC%8A%B5-Ensemble-Learning%EA%B3%BC-%EB%B3%B4%ED%8C%85-Voting\">https://velog.io/@gangjoo/ML-%EB%B6%84%EB%A5%98-%EC%95%99%EC%83%81%EB%B8%94-%ED%95%99%EC%8A%B5-Ensemble-Learning%EA%B3%BC-%EB%B3%B4%ED%8C%85-Voting</a></p>\n<h3 id=\"부스팅\" style=\"position:relative;\"><a href=\"#%EB%B6%80%EC%8A%A4%ED%8C%85\" aria-label=\"부스팅 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>부스팅</h3>\n<h4 id=\"부스팅이란\" style=\"position:relative;\"><a href=\"#%EB%B6%80%EC%8A%A4%ED%8C%85%EC%9D%B4%EB%9E%80\" aria-label=\"부스팅이란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>부스팅이란?</h4>\n<blockquote>\n<p>부스팅은 가중치를 활용하여 약 분류기를 강 분류기로 만드는 방법.</p>\n</blockquote>\n<p><img src=\"/24a7c14bcfbdc59571426527c9c16e8d/ens_4.png\" alt=\"ens_4.PNG\"></p>\n<h4 id=\"진행방식\" style=\"position:relative;\"><a href=\"#%EC%A7%84%ED%96%89%EB%B0%A9%EC%8B%9D\" aria-label=\"진행방식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>진행방식</h4>\n<ol>\n<li>한 라운드 당 하나의 모델을 학습</li>\n<li>각 라운드 당 오분류된 객체들의 가중치를 조절</li>\n<li>조절된 가중치로 다시 학습</li>\n</ol>\n<p>위 1~3 과정을 반복하여 결과</p>\n<h4 id=\"특징-1\" style=\"position:relative;\"><a href=\"#%ED%8A%B9%EC%A7%95-1\" aria-label=\"특징 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>특징</h4>\n<ul>\n<li>\n<p>각 분류기가 순차적으로 진행</p>\n</li>\n<li>\n<p>데이터셋에 과적화될 위험성이 큼</p>\n</li>\n<li>\n<p>배깅 방식에 비해 속도가 느림</p>\n</li>\n<li>\n<p>결과 도출시에도 각 모델 결과에 가중치를 반영한다. 쉽게 말하면 나중 모델의 결과에 더 높은 가중치를 둠.</p>\n</li>\n<li>\n<p>대표적인 알고리즘으로 XGBoost, GBM, LightBoost 등이 있다.</p>\n</li>\n</ul>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"http://www.dinnopartners.com/__trashed-4/\">http://www.dinnopartners.com/__trashed-4/</a></p>\n<p>[2] <a href=\"https://nicola-ml.tistory.com/95\">https://nicola-ml.tistory.com/95</a></p>\n<p>[3] <a href=\"https://blog.naver.com/PostView.naver?blogId=hajuny2903&#x26;logNo=222422472569&#x26;redirect=Dlog&#x26;widgetTypeCall=true&#x26;directAccess=false\">https://blog.naver.com/PostView.naver?blogId=hajuny2903&#x26;logNo=222422472569&#x26;redirect=Dlog&#x26;widgetTypeCall=true&#x26;directAccess=false</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#ensemble\">Ensemble</a></p>\n<ul>\n<li>\n<p><a href=\"#%EC%95%99%EC%83%81%EB%B8%94-%ED%95%99%EC%8A%B5-%EC%9C%A0%ED%98%95\">앙상블 학습 유형</a></p>\n</li>\n<li>\n<p><a href=\"#%EB%B0%B0%EA%B9%85bootstrap-aggregating-bagging\">배깅(Bootstrap Aggregating, Bagging)</a></p>\n<ul>\n<li><a href=\"#%EB%B0%B0%EA%B9%85%EC%9D%B4%EB%9E%80\">배깅이란?</a></li>\n<li><a href=\"#%ED%8A%B9%EC%A7%95\">특징</a></li>\n<li><a href=\"#%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95\">진행 과정</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EB%B3%B4%ED%8C%85\">보팅</a></p>\n<ul>\n<li><a href=\"#%EB%B3%B4%ED%8C%85%EC%9D%B4%EB%9E%80\">보팅이란?</a></li>\n<li><a href=\"#%EB%B0%A9%EC%8B%9D\">방식</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EB%B6%80%EC%8A%A4%ED%8C%85\">부스팅</a></p>\n<ul>\n<li><a href=\"#%EB%B6%80%EC%8A%A4%ED%8C%85%EC%9D%B4%EB%9E%80\">부스팅이란?</a></li>\n<li><a href=\"#%EC%A7%84%ED%96%89%EB%B0%A9%EC%8B%9D\">진행방식</a></li>\n<li><a href=\"#%ED%8A%B9%EC%A7%95-1\">특징</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"September 19, 2022","title":"Ensemble","categories":"ML","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/ML/[ML] ensemble/"}},"site":{"siteMetadata":{"siteUrl":"https://han-archives.github.io","comments":{"utterances":{"repo":"Han-Archives/han-archives.github.io"}}}}},"pageContext":{"slug":"/ML/[ML] RandomForest/","nextSlug":"/ML/[ML] Naive_Bayes/","prevSlug":"/ML/[ML] ensemble/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}