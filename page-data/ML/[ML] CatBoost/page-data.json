{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/ML/[ML] CatBoost/",
    "result": {"data":{"cur":{"id":"7d467ff8-6ac1-56fa-ba39-f6f36ed33bb5","html":"<h2 id=\"catboost\" style=\"position:relative;\"><a href=\"#catboost\" aria-label=\"catboost permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CatBoost</h2>\n<p>CatBoost는 Unbiased boosting with categorical features에 초점을 맞춰서 생성된 알고리즘. <strong>즉 범주형 변수에 초점을 두어 만들어진 Boosting 기반의 알고리즘.</strong></p>\n<h3 id=\"주요-알고리즘\" style=\"position:relative;\"><a href=\"#%EC%A3%BC%EC%9A%94-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98\" aria-label=\"주요 알고리즘 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>주요 알고리즘</h3>\n<p>CatBoost는 앞서 2가지 이슈를 먼저 언급합니다.</p>\n<h4 id=\"target-leakage\" style=\"position:relative;\"><a href=\"#target-leakage\" aria-label=\"target leakage permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Target Leakage</h4>\n<p>범주형 변수(categorical Feautres)를 수치형 변수로 변환할 때 target인 label에 대한 정보가 어느 정도 반영됨.즉 target의 정보가 유출</p>\n<p>이로인해 training dataset과 test dataset 간 확률 분포가 불일치</p>\n<h4 id=\"predict-shift\" style=\"position:relative;\"><a href=\"#predict-shift\" aria-label=\"predict shift permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Predict Shift</h4>\n<p>Target Leakage로 인해 Train dataset과 test dataset과는 다른 확률 분포를 가질 수 있다. 이 점을 Predict Shift로 정의</p>\n<p>위에 대한 해결방안으로</p>\n<p><strong>Target Leakage -> Ordered TS</strong> , <strong>Predict Shift -> Ordered Boosting</strong> 방법이 제시됨</p>\n<h3 id=\"ordered-ts\" style=\"position:relative;\"><a href=\"#ordered-ts\" aria-label=\"ordered ts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ordered TS</h3>\n<p>위의 TS는 Target Statistic 즉 범주형 변수가 변환 되는 값으로 CatBoost에서는 아래의 식을 통해 계산.</p>\n<p><img src=\"/2468078ea223442249902b699ac2f52b/cb_1.png\" alt=\"cb_1.PNG\"></p>\n<p>구하는 방식을 좀 더 자세히 보자면\n<img src=\"/d73c635671c1a335a7d549d8b9e4e857/cb_2.png\" alt=\"cb_2.PNG\"></p>\n<p>[출처] <a href=\"https://www.youtube.com/watch?v=2Yi_Jse_7JQ&#x26;list=WL&#x26;index=2&#x26;t=1817s\">https://www.youtube.com/watch?v=2Yi_Jse_7JQ&#x26;list=WL&#x26;index=2&#x26;t=1817s</a></p>\n<p>위 식에서 <em>a는 파라미터, p는 관측된 y의 평균</em>으로 <strong>기존 방식에서는 total y의 평균이 반영</strong>된 반면에 위 과정에서는 <strong>관측된 값에 대한 y 값만 다루기 때문에 Target Leakage가 감소</strong></p>\n<h3 id=\"ordered-boosting\" style=\"position:relative;\"><a href=\"#ordered-boosting\" aria-label=\"ordered boosting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ordered Boosting</h3>\n<p>Prediction Shift를 해결하기 위해 기존의 방식 <em>t번째 모형을 바로 잔차 계산에 사용하는 것</em>이 아닌  <strong>t-1번 째 모형을 통해 얻은 값을 잔차 계산에 사용.</strong></p>\n<p><img src=\"/8544d30867da9daa09ad5d48d0e80a50/cb_4.png\" alt=\"cb_4.PNG\"></p>\n<h3 id=\"진행과정\" style=\"position:relative;\"><a href=\"#%EC%A7%84%ED%96%89%EA%B3%BC%EC%A0%95\" aria-label=\"진행과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>진행과정</h3>\n<h4 id=\"1-training-dataset을-s1번-random-permutation\" style=\"position:relative;\"><a href=\"#1-training-dataset%EC%9D%84-s1%EB%B2%88-random-permutation\" aria-label=\"1 training dataset을 s1번 random permutation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Training Dataset을 s+1번 Random Permutation</h4>\n<h5 id=\"2-oblivious-tree-생성\" style=\"position:relative;\"><a href=\"#2-oblivious-tree-%EC%83%9D%EC%84%B1\" aria-label=\"2 oblivious tree 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Oblivious Tree 생성</h5>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 54.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB1UlEQVQoz2VSz2sTQRR+u4kxlAhppU1s2lJ/IKVWWixFL+pFkF5EELxI9agHoScLXoR66S3d2d3ZnZ15b2Y2P5rYTdNT/z/J5ocB4YM3vDcfvO/7HgCxcso3rtLVgall+kFmyykHYqD9CYiVLN+67tQyupeZ6oX8Nx2XbVQvtNlDrBjuzGhTOCaoa/GMaJ9oFeNRZzzKCzsSnVM1PBb9BfLBeO4cs6B9MM0tKX4nw7Nk+DJBMOeFMb+C4XNFTisE01y20Sldv0nsPL+o2dek943+uJaBbb433Z9JtoQhGAYFHdzBMJfBHmPy1rQPVVpT0XgxV/ubKv5I3Q/Y2ZRxTfJDbH3WvR0lizTVPMYjJZYp/IGDT7IDeuTKbQx+yasvonOkuifi8lj0vyf9dyI9S4ZrMoJ5V8CwA4W3bLhkoz2pwHhV5LuanqLaIdwnOiC9rdUu4hNLd5HDLA9Q54DeouIu+SUKFpGDZgsUNmTUkPG6jNZjvhHzhuQPpViTUXVCzpO8n9l6D10zUzEN0zAwrGD9lUtdz3S5FYL2wOQfnJxcacevbwavbgbVtgBizizJ/OFov2D8la6sXaiSDZ3cSGd2JI72iyYo2tA1Afx3JBOgN8Jc5y87qB1k8desAQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"cb_3.png\"\n        title=\"cb_3.png\"\n        src=\"/static/f25ae1bdac9c314c9366110e549e8ef2/37523/cb_3.png\"\n        srcset=\"/static/f25ae1bdac9c314c9366110e549e8ef2/e9ff0/cb_3.png 180w,\n/static/f25ae1bdac9c314c9366110e549e8ef2/f21e7/cb_3.png 360w,\n/static/f25ae1bdac9c314c9366110e549e8ef2/37523/cb_3.png 720w,\n/static/f25ae1bdac9c314c9366110e549e8ef2/73b94/cb_3.png 1004w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span>\n[출처] <a href=\"https://towardsdatascience.com/introduction-to-gradient-boosting-on-decision-trees-with-catboost-d511a9ccbd14\">https://towardsdatascience.com/introduction-to-gradient-boosting-on-decision-trees-with-catboost-d511a9ccbd14</a></p>\n<h4 id=\"3-ordered-ts-ordered-boosting-과정을-통해-손실-함수를-얻고-이를-최소화하는-학습을-시행\" style=\"position:relative;\"><a href=\"#3-ordered-ts-ordered-boosting-%EA%B3%BC%EC%A0%95%EC%9D%84-%ED%86%B5%ED%95%B4-%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98%EB%A5%BC-%EC%96%BB%EA%B3%A0-%EC%9D%B4%EB%A5%BC-%EC%B5%9C%EC%86%8C%ED%99%94%ED%95%98%EB%8A%94-%ED%95%99%EC%8A%B5%EC%9D%84-%EC%8B%9C%ED%96%89\" aria-label=\"3 ordered ts ordered boosting 과정을 통해 손실 함수를 얻고 이를 최소화하는 학습을 시행 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Ordered TS, Ordered Boosting 과정을 통해 손실 함수를 얻고 이를 최소화하는 학습을 시행</h4>\n<h4 id=\"4-t번째-데이터를-t-1번째-모형으로-예측하고-잔차와-gradient를-update함-t--s\" style=\"position:relative;\"><a href=\"#4-t%EB%B2%88%EC%A7%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-t-1%EB%B2%88%EC%A7%B8-%EB%AA%A8%ED%98%95%EC%9C%BC%EB%A1%9C-%EC%98%88%EC%B8%A1%ED%95%98%EA%B3%A0-%EC%9E%94%EC%B0%A8%EC%99%80-gradient%EB%A5%BC-update%ED%95%A8-t--s\" aria-label=\"4 t번째 데이터를 t 1번째 모형으로 예측하고 잔차와 gradient를 update함 t  s permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. t번째 데이터를 t-1번째 모형으로 예측하고 잔차와 Gradient를 update함 (t &#x3C; s)</h4>\n<h4 id=\"5-s번째-예측이-완료되면-완료된-모형으로-남은-1번에-적용하여-leaf-value값을-얻음\" style=\"position:relative;\"><a href=\"#5-s%EB%B2%88%EC%A7%B8-%EC%98%88%EC%B8%A1%EC%9D%B4-%EC%99%84%EB%A3%8C%EB%90%98%EB%A9%B4-%EC%99%84%EB%A3%8C%EB%90%9C-%EB%AA%A8%ED%98%95%EC%9C%BC%EB%A1%9C-%EB%82%A8%EC%9D%80-1%EB%B2%88%EC%97%90-%EC%A0%81%EC%9A%A9%ED%95%98%EC%97%AC-leaf-value%EA%B0%92%EC%9D%84-%EC%96%BB%EC%9D%8C\" aria-label=\"5 s번째 예측이 완료되면 완료된 모형으로 남은 1번에 적용하여 leaf value값을 얻음 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. s번째 예측이 완료되면 완료된 모형으로 남은 1번에 적용하여 leaf value값을 얻음.</h4>\n<p>※Oblivious Tree를 사용하는 이유는 3~4과정을 기존의 트리 모형으로는 메모리 부족 issue가 발생. 따라서 Oblivious Tree 구조를 사용</p>\n<h3 id=\"장단점\" style=\"position:relative;\"><a href=\"#%EC%9E%A5%EB%8B%A8%EC%A0%90\" aria-label=\"장단점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>장단점</h3>\n<h4 id=\"장점\" style=\"position:relative;\"><a href=\"#%EC%9E%A5%EC%A0%90\" aria-label=\"장점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>장점</h4>\n<ul>\n<li>\n<p>범수형 변수에 대한 인코딩 방식 제공함에 따라 일반적으로 범주형 변수가 많은 데이터셋의 예측력이 다른 부스팅 알고리즘에 비해 뛰어나다.</p>\n</li>\n<li>\n<p>다른 부스팅 계열 Xgboost, LightGBM에 비해 최적 하이퍼 파라미터 튜닝에 덜 민감하다. 파라미터 최적화가 잘 되어있다.</p>\n</li>\n</ul>\n<h4 id=\"단점\" style=\"position:relative;\"><a href=\"#%EB%8B%A8%EC%A0%90\" aria-label=\"단점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>단점</h4>\n<ul>\n<li>\n<p>LightGBM에서 언급한 Sparse Feature Space는 처리하지 못한다.</p>\n</li>\n<li>\n<p>수치형 변수가 많은 데이터셋의 경우 LightGBM에 비해 학습 속도가 느리다.</p>\n</li>\n</ul>\n<h3 id=\"hyper-parameter\" style=\"position:relative;\"><a href=\"#hyper-parameter\" aria-label=\"hyper parameter permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hyper Parameter</h3>\n<p><strong>loss_function</strong></p>\n<blockquote>\n<p>훈련에 사용될 손실함수</p>\n</blockquote>\n<p><strong>eval_metric</strong></p>\n<blockquote>\n<p>최적의 모델 선택을 위한 함수. 선택적으로 파라미터를 입력</p>\n</blockquote>\n<p><strong>iterations</strong></p>\n<blockquote>\n<p>최대 트리의 수. default=1000</p>\n</blockquote>\n<p><strong>learning_rate</strong></p>\n<blockquote>\n<p>학습률. default=0.03</p>\n</blockquote>\n<p><strong>random_seed</strong></p>\n<blockquote>\n<p>random seed</p>\n</blockquote>\n<p><strong>l2_leaf_reg</strong></p>\n<blockquote>\n<p>비용 함수의 L2 정규화 계수. default=3.0</p>\n</blockquote>\n<p><strong>bootstrap_type</strong></p>\n<blockquote>\n<p>개체의 가중치를 샘플링하는 방법. 베이지안, 베르누이, MVS, 포아송 등</p>\n</blockquote>\n<p><strong>bagging_temperature</strong></p>\n<blockquote>\n<p>베이지안 부트스트랩 설정을 정의. 1로 설정된 경우 객체의 가중치는 지수 분포에서 샘플링. 0인 경우 모든 가중치는 1로 설정. default=1</p>\n</blockquote>\n<p><strong>subsample</strong></p>\n<blockquote>\n<p>배깅에 대한 샘플 비율. default는 데이터셋과 bootstrap 유형에 따라 결정. 0.66~1</p>\n</blockquote>\n<p><strong>sample_frequency</strong></p>\n<blockquote>\n<p>트리 구조를 만들 때 가중치와 객체의 샘플링 빈도. default는 PerTreeLevel</p>\n</blockquote>\n<p><strong>best_model_min_treees</strong></p>\n<blockquote>\n<p>최상의 모델이 가져야 하는 최소 트리 수</p>\n</blockquote>\n<p><strong>depth</strong>\n트리의 깊이. default= 16</p>\n<p><strong>min_data_in_leaf</strong></p>\n<blockquote>\n<p>leaf의 최소 훈련 샘플 수 지정된 값보다 적은 샘플 수가 있는 잎에서 분할 중지. default=1</p>\n</blockquote>\n<p><strong>max_leaves</strong></p>\n<blockquote>\n<p>결과 트리의 최대 리프의 수. default= 31</p>\n</blockquote>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://www.youtube.com/watch?v=2Yi_Jse_7JQ&#x26;list=WL&#x26;index=2&#x26;t=1817s\">https://www.youtube.com/watch?v=2Yi_Jse_7JQ&#x26;list=WL&#x26;index=2&#x26;t=1817s</a></p>\n<p>[2] <a href=\"https://gentlej90.tistory.com/100\">https://gentlej90.tistory.com/100</a></p>\n<p>[3] <a href=\"https://catboost.ai/en/docs/concepts/python-reference_catboost\">https://catboost.ai/en/docs/concepts/python-reference_catboost</a></p>\n<p>[4] <a href=\"https://catboost.ai/en/docs/references/training-parameters/common#eval_metric\">https://catboost.ai/en/docs/references/training-parameters/common#eval_metric</a></p>\n<p>[5] <a href=\"https://dailyheumsi.tistory.com/136\">https://dailyheumsi.tistory.com/136</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#catboost\">CatBoost</a></p>\n<ul>\n<li>\n<p><a href=\"#%EC%A3%BC%EC%9A%94-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98\">주요 알고리즘</a></p>\n<ul>\n<li><a href=\"#target-leakage\">Target Leakage</a></li>\n<li><a href=\"#predict-shift\">Predict Shift</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#ordered-ts\">Ordered TS</a></p>\n</li>\n<li>\n<p><a href=\"#ordered-boosting\">Ordered Boosting</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%A7%84%ED%96%89%EA%B3%BC%EC%A0%95\">진행과정</a></p>\n<ul>\n<li>\n<p><a href=\"#1-training-dataset%EC%9D%84-s1%EB%B2%88-random-permutation\">1. Training Dataset을 s+1번 Random Permutation</a></p>\n<ul>\n<li><a href=\"#2-oblivious-tree-%EC%83%9D%EC%84%B1\">2. Oblivious Tree 생성</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#3-ordered-ts-ordered-boosting-%EA%B3%BC%EC%A0%95%EC%9D%84-%ED%86%B5%ED%95%B4-%EC%86%90%EC%8B%A4-%ED%95%A8%EC%88%98%EB%A5%BC-%EC%96%BB%EA%B3%A0-%EC%9D%B4%EB%A5%BC-%EC%B5%9C%EC%86%8C%ED%99%94%ED%95%98%EB%8A%94-%ED%95%99%EC%8A%B5%EC%9D%84-%EC%8B%9C%ED%96%89\">3. Ordered TS, Ordered Boosting 과정을 통해 손실 함수를 얻고 이를 최소화하는 학습을 시행</a></p>\n</li>\n<li>\n<p><a href=\"#4-t%EB%B2%88%EC%A7%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-t-1%EB%B2%88%EC%A7%B8-%EB%AA%A8%ED%98%95%EC%9C%BC%EB%A1%9C-%EC%98%88%EC%B8%A1%ED%95%98%EA%B3%A0-%EC%9E%94%EC%B0%A8%EC%99%80-gradient%EB%A5%BC-update%ED%95%A8-t--s\">4. t번째 데이터를 t-1번째 모형으로 예측하고 잔차와 Gradient를 update함 (t &#x3C; s)</a></p>\n</li>\n<li>\n<p><a href=\"#5-s%EB%B2%88%EC%A7%B8-%EC%98%88%EC%B8%A1%EC%9D%B4-%EC%99%84%EB%A3%8C%EB%90%98%EB%A9%B4-%EC%99%84%EB%A3%8C%EB%90%9C-%EB%AA%A8%ED%98%95%EC%9C%BC%EB%A1%9C-%EB%82%A8%EC%9D%80-1%EB%B2%88%EC%97%90-%EC%A0%81%EC%9A%A9%ED%95%98%EC%97%AC-leaf-value%EA%B0%92%EC%9D%84-%EC%96%BB%EC%9D%8C\">5. s번째 예측이 완료되면 완료된 모형으로 남은 1번에 적용하여 leaf value값을 얻음.</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%9E%A5%EB%8B%A8%EC%A0%90\">장단점</a></p>\n<ul>\n<li><a href=\"#%EC%9E%A5%EC%A0%90\">장점</a></li>\n<li><a href=\"#%EB%8B%A8%EC%A0%90\">단점</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#hyper-parameter\">Hyper Parameter</a></p>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</li>\n</ul>\n</div>","excerpt":"CatBoost CatBoost는 Unbiased boosting with categorical features에 초점을 맞춰서 생성된 알고리즘. 즉 범주형 변수에 초점을 두어 만들어진 Boosting 기반의 알고리즘. 주요 알고리즘 CatBoost는 앞서 2가지 이슈를 먼저 언급합니다. Target Leakage 범주형 변수(categorical Feautres)를 수치형 변수로 변환할 때 target인 label에 대한 정보가 어느 정도 반영됨.즉 target의 정보가 유출 이로인해 training dataset과 test dataset 간 확률 분포가 불일치 Predict Shift Target Leakage로 인해 Train dataset과 test dataset과는 다른 확률 분포를 가질 수 있다. 이 점을 Predict Shift로 정의 위에 대한 해결방안으로 Target Leakage -> Ordered TS , Predict Shift -> Ordered Boosti…","frontmatter":{"date":"October 16, 2022","title":"CatBoost","categories":"ML","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/ML/[ML] CatBoost/"}},"next":{"id":"5b70f5fe-7146-5ec9-ba1e-199e71befc3e","html":"<h2 id=\"lightgbm\" style=\"position:relative;\"><a href=\"#lightgbm\" aria-label=\"lightgbm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LightGBM</h2>\n<h3 id=\"소개\" style=\"position:relative;\"><a href=\"#%EC%86%8C%EA%B0%9C\" aria-label=\"소개 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>소개</h3>\n<p>LightGBM은 GradientBoosting 프레임워크로 결정 트리 기반의 학습 알고리즘으로 XGBoost와 달리 트리가 아래 그림처럼\n수직으로 확장하는 방식(leaf-wise)</p>\n<p><img src=\"/5f22288cb14121619f2bd98a675b2ba2/lgbm_1.png\" alt=\"lgbm_1.PNG\">\n[출처] <a href=\"https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc\">https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc</a></p>\n<h3 id=\"장단점\" style=\"position:relative;\"><a href=\"#%EC%9E%A5%EB%8B%A8%EC%A0%90\" aria-label=\"장단점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>장단점</h3>\n<h4 id=\"장점\" style=\"position:relative;\"><a href=\"#%EC%9E%A5%EC%A0%90\" aria-label=\"장점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>장점</h4>\n<blockquote>\n<p>leaf-wise 방식은 Delta loss가 가장 큰 Leaf을 선택해 분할하는 방식으로 loss를 줄여나간다. 또한 level-wise 알고리즘의 경우 모든 leaf가 균일하게 선택되 분할되기 때문에 leaf-wise 방식이 수행 속도가 빠르고 예측 오류를 최소화할 수 있다.</p>\n</blockquote>\n<blockquote>\n<p>GPU 학습 지원 및 적은 메모리 사용량 등 다양한 이점 등이 존재한다.</p>\n</blockquote>\n<h4 id=\"단점\" style=\"position:relative;\"><a href=\"#%EB%8B%A8%EC%A0%90\" aria-label=\"단점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>단점</h4>\n<blockquote>\n<p>Leaf Wise의 큰 단점으로 작은 데이터셋의 경우 과적합 되기 쉽다는 문제점을 갖고 있습니다.</p>\n</blockquote>\n<h3 id=\"핵심-개념\" style=\"position:relative;\"><a href=\"#%ED%95%B5%EC%8B%AC-%EA%B0%9C%EB%85%90\" aria-label=\"핵심 개념 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>핵심 개념</h3>\n<h4 id=\"goss-gradient-based-one-side-sampling\" style=\"position:relative;\"><a href=\"#goss-gradient-based-one-side-sampling\" aria-label=\"goss gradient based one side sampling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GOSS (Gradient-Based One-Side Sampling)</h4>\n<blockquote>\n<p>수많은 객체 중에서 중요한 객체를 선택하는 방식으로 높은 기울기(Gradient)를 가지는 객체를 남기고 낮은 기울기를 가지는 객체는 제외하는 방법</p>\n</blockquote>\n<h4 id=\"진행과정\" style=\"position:relative;\"><a href=\"#%EC%A7%84%ED%96%89%EA%B3%BC%EC%A0%95\" aria-label=\"진행과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>진행과정</h4>\n<ol>\n<li>Absolute Gradient에 따라 객체를 정렬시킨다.</li>\n<li>정렬시킨 객체 중 높은 Gradient를 가지는 상위 객체들은 a% 랜덤하게 남겨두고 낮은 Gradient를 가지는 낮은 객체들 중 b% 객체들은 랜덤으로 drop하여 중요하지 않은 객체들은 제외 시킴</li>\n</ol>\n<p>위의  1-a/b 값이 1보다 크다면 효율성이 높다.</p>\n<h4 id=\"알고리즘\" style=\"position:relative;\"><a href=\"#%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98\" aria-label=\"알고리즘 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>알고리즘</h4>\n<p><img src=\"/9e3a46eb38416840fe1325d12f577e3e/lgbm_2.png\" alt=\"lgbm_2.PNG\">\n[출처] <a href=\"https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e\">https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e</a></p>\n<h4 id=\"efb-exclusive-feature-bundling\" style=\"position:relative;\"><a href=\"#efb-exclusive-feature-bundling\" aria-label=\"efb exclusive feature bundling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EFB (Exclusive Feature Bundling)</h4>\n<blockquote>\n<p>원핫 인코딩 변환 등에 의해 <strong>대부분의 Feature들은 서로 완전히 관계없는(상호 배타적인) 특징</strong>을 가지지만 <strong>결측값 문제등으로 인해 Feature간의 어떤 관계(conflict)가 발생하는 경우</strong>가 있다. 이를 <strong>Sparse Feature Space</strong>라 하는데 이런 요소들이 많아지면 시간복잡도 증가 및 트리의 깊이가 증가하는 등 여러 문제가 발생한다. <strong>EFB는 이러한 Feature들을 Bundling하여 Feature의 수를 줄이는 기법이다.</strong>.</p>\n</blockquote>\n<h3 id=\"hyper-parameter\" style=\"position:relative;\"><a href=\"#hyper-parameter\" aria-label=\"hyper parameter permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hyper Parameter</h3>\n<h4 id=\"leaf-wise-tree의-튜닝-방법\" style=\"position:relative;\"><a href=\"#leaf-wise-tree%EC%9D%98-%ED%8A%9C%EB%8B%9D-%EB%B0%A9%EB%B2%95\" aria-label=\"leaf wise tree의 튜닝 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Leaf-wise Tree의 튜닝 방법</h4>\n<p>num_leaves 개수를 먼저 설정한 뒤 min_child_samples, max_depth를 설정하면서 모델의 복잡도를 줄이는 것이 가장 효율적인 방법.</p>\n<h4 id=\"parameters\" style=\"position:relative;\"><a href=\"#parameters\" aria-label=\"parameters permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Parameters</h4>\n<blockquote>\n<p>max_depth : Tree의 최대 깊이. 값이 클수록 과적합. default=-1</p>\n</blockquote>\n<blockquote>\n<p>min_data_in_leaf : leaf가 가지는 최소한의 레코드 수. default=20</p>\n</blockquote>\n<blockquote>\n<p>feature_fraction : 변수 선택 시 무작위로 선택하는 비율. default=1.0</p>\n</blockquote>\n<blockquote>\n<p>bagging_fraction : 과적합 방지를 위해 데이터 샘플링하는 비율을 지정. default=1.0</p>\n</blockquote>\n<blockquote>\n<p>early_stopping_round : 분석속도를 높이는 사용. 평가 지표가 지난 라운드보다 향상되지 않으면 학습을 중단.</p>\n</blockquote>\n<blockquote>\n<p>lambda_l1 : L1 규제로 피처 개수가 많을 때 사용. 0~1 사이 값. default = 0.0</p>\n</blockquote>\n<blockquote>\n<p>lambda_l2 : l2 규제로 피처 개수가 많을 때 사용. 0~1 사이 값. default =0.0</p>\n</blockquote>\n<blockquote>\n<p>min_gain_to_split : split 하기 위한 최소한의 gain을 의미</p>\n</blockquote>\n<blockquote>\n<p>max_cat_group : category 수가 많을 때 과적합을 방지하는 분기 포인트를 찾는다. default=64</p>\n</blockquote>\n<h4 id=\"core-parameters\" style=\"position:relative;\"><a href=\"#core-parameters\" aria-label=\"core parameters permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Core Parameters</h4>\n<blockquote>\n<p>Task : 데이터에 대해 수행하고자 하는 임무. train or predict</p>\n</blockquote>\n<blockquote>\n<p>application : 어떤 분석의 문제인지를 정의. regression or binary or multiclass 인지 결정. default = regression</p>\n</blockquote>\n<blockquote>\n<p>boosting : 실행하고자 하는 알고리즘. default=gdbt</p>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>gbdt : 전통적인 Gradient Boosting Decision Tree</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>rf : RandomForest</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>dart : Dropouts meet Multiple Addictive Regression Trees</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>goss : Gradient-Based One-Side Sampling</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>num_boost_round : Boosting iteration 수로 일반적으로 100이상</p>\n</blockquote>\n<blockquote>\n<p>learning_rate : 학습률. 일반적으로 0.003~0.1</p>\n</blockquote>\n<blockquote>\n<p>num_leaves : 전체 Tree의 leave 수. default = 31</p>\n</blockquote>\n<blockquote>\n<p>device : cpu or gpu. default = cpu</p>\n</blockquote>\n<h4 id=\"metric-parameters\" style=\"position:relative;\"><a href=\"#metric-parameters\" aria-label=\"metric parameters permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Metric Parameters</h4>\n<blockquote>\n<p><strong>metric</strong></p>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>mae</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>mse</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>binary_logloss</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>multi_logloss</p>\n</blockquote>\n</blockquote>\n<h4 id=\"io-parameters\" style=\"position:relative;\"><a href=\"#io-parameters\" aria-label=\"io parameters permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>IO parameters</h4>\n<blockquote>\n<p>max_bin : feature 값의 최대 bin 수</p>\n</blockquote>\n<blockquote>\n<p>categorical_feature : 범주형 feature의 인덱스 수</p>\n</blockquote>\n<blockquote>\n<p>save_binary : True로 설정하면 데이터셋을 바이너리 파일로 저장. 추후 데이터를 읽어올 때 속도 향상</p>\n</blockquote>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://lightgbm.readthedocs.io/en/latest/\">https://lightgbm.readthedocs.io/en/latest/</a></p>\n<p>[2] <a href=\"https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc\">https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc</a></p>\n<p>[3] <a href=\"https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e\">https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e</a></p>\n<p>[4] <a href=\"https://nurilee.com/2020/04/03/lightgbm-definition-parameter-tuning/\">https://nurilee.com/2020/04/03/lightgbm-definition-parameter-tuning/</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#lightgbm\">LightGBM</a></p>\n<ul>\n<li>\n<p><a href=\"#%EC%86%8C%EA%B0%9C\">소개</a></p>\n</li>\n<li>\n<p><a href=\"#%EC%9E%A5%EB%8B%A8%EC%A0%90\">장단점</a></p>\n<ul>\n<li><a href=\"#%EC%9E%A5%EC%A0%90\">장점</a></li>\n<li><a href=\"#%EB%8B%A8%EC%A0%90\">단점</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%ED%95%B5%EC%8B%AC-%EA%B0%9C%EB%85%90\">핵심 개념</a></p>\n<ul>\n<li><a href=\"#goss-gradient-based-one-side-sampling\">GOSS (Gradient-Based One-Side Sampling)</a></li>\n<li><a href=\"#%EC%A7%84%ED%96%89%EA%B3%BC%EC%A0%95\">진행과정</a></li>\n<li><a href=\"#%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98\">알고리즘</a></li>\n<li><a href=\"#efb-exclusive-feature-bundling\">EFB (Exclusive Feature Bundling)</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#hyper-parameter\">Hyper Parameter</a></p>\n<ul>\n<li><a href=\"#leaf-wise-tree%EC%9D%98-%ED%8A%9C%EB%8B%9D-%EB%B0%A9%EB%B2%95\">Leaf-wise Tree의 튜닝 방법</a></li>\n<li><a href=\"#parameters\">Parameters</a></li>\n<li><a href=\"#core-parameters\">Core Parameters</a></li>\n<li><a href=\"#metric-parameters\">Metric Parameters</a></li>\n<li><a href=\"#io-parameters\">IO parameters</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"October 14, 2022","title":"LightGBM","categories":"ML","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/ML/[ML] LightGBM/"}},"prev":{"id":"035ea913-0a45-5620-a8eb-9da8a16d6582","html":"<h3 id=\"군집화\" style=\"position:relative;\"><a href=\"#%EA%B5%B0%EC%A7%91%ED%99%94\" aria-label=\"군집화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>군집화</h3>\n<p>군집화는 대표적인 비지도학습 중 하나로 <strong>유사한 데이터끼리 하나의 군집(Cluster)로 묶는 것</strong>을 말한다.</p>\n<p><img src=\"/c9d946bafeb5bcbc40164da8ddcbf9df/cl_1.png\" alt=\"cl_1.PNG\"></p>\n<h4 id=\"대표적인-군집화-방법\" style=\"position:relative;\"><a href=\"#%EB%8C%80%ED%91%9C%EC%A0%81%EC%9D%B8-%EA%B5%B0%EC%A7%91%ED%99%94-%EB%B0%A9%EB%B2%95\" aria-label=\"대표적인 군집화 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>대표적인 군집화 방법</h4>\n<ul>\n<li>K-means Clustering</li>\n<li>DBSCAN Clustering</li>\n<li>GMM</li>\n<li>Mean Shift</li>\n</ul>\n<h4 id=\"군집화-평가-방법\" style=\"position:relative;\"><a href=\"#%EA%B5%B0%EC%A7%91%ED%99%94-%ED%8F%89%EA%B0%80-%EB%B0%A9%EB%B2%95\" aria-label=\"군집화 평가 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>군집화 평가 방법</h4>\n<ul>\n<li>실루엣 계수</li>\n<li>조정 랜드지수</li>\n</ul>\n<h3 id=\"k-means-clustering\" style=\"position:relative;\"><a href=\"#k-means-clustering\" aria-label=\"k means clustering permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>K-means Clustering</h3>\n<h4 id=\"소개\" style=\"position:relative;\"><a href=\"#%EC%86%8C%EA%B0%9C\" aria-label=\"소개 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>소개</h4>\n<p>K-means는 특정 지점을 선택해 해당 중심에 가장 가까운 데이터를 군집화하는 알고리즘</p>\n<h4 id=\"진행과정\" style=\"position:relative;\"><a href=\"#%EC%A7%84%ED%96%89%EA%B3%BC%EC%A0%95\" aria-label=\"진행과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>진행과정</h4>\n<p><img src=\"/c18646c6f827e07d02438c4afa6a0731/cl_2.png\" alt=\"cl_2.PNG\"></p>\n<h3 id=\"dbscan\" style=\"position:relative;\"><a href=\"#dbscan\" aria-label=\"dbscan permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DBSCAN</h3>\n<h4 id=\"소개-1\" style=\"position:relative;\"><a href=\"#%EC%86%8C%EA%B0%9C-1\" aria-label=\"소개 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>소개</h4>\n<p>DBSCAN은 밀도 기반 군집화 알고리즘으로 데이터의 분포가 기하학적으로 복잡한 데이터셋에도 효과적인 군집화가 가능한 알고리즘</p>\n<h4 id=\"개념\" style=\"position:relative;\"><a href=\"#%EA%B0%9C%EB%85%90\" aria-label=\"개념 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>개념</h4>\n<p>DBSCAN에서 중요 파라미터 입실론, min points가 있다.</p>\n<blockquote>\n<p><img src=\"/c6891a5c7fde35a5bccc9e60e9a6c6bd/dbscan_1.png\" alt=\"dbscan_1.PNG\"></p>\n</blockquote>\n<p>입실론과 min points가 정해지고 그에따라 데이터를 군집화하는 과정에서 각 데이터는 3가지 상태 중 하나의 상태가 된다.</p>\n<p><img src=\"/3d3361ad58f757b9b7db7c14639a1a24/dbscan_0.png\" alt=\"dbscan_0.PNG\"></p>\n<ul>\n<li>Core Point</li>\n</ul>\n<blockquote>\n<p>Core Point는 선택된 데이터를 기준으로 입실론 영역 내 데이터 수가 min points보다 많은 경우 해당.</p>\n</blockquote>\n<ul>\n<li>Border Point</li>\n</ul>\n<blockquote>\n<p>Border Point는 선택된 데이터의 입실론 영역 내 데이터 수가 min points 보다 적고 주변 데이터 중 하나라도 Core Point인 데이터가 있는 경우 해당</p>\n</blockquote>\n<ul>\n<li>Noise Point</li>\n</ul>\n<blockquote>\n<p>Noise Point는 선택된 데이터의 입실론 영역 내 데이터 수가 min points 보다 적고 주변 데이터 중에 Core Point가 존재하지 않는 경우 해당</p>\n</blockquote>\n<p><img src=\"/b744a334a2fb7e4f09ba520f3537b8fa/dbscan_6.png\" alt=\"dbscan_6.PNG\"></p>\n<h3 id=\"mean-shift\" style=\"position:relative;\"><a href=\"#mean-shift\" aria-label=\"mean shift permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Mean-Shift</h3>\n<h4 id=\"소개-2\" style=\"position:relative;\"><a href=\"#%EC%86%8C%EA%B0%9C-2\" aria-label=\"소개 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>소개</h4>\n<p>Mean-Shift는 K-Means와 유사하게 군집의 중심을 지속적으로 이동시키면서 군집화를 수행하며 군집의 중심을 데이터가 많이 모여있는 밀도가 가장 높은 곳으로 이동시키며 K-means와 달리 K의 개수를 설정하지 않아도 됨.</p>\n<h4 id=\"kde-kernel-density-estimation\" style=\"position:relative;\"><a href=\"#kde-kernel-density-estimation\" aria-label=\"kde kernel density estimation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KDE (Kernel Density Estimation)</h4>\n<p>KDE는 커널 함수와 데이터를 바탕으로 연속성 있는 확률 밀도 함수를 추정하는 것으로 각 데이터마다 커널 함수를 생성한 후 모든 커널 함수를 더한 뒤 데이터 갯수로 나누어서 KDE 함수를 구함</p>\n<h4 id=\"진행-과정\" style=\"position:relative;\"><a href=\"#%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95\" aria-label=\"진행 과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>진행 과정</h4>\n<p><img src=\"/40f9a944f3fa166ebbc318dcf3cf32e3/ms_0.png\" alt=\"ms_0.PNG\"></p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>[1] <a href=\"https://datascienceschool.net/03%20machine%20learning/16.01%20%EA%B5%B0%EC%A7%91%ED%99%94.html\">https://datascienceschool.net/03%20machine%20learning/16.01%20%EA%B5%B0%EC%A7%91%ED%99%94.html</a></p>\n<p>[2] <a href=\"https://heung-bae-lee.github.io/2020/05/30/machine_learning_19/\">https://heung-bae-lee.github.io/2020/05/30/machine_learning_19/</a></p>\n<p>[3] <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</a></p>\n<p>[4] <a href=\"https://predictivehacks.com/k-means-elbow-method-code-for-python/\">https://predictivehacks.com/k-means-elbow-method-code-for-python/</a></p>\n<p>[5]  <a href=\"https://medium.com/analytics-vidhya/cluster-analysis-with-dbscan-density-based-spatial-clustering-of-applications-with-noise-6ade1ec23555\">https://medium.com/analytics-vidhya/cluster-analysis-with-dbscan-density-based-spatial-clustering-of-applications-with-noise-6ade1ec23555</a></p>\n<p>[6] <a href=\"https://blogs.sas.com/content/iml/2016/07/27/visualize-kernel-density-estimate.html#prettyPhoto/0/\">https://blogs.sas.com/content/iml/2016/07/27/visualize-kernel-density-estimate.html#prettyPhoto/0/</a></p>\n<p>[7] <a href=\"https://brunch.co.kr/@mnc/10\">https://brunch.co.kr/@mnc/10</a></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EA%B5%B0%EC%A7%91%ED%99%94\">군집화</a></p>\n<ul>\n<li><a href=\"#%EB%8C%80%ED%91%9C%EC%A0%81%EC%9D%B8-%EA%B5%B0%EC%A7%91%ED%99%94-%EB%B0%A9%EB%B2%95\">대표적인 군집화 방법</a></li>\n<li><a href=\"#%EA%B5%B0%EC%A7%91%ED%99%94-%ED%8F%89%EA%B0%80-%EB%B0%A9%EB%B2%95\">군집화 평가 방법</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#k-means-clustering\">K-means Clustering</a></p>\n<ul>\n<li><a href=\"#%EC%86%8C%EA%B0%9C\">소개</a></li>\n<li><a href=\"#%EC%A7%84%ED%96%89%EA%B3%BC%EC%A0%95\">진행과정</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#dbscan\">DBSCAN</a></p>\n<ul>\n<li><a href=\"#%EC%86%8C%EA%B0%9C-1\">소개</a></li>\n<li><a href=\"#%EA%B0%9C%EB%85%90\">개념</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#mean-shift\">Mean-Shift</a></p>\n<ul>\n<li><a href=\"#%EC%86%8C%EA%B0%9C-2\">소개</a></li>\n<li><a href=\"#kde-kernel-density-estimation\">KDE (Kernel Density Estimation)</a></li>\n<li><a href=\"#%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95\">진행 과정</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#reference\">Reference</a></p>\n</li>\n</ul>\n</div>","frontmatter":{"date":"October 21, 2022","title":"Clustering","categories":"ML","author":"HwanHee Park","emoji":"📝"},"fields":{"slug":"/Clustering/[ML] Clustering/"}},"site":{"siteMetadata":{"siteUrl":"https://han-archives.github.io","comments":{"utterances":{"repo":"Han-Archives/han-archives.github.io"}}}}},"pageContext":{"slug":"/ML/[ML] CatBoost/","nextSlug":"/ML/[ML] LightGBM/","prevSlug":"/Clustering/[ML] Clustering/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}